<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Data sets and models | 解释性模型分析</title>
  <meta name="description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Data sets and models | 解释性模型分析" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="github-repo" content="pbiecek/ema" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Data sets and models | 解释性模型分析" />
  
  <meta name="twitter:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2020-03-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="doItYourselfWithPython.html"/>
<link rel="next" href="instance-level.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/ema/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><span style="font-size: large">Explanatory Model Analysis</span><br/>Explore, Explain and Examine<br/>Predictive Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#notes-to-readers"><i class="fa fa-check"></i><b>1.1</b> Notes to readers</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.2</b> The aim of the book</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.3</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.4</b> The structure of this book</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i><b>1.5</b> Terminology</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#glass-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.6</b> Glass-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.7</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#what-is-in-this-book-and-what-is-not"><i class="fa fa-check"></i><b>1.8</b> What is in this book and what is not</a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.9</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>2</b> Model Development</a><ul>
<li class="chapter" data-level="2.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPprocess"><i class="fa fa-check"></i><b>2.2</b> The Process</a></li>
<li class="chapter" data-level="2.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notation"><i class="fa fa-check"></i><b>2.3</b> Notation</a></li>
<li class="chapter" data-level="2.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#data-exploration"><i class="fa fa-check"></i><b>2.4</b> Data exploration</a></li>
<li class="chapter" data-level="2.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notationTraining"><i class="fa fa-check"></i><b>2.5</b> Model training</a></li>
<li class="chapter" data-level="2.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#model-understanding"><i class="fa fa-check"></i><b>2.6</b> Model understanding</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself with R</a><ul>
<li class="chapter" data-level="3.1" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#what-to-install"><i class="fa fa-check"></i><b>3.1</b> What to install?</a></li>
<li class="chapter" data-level="3.2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-dalex"><i class="fa fa-check"></i><b>3.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="3.3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>3.3</b> How to work with <code>archivist</code>?</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html"><i class="fa fa-check"></i><b>4</b> Do-it-yourself with Python</a></li>
<li class="chapter" data-level="5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>5</b> Data sets and models</a><ul>
<li class="chapter" data-level="5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>5.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="5.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>5.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.1.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>5.1.2</b> Logistic regression model</a></li>
<li class="chapter" data-level="5.1.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>5.1.3</b> Random forest model</a></li>
<li class="chapter" data-level="5.1.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>5.1.4</b> Gradient boosting model</a></li>
<li class="chapter" data-level="5.1.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-svm"><i class="fa fa-check"></i><b>5.1.5</b> Support Vector Machine model</a></li>
<li class="chapter" data-level="5.1.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>5.1.6</b> Model predictions</a></li>
<li class="chapter" data-level="5.1.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>5.1.7</b> Model adapters</a></li>
<li class="chapter" data-level="5.1.8" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>5.1.8</b> List of objects for the <code>titanic</code> example</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>5.2</b> Apartment prices</a><ul>
<li class="chapter" data-level="5.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>5.2.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>5.2.2</b> Linear regression model</a></li>
<li class="chapter" data-level="5.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>5.2.3</b> Random forest model</a></li>
<li class="chapter" data-level="5.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-svm"><i class="fa fa-check"></i><b>5.2.4</b> Support vector model</a></li>
<li class="chapter" data-level="5.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>5.2.5</b> Model predictions</a></li>
<li class="chapter" data-level="5.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>5.2.6</b> Model adapters</a></li>
<li class="chapter" data-level="5.2.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>5.2.7</b> List of objects for the <code>apartments</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="instance-level.html"><a href="instance-level.html"><i class="fa fa-check"></i>Instance Level</a></li>
<li class="chapter" data-level="6" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>6</b> Introduction to Instance Level Exploration</a></li>
<li class="chapter" data-level="7" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>7</b> Break-down Plots for Additive Attributions</a><ul>
<li class="chapter" data-level="7.1" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>7.2</b> Method</a><ul>
<li class="chapter" data-level="7.2.1" data-path="breakDown.html"><a href="breakDown.html#break-down-for-linear-models"><i class="fa fa-check"></i><b>7.2.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="7.2.2" data-path="breakDown.html"><a href="breakDown.html#break-down-for-a-general-case"><i class="fa fa-check"></i><b>7.2.2</b> Break-down for a general case</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>7.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.4" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.5.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-variable_attribution-function"><i class="fa fa-check"></i><b>7.5.1</b> Basic use of the <code>variable_attribution()</code> function</a></li>
<li class="chapter" data-level="7.5.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-variable_attribution-function"><i class="fa fa-check"></i><b>7.5.2</b> Advanced use of the <code>variable_attribution()</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>8</b> Break-down Plots for Interactions (iBreak-down Plots)</a><ul>
<li class="chapter" data-level="8.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>8.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>8.4</b> Pros and cons</a></li>
<li class="chapter" data-level="8.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>8.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9</b> Shapley Additive Explanations (SHAP) and Average Variable Attributions</a><ul>
<li class="chapter" data-level="9.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>9.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>10</b> Local Interpretable Model-agnostic Explanations (LIME)</a><ul>
<li class="chapter" data-level="10.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>10.2</b> Intuition</a></li>
<li class="chapter" data-level="10.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>10.3</b> Method</a><ul>
<li class="chapter" data-level="10.3.1" data-path="LIME.html"><a href="LIME.html#interpretable-data-representation"><i class="fa fa-check"></i><b>10.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="10.3.2" data-path="LIME.html"><a href="LIME.html#sampling-around-the-instance-of-interest"><i class="fa fa-check"></i><b>10.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="10.3.3" data-path="LIME.html"><a href="LIME.html#developing-the-glass-box-model"><i class="fa fa-check"></i><b>10.3.3</b> Developing the glass-box model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>10.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="10.6.1" data-path="LIME.html"><a href="LIME.html#the-lime-package"><i class="fa fa-check"></i><b>10.6.1</b> The lime package</a></li>
<li class="chapter" data-level="10.6.2" data-path="LIME.html"><a href="LIME.html#the-localmodel-package"><i class="fa fa-check"></i><b>10.6.2</b> The localModel package</a></li>
<li class="chapter" data-level="10.6.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>10.6.3</b> The iml package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>11</b> Ceteris-paribus Profiles</a><ul>
<li class="chapter" data-level="11.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>11.2</b> Intuition</a></li>
<li class="chapter" data-level="11.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>11.3</b> Method</a></li>
<li class="chapter" data-level="11.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>11.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="11.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>11.5</b> Pros and cons</a></li>
<li class="chapter" data-level="11.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>11.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="11.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-individual_profile-function"><i class="fa fa-check"></i><b>11.6.1</b> Basic use of the <code>individual_profile</code> function</a></li>
<li class="chapter" data-level="11.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-individual_profile-function"><i class="fa fa-check"></i><b>11.6.2</b> Advanced use of the <code>individual_profile</code> function</a></li>
<li class="chapter" data-level="11.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#champion-challenger-analysis"><i class="fa fa-check"></i><b>11.6.3</b> Champion-challenger analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>12</b> Ceteris-paribus Oscillations</a><ul>
<li class="chapter" data-level="12.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a></li>
<li class="chapter" data-level="12.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="12.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="12.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-variable_attribution-function-1"><i class="fa fa-check"></i><b>12.6.1</b> Basic use of the <code>variable_attribution</code> function</a></li>
<li class="chapter" data-level="12.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-variable_attribution-function-1"><i class="fa fa-check"></i><b>12.6.2</b> Advanced use of the <code>variable_attribution</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>13</b> Local Diagnostics Plots</a><ul>
<li class="chapter" data-level="13.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>13.2</b> Intuition</a></li>
<li class="chapter" data-level="13.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>13.3</b> Method</a><ul>
<li class="chapter" data-level="13.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagNeighbors"><i class="fa fa-check"></i><b>13.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="13.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>13.3.2</b> Local-fidelity plot</a></li>
<li class="chapter" data-level="13.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>13.3.3</b> Local-stability plot for neighbors</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>13.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="13.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>13.5</b> Pros and cons</a></li>
<li class="chapter" data-level="13.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>13.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>14</b> Summary of Instance-level Explainers</a><ul>
<li class="chapter" data-level="14.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>14.1</b> Number of explanatory variables in the model</a><ul>
<li class="chapter" data-level="14.1.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.2</b> Medium to large number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>14.2</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="14.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>14.3</b> Models with interactions</a></li>
<li class="chapter" data-level="14.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>14.4</b> Sparse explanations</a></li>
<li class="chapter" data-level="14.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>14.5</b> Additional uses of model exploration and explanation</a></li>
<li class="chapter" data-level="14.6" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#champion-challenger-analysis-1"><i class="fa fa-check"></i><b>14.6</b> Champion Challenger analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dataset-level.html"><a href="dataset-level.html"><i class="fa fa-check"></i>Dataset Level</a></li>
<li class="chapter" data-level="15" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>15</b> Model-level exploration</a></li>
<li class="chapter" data-level="16" data-path="modelPerformance.html"><a href="modelPerformance.html"><i class="fa fa-check"></i><b>16</b> Model Performance Measures</a><ul>
<li class="chapter" data-level="16.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntuition"><i class="fa fa-check"></i><b>16.2</b> Intuition</a></li>
<li class="chapter" data-level="16.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethod"><i class="fa fa-check"></i><b>16.3</b> Method</a><ul>
<li class="chapter" data-level="16.3.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCont"><i class="fa fa-check"></i><b>16.3.1</b> Continuous dependent variable</a></li>
<li class="chapter" data-level="16.3.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodBin"><i class="fa fa-check"></i><b>16.3.2</b> Binary dependent variable</a></li>
<li class="chapter" data-level="16.3.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCateg"><i class="fa fa-check"></i><b>16.3.3</b> Categorical dependent variable</a></li>
<li class="chapter" data-level="16.3.4" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCount"><i class="fa fa-check"></i><b>16.3.4</b> Count dependent variable</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="modelPerformance.html"><a href="modelPerformance.html#example"><i class="fa fa-check"></i><b>16.4</b> Example</a><ul>
<li class="chapter" data-level="16.4.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceApartments"><i class="fa fa-check"></i><b>16.4.1</b> Apartment prices</a></li>
<li class="chapter" data-level="16.4.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceTitanic"><i class="fa fa-check"></i><b>16.4.2</b> Titanic data</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceProsCons"><i class="fa fa-check"></i><b>16.5</b> Pros and cons</a></li>
<li class="chapter" data-level="16.6" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceR"><i class="fa fa-check"></i><b>16.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>17</b> Variable’s Importance</a><ul>
<li class="chapter" data-level="17.1" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntuition"><i class="fa fa-check"></i><b>17.2</b> Intuition</a></li>
<li class="chapter" data-level="17.3" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceMethod"><i class="fa fa-check"></i><b>17.3</b> Method</a></li>
<li class="chapter" data-level="17.4" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceTitanic"><i class="fa fa-check"></i><b>17.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="17.5" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceProsCons"><i class="fa fa-check"></i><b>17.5</b> Pros and cons</a></li>
<li class="chapter" data-level="17.6" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceR"><i class="fa fa-check"></i><b>17.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="17.6.1" data-path="featureImportance.html"><a href="featureImportance.html#models-comparison"><i class="fa fa-check"></i><b>17.6.1</b> Models comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>18</b> Partial dependence profiles</a><ul>
<li class="chapter" data-level="18.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntuition"><i class="fa fa-check"></i><b>18.2</b> Intuition</a></li>
<li class="chapter" data-level="18.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPMethod"><i class="fa fa-check"></i><b>18.3</b> Method</a><ul>
<li class="chapter" data-level="18.3.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPs"><i class="fa fa-check"></i><b>18.3.1</b> Partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clusteredPDPs"><i class="fa fa-check"></i><b>18.3.2</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#groupedPDPs"><i class="fa fa-check"></i><b>18.3.3</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastivePDPs"><i class="fa fa-check"></i><b>18.3.4</b> Contrastive partial dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPExample"><i class="fa fa-check"></i><b>18.4</b> Example: Apartments data</a><ul>
<li class="chapter" data-level="18.4.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.1</b> Partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.2</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.3</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.4</b> Contrastive partial dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPProsCons"><i class="fa fa-check"></i><b>18.5</b> Pros and cons</a></li>
<li class="chapter" data-level="18.6" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPR"><i class="fa fa-check"></i><b>18.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="18.6.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.1</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.6.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.2</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.6.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.3</b> Contrastive partial dependence profiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>19</b> Local-dependence and Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="19.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntro"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntuition"><i class="fa fa-check"></i><b>19.2</b> Intuition</a></li>
<li class="chapter" data-level="19.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPMethod"><i class="fa fa-check"></i><b>19.3</b> Method</a><ul>
<li class="chapter" data-level="19.3.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#local-dependence-profile"><i class="fa fa-check"></i><b>19.3.1</b> Local-dependence profile</a></li>
<li class="chapter" data-level="19.3.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#accumulated-local-profile"><i class="fa fa-check"></i><b>19.3.2</b> Accumulated local profile</a></li>
<li class="chapter" data-level="19.3.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#summaryFeatureEffects"><i class="fa fa-check"></i><b>19.3.3</b> An illustrative example</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#CDPExample"><i class="fa fa-check"></i><b>19.4</b> Example: Apartments data</a></li>
<li class="chapter" data-level="19.5" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPProsCons"><i class="fa fa-check"></i><b>19.5</b> Pros and cons</a></li>
<li class="chapter" data-level="19.6" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPR"><i class="fa fa-check"></i><b>19.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>20</b> Residual Diagnostics</a><ul>
<li class="chapter" data-level="20.1" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntroResidualDiagnostic"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntuitionResidualDiagnostic"><i class="fa fa-check"></i><b>20.2</b> Intuition</a></li>
<li class="chapter" data-level="20.3" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#MethodResidualDiagnostic"><i class="fa fa-check"></i><b>20.3</b> Method</a></li>
<li class="chapter" data-level="20.4" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ExampleResidualDiagnostic"><i class="fa fa-check"></i><b>20.4</b> Example: Apartments data</a></li>
<li class="chapter" data-level="20.5" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ProsConsResidualDiagnostic"><i class="fa fa-check"></i><b>20.5</b> Pros and cons</a></li>
<li class="chapter" data-level="20.6" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#RcodeResidualDiagnostic"><i class="fa fa-check"></i><b>20.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="use-cases.html"><a href="use-cases.html"><i class="fa fa-check"></i>Use Cases</a></li>
<li class="chapter" data-level="21" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html"><i class="fa fa-check"></i><b>21</b> FIFA 19</a><ul>
<li class="chapter" data-level="21.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#introduction-1"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-preparation"><i class="fa fa-check"></i><b>21.2</b> Data preparation</a></li>
<li class="chapter" data-level="21.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-understanding"><i class="fa fa-check"></i><b>21.3</b> Data understanding</a></li>
<li class="chapter" data-level="21.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-assembly"><i class="fa fa-check"></i><b>21.4</b> Model assembly</a></li>
<li class="chapter" data-level="21.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-audit"><i class="fa fa-check"></i><b>21.5</b> Model audit</a></li>
<li class="chapter" data-level="21.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-understanding-1"><i class="fa fa-check"></i><b>21.6</b> Model understanding</a></li>
<li class="chapter" data-level="21.7" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#instance-understanding"><i class="fa fa-check"></i><b>21.7</b> Instance understanding</a></li>
<li class="chapter" data-level="21.8" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#cr7"><i class="fa fa-check"></i><b>21.8</b> CR7</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/ModelOriented/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">解释性模型分析</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dataSetsIntro" class="section level1">
<h1><span class="header-section-number">5</span> Data sets and models</h1>
<p>We illustrate the methods presented in this book by using two datasets:</p>
<ul>
<li>Predicting odds of survival out of <em>Sinking of the RMS Titanic</em></li>
<li>Predicting prices for <em>Apartments in Warsaw</em></li>
</ul>
<p>The first dataset will be used to illustrate the application of the techniques in the case of a predictive model for a binary dependent variable. The second one will provide an example for models for a continuous variable.</p>
<p>In this chapter, we provide a short description of each of the datasets, together with results of exploratory analyses. We also introduce models that will be used for illustration purposes in subsequent chapters.</p>
<div id="TitanicDataset" class="section level2">
<h2><span class="header-section-number">5.1</span> Sinking of the RMS Titanic</h2>
<div class="figure">
<img src="figure/Titanic.jpg" alt="Titanic sinking by Willy Stöwer" />
<p class="caption">Titanic sinking by Willy Stöwer</p>
</div>
<p>Sinking of the RMS Titanic is one of the deadliest maritime disasters in history (during peacetime). Over 1500 people died as a consequence of collision with an iceberg. Projects like <em>Encyclopedia titanica</em> <code>https://www.encyclopedia-titanica.org/</code> are a source of rich and precise data about Titanic’s passengers. The <code>stablelearner</code> package includes a data frame with some passenger characteristics. The dataset, after some data cleaning and variable transformations, is also available in the <code>DALEX</code> package. In particular, the <code>titanic</code> data frame contains 2207 observations (for 1317 passengers and 890 crew members) and nine variables:</p>
<ul>
<li><em>gender</em>, person’s (passenger’s or crew member’s) gender, a factor (categorical variable) with two levels (categories) <code>male</code> (78%) and <code>female</code> (22%);</li>
<li><em>age</em>, person’s age in years, a numerical variable; the age is given in (integer) years, range 0 – 74 years;</li>
<li><em>class</em>, the class in which the passenger travelled, or the duty class of a crew member; a factor with seven levels: <code>1st</code> (14.7%), <code>2nd</code> (12.9%), <code>3rd</code> (32.1%), <code>deck crew</code> (3%), <code>engineering crew</code> (14.7%), <code>restaurant staff</code> (3.1%), <code>victualling crew</code> (19.5%);</li>
<li><em>embarked</em>, the harbor in which the person embarked on the ship, a factor with four levels, <code>Belfast</code> (8.9%), <code>Cherbourg</code> (12.3%), <code>Queenstown</code> (5.6%), <code>Southampton</code> (73.2%);</li>
<li><em>country</em>, person’s home country, a factor with 48 levels, the most common are <code>England</code> (51%), <code>United States</code> (12%), <code>Ireland</code> (6.2%) and <code>Sweden</code> (4.8%);</li>
<li><em>fare</em>, the price of the ticket (only available for passengers; 0 for crew members), a numerical variable range 0 – 512;</li>
<li><em>sibsp</em>, the number of siblings/spouses aboard the ship, a numerical variable range 0 – 8;</li>
<li><em>parch</em>, the number of parents/children aboard the ship, a numerical variable range 0 – 9;</li>
<li><em>survived</em>, a factor with two levels <code>yes</code> (67.8%), <code>no</code> (32.2%), indicating whether the person survived or not.</li>
</ul>
<p>The R code below provides more info about the contents of the dataset, values of the variables, etc.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)
<span class="kw">head</span>(titanic, <span class="dv">2</span>)</code></pre></div>
<pre><code>##   gender age class    embarked       country  fare sibsp parch survived
## 1   male  42   3rd Southampton United States  7.11     0     0       no
## 2   male  13   3rd Southampton United States 20.05     0     2       no</code></pre>
<p>Models considered for this dataset will use <em>survived</em> as the (binary) dependent variable.</p>
<div id="exploration-titanic" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Data exploration</h3>
<p>It is always advisable to explore data before modelling. However, as this book is focused on model exploration, we will limit the data exploration part.</p>
<p>Before exploring the data, we first do some pre-processing. In particular, the value of variables <em>age</em>, <em>country</em>, <em>sibsp</em>, <em>parch</em>, and <em>fare</em> is missing for a limited number of observations (2, 81, 10, 10, and 26, respectively). Analyzing data with missing values is a topic on its own (Little and Rubin 1987; Schafer 1997; Molenberghs and Kenward 2007). An often-used approach is to impute the missing values. Toward this end, multiple imputation should be considered (Schafer 1997; Molenberghs and Kenward 2007; van Buuren 2012). However, given the limited number of missing values and the intended illustrative use of the dataset, we will limit ourselves to, admittedly inferior, single imputation. In particular, we replace the missing <em>age</em> values by the mean of the observed ones, i.e., 30. Missing <em>country</em> will be coded by “X”. For <em>sibsp</em> and <em>parch</em>, we replace the missing values by the most frequently observed value, i.e., 0. Finally, for <em>fare</em>, we use the mean fare for a given <em>class</em>, i.e., 0 pounds for crew, 89 pounds for the 1st, 22 pounds for the 2nd, and 13 pounds for the 3rd class. The R code presented below implements the imputation steps.</p>
<ul>
<li>missing <code>age</code> is replaced by its average, that is 30</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic<span class="op">$</span>age[<span class="kw">is.na</span>(titanic<span class="op">$</span>age)] =<span class="st"> </span><span class="dv">30</span></code></pre></div>
<ul>
<li>missing <code>country</code> is replaced by <code>&quot;X&quot;</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic<span class="op">$</span>country &lt;-<span class="st"> </span><span class="kw">as.character</span>(titanic<span class="op">$</span>country)
titanic<span class="op">$</span>country[<span class="kw">is.na</span>(titanic<span class="op">$</span>country)] =<span class="st"> &quot;X&quot;</span>
titanic<span class="op">$</span>country &lt;-<span class="st"> </span><span class="kw">factor</span>(titanic<span class="op">$</span>country)</code></pre></div>
<ul>
<li>missing <code>fare</code> is replaced by within <code>class</code> average, that is 89, 22 and 13 correspondingly</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic<span class="op">$</span>fare[<span class="kw">is.na</span>(titanic<span class="op">$</span>fare) <span class="op">&amp;</span><span class="st"> </span>titanic<span class="op">$</span>class <span class="op">==</span><span class="st"> &quot;1st&quot;</span>] =<span class="st"> </span><span class="dv">89</span>
titanic<span class="op">$</span>fare[<span class="kw">is.na</span>(titanic<span class="op">$</span>fare) <span class="op">&amp;</span><span class="st"> </span>titanic<span class="op">$</span>class <span class="op">==</span><span class="st"> &quot;2nd&quot;</span>] =<span class="st"> </span><span class="dv">22</span>
titanic<span class="op">$</span>fare[<span class="kw">is.na</span>(titanic<span class="op">$</span>fare) <span class="op">&amp;</span><span class="st"> </span>titanic<span class="op">$</span>class <span class="op">==</span><span class="st"> &quot;3rd&quot;</span>] =<span class="st"> </span><span class="dv">13</span></code></pre></div>
<ul>
<li>missing <code>sibsp</code> and <code>parch</code> are replaced by 0</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic<span class="op">$</span>sibsp[<span class="kw">is.na</span>(titanic<span class="op">$</span>sibsp)] =<span class="st"> </span><span class="dv">0</span>
titanic<span class="op">$</span>parch[<span class="kw">is.na</span>(titanic<span class="op">$</span>parch)] =<span class="st"> </span><span class="dv">0</span></code></pre></div>
<p>After imputing the missing values, we investigate the association between survival status and other variables. Most variables in the Titanic dataset are categorical, except Age and Fare. In order to keep the exploration uniform we first transformed them into categorical variables. Figure <a href="dataSetsIntro.html#fig:titanicExplorationHistograms">5.1</a> shows histograms for both variables. Age is discretized into 5 categories with cutoffs 5, 10, 20 and 30 while Fare is discretized with cutoffs 1, 10, 25, and 50.</p>
<p>Figures <a href="dataSetsIntro.html#fig:titanicExplorationGenderAge">5.2</a>-<a href="dataSetsIntro.html#fig:titanicExplorationCountry">5.5</a> present graphically the proportion non- and survivors for different levels of the other variables with the use of mosaic plots. The height of the bars (on the y-axis) reflects the marginal distribution (proportions) of the observed levels of the variable. On the other hand, the width of the bars (on the x-axis) provides the information about the proportion of non- and survivors. Note that, to construct the graphs for <em>age</em> and <em>fare</em>, we categorized the range of the observed values.</p>
<p>Figure <a href="dataSetsIntro.html#fig:titanicExplorationGenderAge">5.2</a> indicates that the proportion of survivors was larger for females and children below 5 years of age. This is most likely the result of the “women and children first” principle that is often evoked in situations that require evacuation of persons whose life is in danger. The principle can, perhaps, partially explain the trend seen in Figure <a href="dataSetsIntro.html#fig:titanicExplorationParch">5.3</a>, i.e., a higher proportion of survivors among those with 1-3 parents/children and 1-2 siblings/spouses aboard. Figure <a href="dataSetsIntro.html#fig:titanicExplorationClass">5.4</a> indicates that passengers travelling in the first and second class had a higher chance of survival, perhaps due to the proximity of the location of their cabins to the deck. Interestingly, the proportion of survivors among crew deck was similar to the proportion of the first-class passengers. It also shows that the proportion of survivors increased with the fare, which is consistent with the fact that the proportion was higher for passengers travelling in the first and second class. Finally, Figure <a href="dataSetsIntro.html#fig:titanicExplorationCountry">5.5</a> does not suggest any noteworthy trends.</p>
<div class="figure" style="text-align: center"><span id="fig:titanicExplorationHistograms"></span>
<img src="ema_files/figure-html/titanicExplorationHistograms-1.png" alt="Histogram of Age and Fare for the Titanic data." width="100%" />
<p class="caption">
Figure 5.1: Histogram of Age and Fare for the Titanic data.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:titanicExplorationGenderAge"></span>
<img src="ema_files/figure-html/titanicExplorationGenderAge-1.png" alt="Survival status in groups defined be Gender and Age for the Titanic data." width="100%" />
<p class="caption">
Figure 5.2: Survival status in groups defined be Gender and Age for the Titanic data.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:titanicExplorationParch"></span>
<img src="ema_files/figure-html/titanicExplorationParch-1.png" alt="Survival according to the number of parents/children and siblings/spouses in the Titanic data." width="100%" />
<p class="caption">
Figure 5.3: Survival according to the number of parents/children and siblings/spouses in the Titanic data.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:titanicExplorationClass"></span>
<img src="ema_files/figure-html/titanicExplorationClass-1.png" alt="Survival according to the class and port of embarking in the Titanic data." width="100%" />
<p class="caption">
Figure 5.4: Survival according to the class and port of embarking in the Titanic data.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:titanicExplorationCountry"></span>
<img src="ema_files/figure-html/titanicExplorationCountry-1.png" alt="Survival according to fare and country in the Titanic data." width="100%" />
<p class="caption">
Figure 5.5: Survival according to fare and country in the Titanic data.
</p>
</div>
</div>
<div id="model-titanic-lmr" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Logistic regression model</h3>
<p>The dependent variable of interest, <em>survival</em>, is binary. Thus, a natural choice is to start the predictive modelling with logistic regression model. As there is no reason to expect a linear relationship between age and odds of survival, we use linear tail-restricted cubic splines, available in the <code>rcs()</code> function of the <code>rms</code> package <span class="citation">(Harrell Jr <a href="#ref-rms">2018</a>)</span>, to model the effect of age. We also do not expect linear relation for the <code>fare</code> variable, but because of it’s skewness, we do not use splines for this variable. The results of the model are stored in model-object <code>titanic_lmr_v6</code>, which will be used in subsequent chapters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;rms&quot;</span>)
<span class="kw">set.seed</span>(<span class="dv">1313</span>)
titanic_lmr_v6 &lt;-<span class="st"> </span><span class="kw">lrm</span>(survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span> <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span><span class="kw">rcs</span>(age) <span class="op">+</span><span class="st"> </span>class <span class="op">+</span>
<span class="st">         </span>sibsp <span class="op">+</span><span class="st"> </span>parch <span class="op">+</span><span class="st"> </span>fare <span class="op">+</span><span class="st"> </span>embarked, titanic)
titanic_lmr_v6</code></pre></div>
<pre><code>## Logistic Regression Model
##  
##  lrm(formula = survived == &quot;yes&quot; ~ gender + rcs(age) + class + 
##      sibsp + parch + fare + embarked, data = titanic)
##  
##                         Model Likelihood     Discrimination    Rank Discrim.    
##                            Ratio Test           Indexes           Indexes       
##  Obs           2207    LR chi2     752.06    R2       0.404    C       0.817    
##   FALSE        1496    d.f.            17    g        1.647    Dxy     0.635    
##   TRUE          711    Pr(&gt; chi2) &lt;0.0001    gr       5.191    gamma   0.636    
##  max |deriv| 0.0001                          gp       0.282    tau-a   0.277    
##                                              Brier    0.146                     
##  
##                         Coef    S.E.   Wald Z Pr(&gt;|Z|)
##  Intercept               4.5746 0.5480   8.35 &lt;0.0001 
##  gender=male            -2.7687 0.1586 -17.45 &lt;0.0001 
##  age                    -0.1180 0.0221  -5.35 &lt;0.0001 
##  age&#39;                    0.6313 0.1628   3.88 0.0001  
##  age&#39;&#39;                  -2.6583 0.7840  -3.39 0.0007  
##  age&#39;&#39;&#39;                  2.8977 1.0130   2.86 0.0042  
##  class=2nd              -1.1390 0.2501  -4.56 &lt;0.0001 
##  class=3rd              -2.0627 0.2490  -8.28 &lt;0.0001 
##  class=deck crew         1.0672 0.3498   3.05 0.0023  
##  class=engineering crew -0.9702 0.2648  -3.66 0.0002  
##  class=restaurant staff -3.1712 0.6583  -4.82 &lt;0.0001 
##  class=victualling crew -1.0877 0.2596  -4.19 &lt;0.0001 
##  sibsp                  -0.4504 0.1006  -4.48 &lt;0.0001 
##  parch                  -0.0871 0.0987  -0.88 0.3776  
##  fare                    0.0014 0.0020   0.70 0.4842  
##  embarked=Cherbourg      0.7881 0.2836   2.78 0.0055  
##  embarked=Queenstown     0.2745 0.3409   0.80 0.4208  
##  embarked=Southampton    0.2343 0.2119   1.11 0.2689  
## </code></pre>
<p>Note that our prime interest is not in the assessment of model performance, but rather in the understanding of model behavior. This is why we do not split the data into train/test subsets. The model is trained and will be explained on the whole dataset.</p>
</div>
<div id="model-titanic-rf" class="section level3">
<h3><span class="header-section-number">5.1.3</span> Random forest model</h3>
<p>As a challenger to the logistic regression model, we consider a random forest model. Random forest is known for good predictive performance, is able to grasp low-order variable interactions, and is quite stable <span class="citation">(Breiman <a href="#ref-randomForestBreiman">2001</a>)</span>. To fit the model, we apply the <code>randomForest()</code> function, with default settings, from the package with the same name <span class="citation">(Liaw and Wiener <a href="#ref-randomForest">2002</a>)</span>.</p>
<p>In the first instance, we fit a model with the same set of explanatory variables as the logistic regression model. The results of the model are stored in model-object <code>titanic_rf_v6</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)
<span class="kw">set.seed</span>(<span class="dv">1313</span>)
titanic_rf_v6 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(survived <span class="op">~</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sibsp <span class="op">+</span><span class="st"> </span>
<span class="st">         </span>parch <span class="op">+</span><span class="st"> </span>fare <span class="op">+</span><span class="st"> </span>embarked, <span class="dt">data =</span> titanic)
titanic_rf_v6</code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = survived ~ class + gender + age + sibsp +      parch + fare + embarked, data = titanic) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 18.62%
## Confusion matrix:
##       no yes class.error
## no  1393 103  0.06885027
## yes  308 403  0.43319269</code></pre>
<p>For comparison purposes, we also consider a model with only three explanatory variables: <em>class</em>, <em>gender</em>, and <em>age</em>. The results of the model are stored in model-object <code>titanic_rf_v3</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic_rf_v3 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(survived <span class="op">~</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age, 
         <span class="dt">data =</span> titanic)
titanic_rf_v3</code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = survived ~ class + gender + age, data = titanic) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##         OOB estimate of  error rate: 21.02%
## Confusion matrix:
##       no yes class.error
## no  1367 129  0.08622995
## yes  335 376  0.47116737</code></pre>
</div>
<div id="model-titanic-gbm" class="section level3">
<h3><span class="header-section-number">5.1.4</span> Gradient boosting model</h3>
<p>Let’s consider an another challenger – the gradient-boosting model <span class="citation">(Friedman <a href="#ref-Friedman00greedyfunction">2000</a>)</span>. The tree based boosting models are known for being able to accommodate higher-order interactions between variables. We use the same set of six explanatory variables as for the logistic regression model. To fit the gradient-boosting model, we use function <code>gbm()</code> from the <code>gbm</code> package <span class="citation">(Ridgeway <a href="#ref-gbm">2017</a>)</span>. The results of the model are stored in model-object <code>titanic_gbm_v6</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;gbm&quot;</span>)
<span class="kw">set.seed</span>(<span class="dv">1313</span>)
titanic_gbm_v6 &lt;-<span class="st"> </span><span class="kw">gbm</span>(survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span> <span class="op">~</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sibsp <span class="op">+</span><span class="st"> </span>
<span class="st">         </span>parch <span class="op">+</span><span class="st"> </span>fare <span class="op">+</span><span class="st"> </span>embarked, <span class="dt">data =</span> titanic, <span class="dt">n.trees =</span> <span class="dv">15000</span>, 
         <span class="dt">distribution =</span> <span class="st">&quot;bernoulli&quot;</span>)
titanic_gbm_v6</code></pre></div>
<pre><code>## gbm(formula = survived == &quot;yes&quot; ~ class + gender + age + sibsp + 
##     parch + fare + embarked, distribution = &quot;bernoulli&quot;, data = titanic, 
##     n.trees = 15000)
## A gradient boosted model with bernoulli loss function.
## 15000 iterations were performed.
## There were 7 predictors of which 7 had non-zero influence.</code></pre>
</div>
<div id="model-titanic-svm" class="section level3">
<h3><span class="header-section-number">5.1.5</span> Support Vector Machine model</h3>
<p>Finally, we consider also Support Vector Machine model <span class="citation">(Cortes and Vapnik <a href="#ref-svm95vapnik">1995</a>)</span>. We use the C-classification mode. To fit the Support Vector Machine model, we use function <code>svm()</code> from the <code>e1071</code> package <span class="citation">(Meyer et al. <a href="#ref-e1071">2019</a>)</span>. The results of the model are stored in model-object <code>titanic_svm_v6</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;e1071&quot;</span>)
<span class="kw">set.seed</span>(<span class="dv">1313</span>)
titanic_svm_v6 &lt;-<span class="st"> </span><span class="kw">svm</span>(survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span> <span class="op">~</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sibsp <span class="op">+</span>
<span class="st">            </span>parch <span class="op">+</span><span class="st"> </span>fare <span class="op">+</span><span class="st"> </span>embarked, <span class="dt">data =</span> titanic, 
            <span class="dt">type =</span> <span class="st">&quot;C-classification&quot;</span>, <span class="dt">probability =</span> <span class="ot">TRUE</span>)
titanic_svm_v6</code></pre></div>
<pre><code>## 
## Call:
## svm(formula = survived == &quot;yes&quot; ~ class + gender + age + sibsp + parch + 
##     fare + embarked, data = titanic, type = &quot;C-classification&quot;, probability = TRUE)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  radial 
##        cost:  1 
##       gamma:  0.06666667 
## 
## Number of Support Vectors:  1030</code></pre>
</div>
<div id="predictions-titanic" class="section level3">
<h3><span class="header-section-number">5.1.6</span> Model predictions</h3>
<p>Let us now compare predictions that are obtained from the three different models. In particular, we will compute the predicted probability of survival for an 8-year-old boy who embarked in Belfast and travelled in the 1-st class with no parents nor siblings and with a ticket costing 72 pounds.</p>
<p>First, we create a dataframe <code>johny_d</code> that contains the data describing the passenger.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">johny_d &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
            <span class="dt">class =</span> <span class="kw">factor</span>(<span class="st">&quot;1st&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;1st&quot;</span>, <span class="st">&quot;2nd&quot;</span>, <span class="st">&quot;3rd&quot;</span>, <span class="st">&quot;deck crew&quot;</span>,
                        <span class="st">&quot;engineering crew&quot;</span>, <span class="st">&quot;restaurant staff&quot;</span>, <span class="st">&quot;victualling crew&quot;</span>)),
            <span class="dt">gender =</span> <span class="kw">factor</span>(<span class="st">&quot;male&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>)),
            <span class="dt">age =</span> <span class="dv">8</span>,
            <span class="dt">sibsp =</span> <span class="dv">0</span>,
            <span class="dt">parch =</span> <span class="dv">0</span>,
            <span class="dt">fare =</span> <span class="dv">72</span>,
            <span class="dt">embarked =</span> <span class="kw">factor</span>(<span class="st">&quot;Southampton&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Belfast&quot;</span>,
                        <span class="st">&quot;Cherbourg&quot;</span>,<span class="st">&quot;Queenstown&quot;</span>,<span class="st">&quot;Southampton&quot;</span>))
)</code></pre></div>
<p>Subsequently, we use the generic function <code>predict()</code> to get the predicted probability of survival for the logistic regression model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pred_lmr &lt;-<span class="st"> </span><span class="kw">predict</span>(titanic_lmr_v6, johny_d, <span class="dt">type =</span> <span class="st">&quot;fitted&quot;</span>))</code></pre></div>
<pre><code>##         1 
## 0.7677036</code></pre>
<p>The predicted probability is equal to 0.77.</p>
<p>We do the same for the random forest and gradient boosting models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pred_rf &lt;-<span class="st"> </span><span class="kw">predict</span>(titanic_rf_v6, johny_d, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>))</code></pre></div>
<pre><code>##      no   yes
## 1 0.578 0.422
## attr(,&quot;class&quot;)
## [1] &quot;matrix&quot; &quot;votes&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pred_gbm &lt;-<span class="st"> </span><span class="kw">predict</span>(titanic_gbm_v6, johny_d, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>, <span class="dt">n.trees =</span> <span class="dv">15000</span>))</code></pre></div>
<pre><code>## [1] 0.6632574</code></pre>
<p>As a result, we obtain the predicted probabilities of 0.42 and 0.66, respectively.</p>
<p>The models lead to different probabilities. Thus, it might be of interest to understand the reason for the differences, as it could help us to decide which of the predictions we might want to trust.</p>
<p>Note that for some examples we will use another observation (instance) with lower chances of survival. Let’s call this passenger Henry.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">henry &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
         <span class="dt">class =</span> <span class="kw">factor</span>(<span class="st">&quot;1st&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;1st&quot;</span>, <span class="st">&quot;2nd&quot;</span>, <span class="st">&quot;3rd&quot;</span>, <span class="st">&quot;deck crew&quot;</span>, 
                     <span class="st">&quot;engineering crew&quot;</span>, <span class="st">&quot;restaurant staff&quot;</span>, <span class="st">&quot;victualling crew&quot;</span>)),
         <span class="dt">gender =</span> <span class="kw">factor</span>(<span class="st">&quot;male&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>)),
         <span class="dt">age =</span> <span class="dv">47</span>,
         <span class="dt">sibsp =</span> <span class="dv">0</span>,
         <span class="dt">parch =</span> <span class="dv">0</span>,
         <span class="dt">fare =</span> <span class="dv">25</span>,
         <span class="dt">embarked =</span> <span class="kw">factor</span>(<span class="st">&quot;Cherbourg&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Belfast&quot;</span>,
                           <span class="st">&quot;Cherbourg&quot;</span>,<span class="st">&quot;Queenstown&quot;</span>,<span class="st">&quot;Southampton&quot;</span>))
)
<span class="kw">predict</span>(titanic_lmr_v6, henry, <span class="dt">type =</span> <span class="st">&quot;fitted&quot;</span>)</code></pre></div>
<pre><code>##         1 
## 0.4318245</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(titanic_rf_v6, henry, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)</code></pre></div>
<pre><code>##      no   yes
## 1 0.754 0.246
## attr(,&quot;class&quot;)
## [1] &quot;matrix&quot; &quot;votes&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(titanic_gbm_v6, henry, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>, <span class="dt">n.trees =</span> <span class="dv">15000</span>)</code></pre></div>
<pre><code>## [1] 0.3073358</code></pre>
</div>
<div id="ExplainersTitanicRCode" class="section level3">
<h3><span class="header-section-number">5.1.7</span> Model adapters</h3>
<p>Model-objects created with different machine learning libraries may have different internal structures. Thus, first, we have got to create an adapter for the model that provides an uniform interface. Toward this end, we use the <code>explain()</code> function from the <code>DALEX</code> package <span class="citation">(Biecek <a href="#ref-DALEX">2018</a>)</span>. The function requires five arguments:</p>
<ul>
<li><code>model</code>, a model-object;</li>
<li><code>data</code>, a validation data frame;</li>
<li><code>y</code>, observed values of the dependent variable for the validation data;</li>
<li><code>predict_function</code>, a function that returns prediction scores; if not specified, then a default <code>predict()</code> function is used;</li>
<li><code>label</code>, an unique name of the model; if not specified, then it is extracted from the <code>class(model)</code>.</li>
</ul>
<p>Each adapter contains all elements needed to create a model explanation, i.e., a suitable <code>predict()</code> function, validation data set, and the model object. Thus, in subsequent chapters we will use the explainers instead of the model objects to keep code snippets more concise.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">explain_titanic_lmr_v6 &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_lmr_v6, 
                                 <span class="dt">data =</span> titanic[, <span class="op">-</span><span class="dv">9</span>],
                                 <span class="dt">y =</span> titanic<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
                                 <span class="dt">label =</span> <span class="st">&quot;Logistic Regression&quot;</span>)
explain_titanic_lmr_v6<span class="op">$</span>model_info<span class="op">$</span>type =<span class="st"> &quot;classification&quot;</span>
explain_titanic_rf_v6 &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_rf_v6, 
                                 <span class="dt">data =</span> titanic[, <span class="op">-</span><span class="dv">9</span>],
                                 <span class="dt">y =</span> titanic<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
                                 <span class="dt">label =</span> <span class="st">&quot;Random Forest&quot;</span>)
explain_titanic_rf_v3 &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_rf_v3, 
                                 <span class="dt">data =</span> titanic[, <span class="op">-</span><span class="dv">9</span>],
                                 <span class="dt">y =</span> titanic<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
                                 <span class="dt">label =</span> <span class="st">&quot;Random Forest small&quot;</span>)
explain_titanic_gbm_v6 &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_gbm_v6, 
                                 <span class="dt">data =</span> titanic[, <span class="op">-</span><span class="dv">9</span>],
                                 <span class="dt">y =</span> titanic<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
                                 <span class="dt">label =</span> <span class="st">&quot;Generalized Boosted Regression&quot;</span>)
explain_titanic_svm_v6 &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_svm_v6, 
                                 <span class="dt">data =</span> titanic[, <span class="op">-</span><span class="dv">9</span>],
                                 <span class="dt">y =</span> titanic<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
                                 <span class="dt">label =</span> <span class="st">&quot;Support Vector Machine&quot;</span>)</code></pre></div>
</div>
<div id="ListOfModelsTitanic" class="section level3">
<h3><span class="header-section-number">5.1.8</span> List of objects for the <code>titanic</code> example</h3>
<p>In the previous sections we have built four predictive models for the <code>titanic</code> data set. The models will be used in the rest of the book to illustrate the model explanation methods and tools.</p>
<p>For the ease of reference, we summarize the models in Table <a href="dataSetsIntro.html#tab:archivistHooksOfModelsTitanic">5.1</a>. The binary model-objects can be downloaded by using the indicated <code>archivist</code> hooks <span class="citation">(Biecek and Kosinski <a href="#ref-archivist">2017</a>)</span>. By calling a function specified in the last column of the table, one can restore a selected model in its local R environment.</p>
<table style="width:89%;">
<caption><span id="tab:archivistHooksOfModelsTitanic">Table 5.1: </span> Predictive models created for the <code>titanic</code> dataset.</caption>
<colgroup>
<col width="20%" />
<col width="25%" />
<col width="18%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Model name</th>
<th>Model generator</th>
<th>Variables</th>
<th>Archivist hooks</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>titanic_lmr_v6</code></td>
<td><code>rms:: lmr</code> v.5.1.3</td>
<td>gender, age, class, sibsp, parch, fare, embarked</td>
<td>Get the model: <code>archivist:: aread(&quot;pbiecek/models/56d8a&quot;)</code>. Get the explainer: <code>archivist:: aread(&quot;pbiecek/models/ff1cd&quot;)</code></td>
</tr>
<tr class="even">
<td><code>titanic_rf_v6</code></td>
<td><code>randomForest:: randomForest</code> v.4.6.14</td>
<td>gender, age, class, sibsp, parch, fare, embarked</td>
<td>Get the model: <code>archivist:: aread(&quot;pbiecek/models/31570&quot;)</code>. Get the explainer: <code>archivist:: aread(&quot;pbiecek/models/6ed54&quot;)</code></td>
</tr>
<tr class="odd">
<td><code>titanic_rf_v3</code></td>
<td><code>randomForest:: randomForest</code> v.4.6.14</td>
<td>gender, age, class</td>
<td>Get the model: <code>archivist:: aread(&quot;pbiecek/models/855c1&quot;)</code>. Get the explainer: <code>archivist:: aread(&quot;pbiecek/models/5b32a&quot;)</code></td>
</tr>
<tr class="even">
<td><code>titanic_gbm_v6</code></td>
<td><code>gbm:: gbm</code> v.2.1.5</td>
<td>gender, age, class, sibsp, parch, fare, embarked</td>
<td>Get the model: <code>archivist:: aread(&quot;pbiecek/models/08544&quot;)</code>. Get the explainer: <code>archivist:: aread(&quot;pbiecek/models/87271&quot;)</code></td>
</tr>
<tr class="odd">
<td><code>titanic_svm_v6</code></td>
<td><code>e1071:: svm</code> 1.7-2</td>
<td>gender, age, class, sibsp, parch, fare, embarked</td>
<td>Get the model: <code>archivist:: aread(&quot;pbiecek/models/be26e&quot;)</code>. Get the explainer: <code>archivist:: aread(&quot;pbiecek/models/21966&quot;)</code></td>
</tr>
</tbody>
</table>
<p>Table <a href="dataSetsIntro.html#tab:archivistHooksOfDataFramesTitanic">5.2</a> summarizes the data frames that will be used in examples in the subsequent chapters.</p>
<table style="width:85%;">
<caption><span id="tab:archivistHooksOfDataFramesTitanic">Table 5.2: </span> Data frames created for the <code>titanic</code> example.</caption>
<colgroup>
<col width="20%" />
<col width="15%" />
<col width="18%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th>Description</th>
<th>No. rows</th>
<th>Variables</th>
<th>Link to this object</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>titanic</code> dataset with imputed missing values</td>
<td>2207</td>
<td>gender, age, class, embarked, country, fare, sibsp, parch, survived</td>
<td><code>archivist:: aread(&quot;pbiecek/models/27e5c&quot;)</code></td>
</tr>
<tr class="even">
<td><code>johny_d</code> 8-year-old boy that travelled in the 1st class without parents</td>
<td>1</td>
<td>class, gender, age, sibsp, parch, fare, embarked</td>
<td><code>archivist:: aread(&quot;pbiecek/models/e3596&quot;)</code></td>
</tr>
<tr class="odd">
<td><code>henry</code> 47-year-old male passenger from the 1st class, paid 25 pounds and embarked at Cherbourg</td>
<td>1</td>
<td>class, gender, age, sibsp, parch, fare, embarked</td>
<td><code>archivist:: aread(&quot;pbiecek/models/a6538&quot;)</code></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="ApartmentDataset" class="section level2">
<h2><span class="header-section-number">5.2</span> Apartment prices</h2>
<div class="figure">
<img src="figure/am1974_flicker.jpg" alt="Warsaw skyscrapers by Artur Malinowski Flicker" />
<p class="caption">Warsaw skyscrapers by Artur Malinowski Flicker</p>
</div>
<p>Predicting house prices is a common exercise used in machine-learning courses. Various datasets for house prices are available at websites like Kaggle (<a href="https://www.kaggle.com" class="uri">https://www.kaggle.com</a>) or UCI Machine Learning Repository (<a href="https://archive.ics.uci.edu" class="uri">https://archive.ics.uci.edu</a>).</p>
<p>In this book, we will work with an interesting variant of this problem. The <code>apartments</code> dataset is an artificial dataset created to match key characteristics of real apartments in Warsaw, the capital of Poland. However, the dataset is created in a way that two very different models, namely linear regression and random forest, have almost exactly the same accuracy. The natural question is then: which model should we choose? We will show that the model-explanation tools provide important insight into the key model characteristics and are helpful in model selection.</p>
<p>The dataset is available in the <code>DALEX</code> package <span class="citation">(Biecek <a href="#ref-DALEX">2018</a>)</span>. It contains 1000 observations (apartments) and six variables:</p>
<ul>
<li><em>m2.price</em>, apartments price per meter-squared (in EUR), a numerical variable range 1607 – 6595;</li>
<li><em>construction.year</em>, the year of construction of the block of flats in which the apartment is located, a numerical variable range 1920 – 2010;</li>
<li><em>surface</em>, apartment’s total surface in square meters, a numerical variable range 20 – 150;</li>
<li><em>floor</em>, the floor at which the apartment is located (ground floor taken to be the first floor), a numerical integer variable with values from 1 to 10;</li>
<li><em>no.rooms</em>, the total number of rooms, a numerical variable with values from 1 to 6;</li>
<li><em>district</em>, a factor with 10 levels indicating the district of Warsaw where the apartment is located.</li>
</ul>
<p>The R code below provides more info about the contents of the dataset, values of the variables, etc.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)
<span class="kw">head</span>(apartments, <span class="dv">2</span>)</code></pre></div>
<pre><code>##   m2.price construction.year surface floor no.rooms    district
## 1     5897              1953      25     3        1 Srodmiescie
## 2     1818              1992     143     9        5     Bielany</code></pre>
<p>Models considered for this dataset will use <em>m2.price</em> as the (continuous) dependent variable.</p>
<p>Model predictions will be obtained for a set of six apartments included in data frame <code>apartments_test</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(apartments_test)</code></pre></div>
<pre><code>##      m2.price construction.year surface floor no.rooms    district
## 1001     4644              1976     131     3        5 Srodmiescie
## 1002     3082              1978     112     9        4     Mokotow
## 1003     2498              1958     100     7        4     Bielany
## 1004     2735              1951     112     3        5        Wola
## 1005     2781              1978     102     4        4      Bemowo
## 1006     2936              2001     116     7        4      Bemowo</code></pre>
<div id="exploration-apartments" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Data exploration</h3>
<p>Note that <code>apartments</code> is an artificial dataset created to illustrate and explain differences between random forest and linear regression. Hence, the structure of the data, the form and strength of association between variables, plausibility of distributional assumptions, etc., is better than in a real-life dataset. In fact, all these characteristics of the data are known. Nevertheless, we conduct some data exploration to illustrate the important aspects of the data.</p>
The variable of interest is <em>m2.price</em>, the price per meter-squared. The histogram presented in Figure <a href="dataSetsIntro.html#fig:appartmentsExplorationMi2">5.6</a> indicates that the distribution of the variable is slightly skewed to the right.
<div class="figure"><span id="fig:appartmentsExplorationMi2"></span>
<img src="ema_files/figure-html/appartmentsExplorationMi2-1.png" alt="Distribution of the price per meter-squared in the apartments data." width="576" />
<p class="caption">
Figure 5.6: Distribution of the price per meter-squared in the apartments data.
</p>
</div>
<p>Figure <a href="dataSetsIntro.html#fig:appartmentsMi2Construction">5.7</a> suggests (possibly) a nonlinear relation between <em>construction.year</em> and <em>m2.price</em> and a linear relation between <em>surface</em> and <em>m2.price</em>.</p>
<div class="figure" style="text-align: center"><span id="fig:appartmentsMi2Construction"></span>
<img src="ema_files/figure-html/appartmentsMi2Construction-1.png" alt="Left panel shows apartment price per m2 vs. year of construction, right panel shows price  vs. square footage" width="100%" />
<p class="caption">
Figure 5.7: Left panel shows apartment price per m2 vs. year of construction, right panel shows price vs. square footage
</p>
</div>
<p>Relation between <em>floor</em> and <em>m2.price</em> is also close to linear, as well as relation between <em>no.rooms</em> and <em>m2.price</em> as seen in Figure <a href="dataSetsIntro.html#fig:appartmentsMi2Floor">5.8</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:appartmentsMi2Floor"></span>
<img src="ema_files/figure-html/appartmentsMi2Floor-1.png" alt="Price per meter-squared vs. floor and vs. number of rooms." width="100%" />
<p class="caption">
Figure 5.8: Price per meter-squared vs. floor and vs. number of rooms.
</p>
</div>
<p>Surface and number of rooms are correlated and prices depend on district. Boxplots plots in Figure <a href="dataSetsIntro.html#fig:appartmentsSurfaceNorooms">5.9</a> indicate that the highest prices per meter-squared are observed in Srodmiescie (Downtown).</p>
<div class="figure" style="text-align: center"><span id="fig:appartmentsSurfaceNorooms"></span>
<img src="ema_files/figure-html/appartmentsSurfaceNorooms-1.png" alt="Left panel: surface vs. number of rooms. Right panel: price per meter-squared for different districts" width="100%" />
<p class="caption">
Figure 5.9: Left panel: surface vs. number of rooms. Right panel: price per meter-squared for different districts
</p>
</div>
</div>
<div id="model-Apartments-lr" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Linear regression model</h3>
<p>The dependent variable of interest, <em>m2.price</em>, is continuous. Thus, a natural choice to build a predictive model is the linear regression. We treat all the other variables in the <code>apartments</code> dataframe as explanatory and include them in the model. The results of the model are stored in model-object <code>apartments_lm_v5</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">apartments_lm_v5 &lt;-<span class="st"> </span><span class="kw">lm</span>(m2.price <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> apartments)
<span class="kw">anova</span>(apartments_lm_v5)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: m2.price
##                    Df    Sum Sq   Mean Sq  F value    Pr(&gt;F)    
## construction.year   1   2629802   2629802   33.233 1.093e-08 ***
## surface             1 207840733 207840733 2626.541 &lt; 2.2e-16 ***
## floor               1  79823027  79823027 1008.746 &lt; 2.2e-16 ***
## no.rooms            1    956996    956996   12.094  0.000528 ***
## district            9 451993980  50221553  634.664 &lt; 2.2e-16 ***
## Residuals         986  78023123     79131                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="model-Apartments-rf" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Random forest model</h3>
<p>As a challenger to linear regression, we consider a random forest model. To fit the model, we apply the <code>randomForest()</code> function, with default settings, from the package with the same name <span class="citation">(Liaw and Wiener <a href="#ref-randomForest">2002</a>)</span>.<br />
The results of the model are stored in model-object <code>apartments_rf_v5</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)
<span class="kw">set.seed</span>(<span class="dv">72</span>)
apartments_rf_v5 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(m2.price <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> apartments)
apartments_rf_v5</code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = m2.price ~ ., data = apartments) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##           Mean of squared residuals: 79789.39
##                     % Var explained: 90.28</code></pre>
</div>
<div id="model-Apartments-svm" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Support vector model</h3>
<p>As an another challenger to the linear regression model, we consider a Support Vector Machines model. To fit the model, we use the <code>svm()</code> function, with default settings, from the package <code>e1071</code> <span class="citation">(Meyer et al. <a href="#ref-R-e1071">2017</a>)</span>.<br />
The results of the model are stored in model-object <code>apartments_svm_v5</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;e1071&quot;</span>)
apartments_svm_v5 &lt;-<span class="st"> </span><span class="kw">svm</span>(m2.price <span class="op">~</span><span class="st"> </span>construction.year <span class="op">+</span><span class="st"> </span>surface <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>
<span class="st">         </span>no.rooms <span class="op">+</span><span class="st"> </span>district, <span class="dt">data =</span> apartments)
apartments_svm_v5</code></pre></div>
</div>
<div id="predictionsApartments" class="section level3">
<h3><span class="header-section-number">5.2.5</span> Model predictions</h3>
<p>The <code>predict()</code> function calculates predictions for a specific model. In the example below we use model-object <code>apartments_lm_v5</code> to calculate predictions for prices for first six rows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(apartments_lm_v5, apartments_test[<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, ])</code></pre></div>
<pre><code>##     1001     1002     1003     1004     1005     1006 
## 4820.009 3292.678 2717.910 2922.751 2974.086 2527.043</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(apartments_rf_v5, apartments_test[<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, ])</code></pre></div>
<pre><code>##     1001     1002     1003     1004     1005     1006 
## 3399.854 2545.792 2695.787 2748.969 3682.974 3739.780</code></pre>
<p>In the example below we calculate predictive performance for <code>apartments_lm_v5</code> and <code>apartments_rf_v5</code> as the square root of the average of squared errors (RMSE).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predicted_apartments_lm &lt;-<span class="st"> </span><span class="kw">predict</span>(apartments_lm_v5, apartments_test)
(rmsd_lm &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((predicted_apartments_lm <span class="op">-</span><span class="st"> </span>apartments_test<span class="op">$</span>m2.price)<span class="op">^</span><span class="dv">2</span>)))</code></pre></div>
<pre><code>## [1] 283.0865</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predicted_apartments_rf &lt;-<span class="st"> </span><span class="kw">predict</span>(apartments_rf_v5, apartments_test)
(rmsd_rf &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((predicted_apartments_rf <span class="op">-</span><span class="st"> </span>apartments_test<span class="op">$</span>m2.price)<span class="op">^</span><span class="dv">2</span>)))</code></pre></div>
<pre><code>## [1] 795.2587</code></pre>
<p>For the random forest model, the root-mean-square of the mean squared difference is equal to 795.3. It is almost identical as root-mean-square for the linear regression model 283.1. Thus, the question we may face is: should we choose the more complex, but flexible random-forest model, or the simpler and easier to interpret linear model? In the subsequent chapters we will try to provide an answer to this question.</p>
<p>As we will show in following chapters, a proper model exploration helps to understand which model we should choose. And even more, it helps to understand weak and strong sides of both models and in consequence we can create a new model better than these two.</p>
</div>
<div id="ExplainersApartmentsRCode" class="section level3">
<h3><span class="header-section-number">5.2.6</span> Model adapters</h3>
<p>In similar spirit to the Section <a href="dataSetsIntro.html#ExplainersTitanicRCode">5.1.7</a> we will use explainers also for predictive models created for the <code>apartments</code> dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">explain_apartments_lm_v5 &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> apartments_lm_v5, 
         <span class="dt">data =</span> apartments_test, <span class="dt">y =</span> apartments_test<span class="op">$</span>m2.price,
         <span class="dt">label =</span> <span class="st">&quot;Linear Regression&quot;</span>)
explain_apartments_rf_v5 &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> apartments_rf_v5, 
         <span class="dt">data =</span> apartments_test, <span class="dt">y =</span> apartments_test<span class="op">$</span>m2.price,
         <span class="dt">label =</span> <span class="st">&quot;Random Forest&quot;</span>)
explain_apartments_svm_v5 &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> apartments_svm_v5, 
         <span class="dt">data =</span> apartments_test, <span class="dt">y =</span> apartments_test<span class="op">$</span>m2.price,
         <span class="dt">label =</span> <span class="st">&quot;Support Vector Machines&quot;</span>)</code></pre></div>
</div>
<div id="ListOfModelsApartments" class="section level3">
<h3><span class="header-section-number">5.2.7</span> List of objects for the <code>apartments</code> example</h3>
<p>In Sections <a href="dataSetsIntro.html#model-Apartments-lr">5.2.2</a> and <a href="dataSetsIntro.html#model-Apartments-rf">5.2.3</a> we have built two predictive models for the <code>apartments</code> data set. The models will be used in the rest of the book to illustrate the model explanation methods and tools.</p>
<p>For the ease of reference, we summarize the models in Table <a href="dataSetsIntro.html#tab:archivistHooksOfModelsApartments">5.3</a>. The binary model-objects can be downloaded by using the indicated <code>archivist</code> hooks <span class="citation">(Biecek and Kosinski <a href="#ref-archivist">2017</a>)</span>. By calling a function specified in the last column of the table, one can restore a selected model in a local R environment.</p>
<table style="width:89%;">
<caption><span id="tab:archivistHooksOfModelsApartments">Table 5.3: </span> Predictive models created for the <code>apartments</code> dataset.</caption>
<colgroup>
<col width="20%" />
<col width="25%" />
<col width="18%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Model name</th>
<th>Model generator</th>
<th>Variables</th>
<th>Archivist hooks</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>apartments_lm_v5</code></td>
<td><code>stats:: lm</code> v.3.5.3</td>
<td>construction .year, surface, floor, no.rooms, district</td>
<td>Get the model: <code>archivist:: aread(&quot;pbiecek/models/55f19&quot;)</code>. Get the explainer: <code>archivist:: aread(&quot;pbiecek/models/78d4e&quot;)</code></td>
</tr>
<tr class="even">
<td><code>apartments_rf_v5</code></td>
<td><code>randomForest:: randomForest</code> v.4.6.14</td>
<td>construction .year, surface, floor, no.rooms, district</td>
<td>Get the model: <code>archivist:: aread(&quot;pbiecek/models/fe7a5&quot;)</code>. Get the explainer: <code>archivist:: aread(&quot;pbiecek/models/b1739&quot;)</code></td>
</tr>
<tr class="odd">
<td><code>apartments_svm_v5</code></td>
<td><code>e1071:: svm</code> v.1.7-2</td>
<td>construction .year, surface, floor, no.rooms, district</td>
<td>Get the model: <code>archivist:: aread(&quot;pbiecek/models/545fa&quot;)</code>. Get the explainer: <code>archivist:: aread(&quot;pbiecek/models/16602&quot;)</code></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-DALEX">
<p>Biecek, Przemyslaw. 2018. <em>DALEX: Explainers for Complex Predictive Models in R</em>. <em>Journal of Machine Learning Research</em>. Vol. 19. <a href="http://jmlr.org/papers/v19/18-416.html" class="uri">http://jmlr.org/papers/v19/18-416.html</a>.</p>
</div>
<div id="ref-archivist">
<p>Biecek, Przemyslaw, and Marcin Kosinski. 2017. “archivist: An R Package for Managing, Recording and Restoring Data Analysis Results.” <em>Journal of Statistical Software</em> 82 (11): 1–28. doi:<a href="https://doi.org/10.18637/jss.v082.i11">10.18637/jss.v082.i11</a>.</p>
</div>
<div id="ref-randomForestBreiman">
<p>Breiman, Leo. 2001. “Random Forests.” In <em>Machine Learning</em>, 45:5–32. doi:<a href="https://doi.org/10.1023/a:1010933404324">10.1023/a:1010933404324</a>.</p>
</div>
<div id="ref-svm95vapnik">
<p>Cortes, Corinna, and Vladimir Vapnik. 1995. “Support-Vector Networks.” In <em>Machine Learning</em>, 273–97.</p>
</div>
<div id="ref-Friedman00greedyfunction">
<p>Friedman, Jerome H. 2000. “Greedy Function Approximation: A Gradient Boosting Machine.” <em>Annals of Statistics</em> 29: 1189–1232.</p>
</div>
<div id="ref-rms">
<p>Harrell Jr, Frank E. 2018. <em>Rms: Regression Modeling Strategies</em>. <a href="https://CRAN.R-project.org/package=rms" class="uri">https://CRAN.R-project.org/package=rms</a>.</p>
</div>
<div id="ref-randomForest">
<p>Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22. <a href="http://CRAN.R-project.org/doc/Rnews/" class="uri">http://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
<div id="ref-R-e1071">
<p>Meyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2017. <em>E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), Tu Wien</em>. <a href="https://CRAN.R-project.org/package=e1071" class="uri">https://CRAN.R-project.org/package=e1071</a>.</p>
</div>
<div id="ref-e1071">
<p>Meyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2019. <em>E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), Tu Wien</em>. <a href="https://CRAN.R-project.org/package=e1071" class="uri">https://CRAN.R-project.org/package=e1071</a>.</p>
</div>
<div id="ref-gbm">
<p>Ridgeway, Greg. 2017. <em>Gbm: Generalized Boosted Regression Models</em>. <a href="https://CRAN.R-project.org/package=gbm" class="uri">https://CRAN.R-project.org/package=gbm</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="doItYourselfWithPython.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="instance-level.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ema.pdf", "ema.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
