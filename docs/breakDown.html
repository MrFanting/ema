<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Break-down Plots for Additive Attributions | 解释性模型分析</title>
  <meta name="description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Break-down Plots for Additive Attributions | 解释性模型分析" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="github-repo" content="pbiecek/ema" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Break-down Plots for Additive Attributions | 解释性模型分析" />
  
  <meta name="twitter:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2020-03-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="InstanceLevelExploration.html"/>
<link rel="next" href="iBreakDown.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/ema/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><span style="font-size: large">Explanatory Model Analysis</span><br/>Explore, Explain and Examine<br/>Predictive Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#notes-to-readers"><i class="fa fa-check"></i><b>1.1</b> Notes to readers</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.2</b> The aim of the book</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.3</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.4</b> The structure of this book</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i><b>1.5</b> Terminology</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#glass-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.6</b> Glass-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.7</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#what-is-in-this-book-and-what-is-not"><i class="fa fa-check"></i><b>1.8</b> What is in this book and what is not</a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.9</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>2</b> Model Development</a><ul>
<li class="chapter" data-level="2.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPprocess"><i class="fa fa-check"></i><b>2.2</b> The Process</a></li>
<li class="chapter" data-level="2.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notation"><i class="fa fa-check"></i><b>2.3</b> Notation</a></li>
<li class="chapter" data-level="2.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#data-exploration"><i class="fa fa-check"></i><b>2.4</b> Data exploration</a></li>
<li class="chapter" data-level="2.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notationTraining"><i class="fa fa-check"></i><b>2.5</b> Model training</a></li>
<li class="chapter" data-level="2.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#model-understanding"><i class="fa fa-check"></i><b>2.6</b> Model understanding</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself with R</a><ul>
<li class="chapter" data-level="3.1" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#what-to-install"><i class="fa fa-check"></i><b>3.1</b> What to install?</a></li>
<li class="chapter" data-level="3.2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-dalex"><i class="fa fa-check"></i><b>3.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="3.3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>3.3</b> How to work with <code>archivist</code>?</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html"><i class="fa fa-check"></i><b>4</b> Do-it-yourself with Python</a></li>
<li class="chapter" data-level="5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>5</b> Data sets and models</a><ul>
<li class="chapter" data-level="5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>5.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="5.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>5.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.1.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>5.1.2</b> Logistic regression model</a></li>
<li class="chapter" data-level="5.1.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>5.1.3</b> Random forest model</a></li>
<li class="chapter" data-level="5.1.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>5.1.4</b> Gradient boosting model</a></li>
<li class="chapter" data-level="5.1.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-svm"><i class="fa fa-check"></i><b>5.1.5</b> Support Vector Machine model</a></li>
<li class="chapter" data-level="5.1.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>5.1.6</b> Model predictions</a></li>
<li class="chapter" data-level="5.1.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>5.1.7</b> Model adapters</a></li>
<li class="chapter" data-level="5.1.8" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>5.1.8</b> List of objects for the <code>titanic</code> example</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>5.2</b> Apartment prices</a><ul>
<li class="chapter" data-level="5.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>5.2.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>5.2.2</b> Linear regression model</a></li>
<li class="chapter" data-level="5.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>5.2.3</b> Random forest model</a></li>
<li class="chapter" data-level="5.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-svm"><i class="fa fa-check"></i><b>5.2.4</b> Support vector model</a></li>
<li class="chapter" data-level="5.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>5.2.5</b> Model predictions</a></li>
<li class="chapter" data-level="5.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>5.2.6</b> Model adapters</a></li>
<li class="chapter" data-level="5.2.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>5.2.7</b> List of objects for the <code>apartments</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="instance-level.html"><a href="instance-level.html"><i class="fa fa-check"></i>Instance Level</a></li>
<li class="chapter" data-level="6" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>6</b> Introduction to Instance Level Exploration</a></li>
<li class="chapter" data-level="7" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>7</b> Break-down Plots for Additive Attributions</a><ul>
<li class="chapter" data-level="7.1" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>7.2</b> Method</a><ul>
<li class="chapter" data-level="7.2.1" data-path="breakDown.html"><a href="breakDown.html#break-down-for-linear-models"><i class="fa fa-check"></i><b>7.2.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="7.2.2" data-path="breakDown.html"><a href="breakDown.html#break-down-for-a-general-case"><i class="fa fa-check"></i><b>7.2.2</b> Break-down for a general case</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>7.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.4" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.5.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-variable_attribution-function"><i class="fa fa-check"></i><b>7.5.1</b> Basic use of the <code>variable_attribution()</code> function</a></li>
<li class="chapter" data-level="7.5.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-variable_attribution-function"><i class="fa fa-check"></i><b>7.5.2</b> Advanced use of the <code>variable_attribution()</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>8</b> Break-down Plots for Interactions (iBreak-down Plots)</a><ul>
<li class="chapter" data-level="8.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>8.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>8.4</b> Pros and cons</a></li>
<li class="chapter" data-level="8.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>8.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9</b> Shapley Additive Explanations (SHAP) and Average Variable Attributions</a><ul>
<li class="chapter" data-level="9.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>9.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>10</b> Local Interpretable Model-agnostic Explanations (LIME)</a><ul>
<li class="chapter" data-level="10.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>10.2</b> Intuition</a></li>
<li class="chapter" data-level="10.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>10.3</b> Method</a><ul>
<li class="chapter" data-level="10.3.1" data-path="LIME.html"><a href="LIME.html#interpretable-data-representation"><i class="fa fa-check"></i><b>10.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="10.3.2" data-path="LIME.html"><a href="LIME.html#sampling-around-the-instance-of-interest"><i class="fa fa-check"></i><b>10.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="10.3.3" data-path="LIME.html"><a href="LIME.html#developing-the-glass-box-model"><i class="fa fa-check"></i><b>10.3.3</b> Developing the glass-box model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>10.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="10.6.1" data-path="LIME.html"><a href="LIME.html#the-lime-package"><i class="fa fa-check"></i><b>10.6.1</b> The lime package</a></li>
<li class="chapter" data-level="10.6.2" data-path="LIME.html"><a href="LIME.html#the-localmodel-package"><i class="fa fa-check"></i><b>10.6.2</b> The localModel package</a></li>
<li class="chapter" data-level="10.6.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>10.6.3</b> The iml package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>11</b> Ceteris-paribus Profiles</a><ul>
<li class="chapter" data-level="11.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>11.2</b> Intuition</a></li>
<li class="chapter" data-level="11.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>11.3</b> Method</a></li>
<li class="chapter" data-level="11.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>11.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="11.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>11.5</b> Pros and cons</a></li>
<li class="chapter" data-level="11.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>11.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="11.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-individual_profile-function"><i class="fa fa-check"></i><b>11.6.1</b> Basic use of the <code>individual_profile</code> function</a></li>
<li class="chapter" data-level="11.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-individual_profile-function"><i class="fa fa-check"></i><b>11.6.2</b> Advanced use of the <code>individual_profile</code> function</a></li>
<li class="chapter" data-level="11.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#champion-challenger-analysis"><i class="fa fa-check"></i><b>11.6.3</b> Champion-challenger analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>12</b> Ceteris-paribus Oscillations</a><ul>
<li class="chapter" data-level="12.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a></li>
<li class="chapter" data-level="12.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="12.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="12.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-variable_attribution-function-1"><i class="fa fa-check"></i><b>12.6.1</b> Basic use of the <code>variable_attribution</code> function</a></li>
<li class="chapter" data-level="12.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-variable_attribution-function-1"><i class="fa fa-check"></i><b>12.6.2</b> Advanced use of the <code>variable_attribution</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>13</b> Local Diagnostics Plots</a><ul>
<li class="chapter" data-level="13.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>13.2</b> Intuition</a></li>
<li class="chapter" data-level="13.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>13.3</b> Method</a><ul>
<li class="chapter" data-level="13.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagNeighbors"><i class="fa fa-check"></i><b>13.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="13.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>13.3.2</b> Local-fidelity plot</a></li>
<li class="chapter" data-level="13.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>13.3.3</b> Local-stability plot for neighbors</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>13.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="13.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>13.5</b> Pros and cons</a></li>
<li class="chapter" data-level="13.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>13.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>14</b> Summary of Instance-level Explainers</a><ul>
<li class="chapter" data-level="14.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>14.1</b> Number of explanatory variables in the model</a><ul>
<li class="chapter" data-level="14.1.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.2</b> Medium to large number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>14.2</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="14.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>14.3</b> Models with interactions</a></li>
<li class="chapter" data-level="14.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>14.4</b> Sparse explanations</a></li>
<li class="chapter" data-level="14.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>14.5</b> Additional uses of model exploration and explanation</a></li>
<li class="chapter" data-level="14.6" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#champion-challenger-analysis-1"><i class="fa fa-check"></i><b>14.6</b> Champion Challenger analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dataset-level.html"><a href="dataset-level.html"><i class="fa fa-check"></i>Dataset Level</a></li>
<li class="chapter" data-level="15" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>15</b> Model-level exploration</a></li>
<li class="chapter" data-level="16" data-path="modelPerformance.html"><a href="modelPerformance.html"><i class="fa fa-check"></i><b>16</b> Model Performance Measures</a><ul>
<li class="chapter" data-level="16.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntuition"><i class="fa fa-check"></i><b>16.2</b> Intuition</a></li>
<li class="chapter" data-level="16.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethod"><i class="fa fa-check"></i><b>16.3</b> Method</a><ul>
<li class="chapter" data-level="16.3.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCont"><i class="fa fa-check"></i><b>16.3.1</b> Continuous dependent variable</a></li>
<li class="chapter" data-level="16.3.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodBin"><i class="fa fa-check"></i><b>16.3.2</b> Binary dependent variable</a></li>
<li class="chapter" data-level="16.3.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCateg"><i class="fa fa-check"></i><b>16.3.3</b> Categorical dependent variable</a></li>
<li class="chapter" data-level="16.3.4" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCount"><i class="fa fa-check"></i><b>16.3.4</b> Count dependent variable</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="modelPerformance.html"><a href="modelPerformance.html#example"><i class="fa fa-check"></i><b>16.4</b> Example</a><ul>
<li class="chapter" data-level="16.4.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceApartments"><i class="fa fa-check"></i><b>16.4.1</b> Apartment prices</a></li>
<li class="chapter" data-level="16.4.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceTitanic"><i class="fa fa-check"></i><b>16.4.2</b> Titanic data</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceProsCons"><i class="fa fa-check"></i><b>16.5</b> Pros and cons</a></li>
<li class="chapter" data-level="16.6" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceR"><i class="fa fa-check"></i><b>16.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>17</b> Variable’s Importance</a><ul>
<li class="chapter" data-level="17.1" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntuition"><i class="fa fa-check"></i><b>17.2</b> Intuition</a></li>
<li class="chapter" data-level="17.3" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceMethod"><i class="fa fa-check"></i><b>17.3</b> Method</a></li>
<li class="chapter" data-level="17.4" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceTitanic"><i class="fa fa-check"></i><b>17.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="17.5" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceProsCons"><i class="fa fa-check"></i><b>17.5</b> Pros and cons</a></li>
<li class="chapter" data-level="17.6" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceR"><i class="fa fa-check"></i><b>17.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="17.6.1" data-path="featureImportance.html"><a href="featureImportance.html#models-comparison"><i class="fa fa-check"></i><b>17.6.1</b> Models comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>18</b> Partial dependence profiles</a><ul>
<li class="chapter" data-level="18.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntuition"><i class="fa fa-check"></i><b>18.2</b> Intuition</a></li>
<li class="chapter" data-level="18.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPMethod"><i class="fa fa-check"></i><b>18.3</b> Method</a><ul>
<li class="chapter" data-level="18.3.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPs"><i class="fa fa-check"></i><b>18.3.1</b> Partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clusteredPDPs"><i class="fa fa-check"></i><b>18.3.2</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#groupedPDPs"><i class="fa fa-check"></i><b>18.3.3</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastivePDPs"><i class="fa fa-check"></i><b>18.3.4</b> Contrastive partial dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPExample"><i class="fa fa-check"></i><b>18.4</b> Example: Apartments data</a><ul>
<li class="chapter" data-level="18.4.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.1</b> Partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.2</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.3</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.4</b> Contrastive partial dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPProsCons"><i class="fa fa-check"></i><b>18.5</b> Pros and cons</a></li>
<li class="chapter" data-level="18.6" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPR"><i class="fa fa-check"></i><b>18.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="18.6.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.1</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.6.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.2</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.6.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.3</b> Contrastive partial dependence profiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>19</b> Local-dependence and Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="19.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntro"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntuition"><i class="fa fa-check"></i><b>19.2</b> Intuition</a></li>
<li class="chapter" data-level="19.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPMethod"><i class="fa fa-check"></i><b>19.3</b> Method</a><ul>
<li class="chapter" data-level="19.3.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#local-dependence-profile"><i class="fa fa-check"></i><b>19.3.1</b> Local-dependence profile</a></li>
<li class="chapter" data-level="19.3.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#accumulated-local-profile"><i class="fa fa-check"></i><b>19.3.2</b> Accumulated local profile</a></li>
<li class="chapter" data-level="19.3.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#summaryFeatureEffects"><i class="fa fa-check"></i><b>19.3.3</b> An illustrative example</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#CDPExample"><i class="fa fa-check"></i><b>19.4</b> Example: Apartments data</a></li>
<li class="chapter" data-level="19.5" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPProsCons"><i class="fa fa-check"></i><b>19.5</b> Pros and cons</a></li>
<li class="chapter" data-level="19.6" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPR"><i class="fa fa-check"></i><b>19.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>20</b> Residual Diagnostics</a><ul>
<li class="chapter" data-level="20.1" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntroResidualDiagnostic"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntuitionResidualDiagnostic"><i class="fa fa-check"></i><b>20.2</b> Intuition</a></li>
<li class="chapter" data-level="20.3" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#MethodResidualDiagnostic"><i class="fa fa-check"></i><b>20.3</b> Method</a></li>
<li class="chapter" data-level="20.4" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ExampleResidualDiagnostic"><i class="fa fa-check"></i><b>20.4</b> Example: Apartments data</a></li>
<li class="chapter" data-level="20.5" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ProsConsResidualDiagnostic"><i class="fa fa-check"></i><b>20.5</b> Pros and cons</a></li>
<li class="chapter" data-level="20.6" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#RcodeResidualDiagnostic"><i class="fa fa-check"></i><b>20.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="use-cases.html"><a href="use-cases.html"><i class="fa fa-check"></i>Use Cases</a></li>
<li class="chapter" data-level="21" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html"><i class="fa fa-check"></i><b>21</b> FIFA 19</a><ul>
<li class="chapter" data-level="21.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#introduction-1"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-preparation"><i class="fa fa-check"></i><b>21.2</b> Data preparation</a></li>
<li class="chapter" data-level="21.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-understanding"><i class="fa fa-check"></i><b>21.3</b> Data understanding</a></li>
<li class="chapter" data-level="21.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-assembly"><i class="fa fa-check"></i><b>21.4</b> Model assembly</a></li>
<li class="chapter" data-level="21.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-audit"><i class="fa fa-check"></i><b>21.5</b> Model audit</a></li>
<li class="chapter" data-level="21.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-understanding-1"><i class="fa fa-check"></i><b>21.6</b> Model understanding</a></li>
<li class="chapter" data-level="21.7" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#instance-understanding"><i class="fa fa-check"></i><b>21.7</b> Instance understanding</a></li>
<li class="chapter" data-level="21.8" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#cr7"><i class="fa fa-check"></i><b>21.8</b> CR7</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/ModelOriented/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">解释性模型分析</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="breakDown" class="section level1">
<h1><span class="header-section-number">7</span> Break-down Plots for Additive Attributions</h1>
<p>Probably the most common question related to the explanation of model prediction for a single instance is: <em>which variables contributed to this result the most?</em></p>
<p>Unfortunately, there is no silver bullet. Fortunately, there are some bullets. In this chapter we introduce Break-down (BD) plots, which offer a solution to this problem. Next two chapters are related to extensions of BD plot. Finally, Chapter <a href="LIME.html#LIME">10</a> offer a different approach to this problem. The goal for BD plots is to show “variables attributions” i.e., the decomposition of the model prediction among explanatory variables.</p>
<div id="BDIntuition" class="section level2">
<h2><span class="header-section-number">7.1</span> Intuition</h2>
<p>The underlying idea is to calculate contribution of an explanatory variable <span class="math inline">\(x^i\)</span> to model’s prediction <span class="math inline">\(f(x)\)</span> as a shift in the expected model response after conditioning on other variables.</p>
<p>This idea is illustrated in Figure <a href="breakDown.html#fig:BDPrice4">7.1</a>. Consider an example related to the prediction for the random-forest model <code>model_rf_v6</code> for Titanic data (see Section <a href="dataSetsIntro.html#model-titanic-rf">5.1.3</a>). We are interested in chances of survival for <code>johny_d</code> - an 8-years old passenger from first class. Panel A shows distribution of model predictions for all 2207 instances from dataset <span class="math inline">\(X\)</span>. The row <code>all data</code> shows the vioplot of the predictions for the entire dataset. The red dot indicates the average and it is an estimate of the expected model prediction <span class="math inline">\(E_X[f(X)]\)</span> over the distribution of all explanatory variables. In this example the average model response is 23.5%.</p>
<p>To evaluate the contribution of the explanatory variables to the particular instance prediction, we trace changes in model predictions when fixing the values of consecutive variables. For instance, the row <code>class=1st</code> in Panel A of Figure <a href="breakDown.html#fig:BDPrice4">7.1</a> presents the distribution of the predictions obtained when the value of the <code>class</code> variable has been fixed to the <code>1st</code> class. Again, the red dot indicates the average of the predictions. The next row <code>age=8</code> shows the distribution and the average predictions with the value of variable <code>class</code> set to <code>1st</code> and <code>age</code> set to <code>8</code>, and so on. With this procedure after <span class="math inline">\(p\)</span> steps every row in <span class="math inline">\(X\)</span> will be filled up with variable values of <code>johny_d</code>. All predictions for these rows will be equal, so the last row in the Figure corresponds to the prediction for <code>model response</code> for <code>johny_d</code>.</p>
<p>The thin black lines in Panel A show how the individual prediction for a single person changes after the value of the <span class="math inline">\(j\)</span>-th variable has been replaced by the value indicated in the name of the row.</p>
<p>As we see from lines between first and the second row, the conditioning over <code>class=1st</code> has different effect on different instances. For some the model prediction has not changes (probably these passengers were already in the 1st class). For some the model prediction increase (probably they were in 2nd or 3rd class) while for other passenger the model prediction decreases (probably these were desk crew members).</p>
<p>Eventually, however, we may be interested in the average predictions, as indicated in Panel B of Figure <a href="breakDown.html#fig:BDPrice4">7.1</a>, or even only in the changes of the averages, as shown in Panel C. In Panel C, positive changes are presented with green bars, while negative differences are marked with red bar. The changes sum up to the final prediction, which is illustrated by the violet bar at the bottom of Panel C.</p>
<p>What can be learned from Break-down plots? In this case we have concise summary of effects of particular variables on expected model response. First, we see that average model response is 23.5 percent. These are odds of survival averaged over all people on Titanic. Note that it is not the fraction of people that survived, but the average model response, so for different models one can get different averages. The model prediction for Johny D is 42.2 percent. It is much higher than an average prediction. Two variables that influence this prediction the most are class (=1st) and age (=8). Setting these two variables increase average model prediction by 33.5 percent points. Values in all other variables have rather negative effect. Low fare and being a male diminish odds of survival predicted by the model. Other variables do not change model predictions that much. Note that value of variable attribution depends on the value not only a variable itself. In this example the <code>embarked = Southampton</code> has small effect on average model prediction. It may be because the variable <code>embarked</code> is not important or it is possible that variable <code>embarked</code> is important but <code>Southampton</code> has an average effect out of all other possible values of the <code>embarked</code> variable.</p>
<div class="figure" style="text-align: center"><span id="fig:BDPrice4"></span>
<img src="figure/break_down_distr.png" alt="Break-down plots show how the contribution of individual explanatory variables change the average model prediction to the prediction for a single instance (observation). Panel A) The first row shows the distribution and the average (red dot) of model predictions for all data. The next rows show the distribution and the average of the predictions when fixing values of subsequent explanatory variables. The last row shows the prediction for a particular instance of interest. B) Red dots indicate the average predictions from Panel A. C) The green and red bars indicate, respectively, positive and negative changes in the average predictions (variable contributions). " width="70%" />
<p class="caption">
Figure 7.1: Break-down plots show how the contribution of individual explanatory variables change the average model prediction to the prediction for a single instance (observation). Panel A) The first row shows the distribution and the average (red dot) of model predictions for all data. The next rows show the distribution and the average of the predictions when fixing values of subsequent explanatory variables. The last row shows the prediction for a particular instance of interest. B) Red dots indicate the average predictions from Panel A. C) The green and red bars indicate, respectively, positive and negative changes in the average predictions (variable contributions).
</p>
</div>
</div>
<div id="BDMethod" class="section level2">
<h2><span class="header-section-number">7.2</span> Method</h2>
<p>First, let’s see how variable attribution works for linear models. Because of the simple and additive structure of linear models it will be easier to build some intuitions.</p>
<div id="break-down-for-linear-models" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Break-down for linear models</h3>
<p>Assume a classical linear model for response <span class="math inline">\(y\)</span> with <span class="math inline">\(p\)</span> explanatory variables collected in the vector <span class="math inline">\(X = (X^1, X^2, \ldots, X^p)\)</span> and coefficients <span class="math inline">\(\beta = (\beta^0, \beta^1, .., \beta^p)\)</span>, where <span class="math inline">\(\beta^0\)</span> is the intercept. The prediction for <span class="math inline">\(y\)</span> at point <span class="math inline">\(x=(x^1, x^2, \ldots, x^p)\)</span> is given by the expected value of <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\(X=x\)</span>. For a linear model, the expected value is given by the following linear combination:</p>
<p><span class="math display">\[
E_Y(y | x) = f(x) = \beta^0 + x^1 \beta^1 + \ldots + x^p \beta^p.
\]</span></p>
<p>Now assume that we selected a single point from the input space <span class="math inline">\(x_* \in \mathcal R^p\)</span>. We are interested in the contribution of the <span class="math inline">\(i\)</span>-th explanatory variable to model prediction <span class="math inline">\(f(x_*)\)</span> for a single observation described by <span class="math inline">\(x_*\)</span>. Because of additive structure of the linear model we expect that this contribution will be somehow linked to <span class="math inline">\(x_*^i\beta^i\)</span>, because the <span class="math inline">\(i\)</span>-th variable occurs only in this term. As it will become clear in the sequel, it is easier to interpret the variable’s contribution if <span class="math inline">\(x^i\)</span> is centered by subtracting a constant <span class="math inline">\(\hat x^i\)</span> (usually, the mean of <span class="math inline">\(x^i\)</span>). This leads the following, proposition for the variable attribution:</p>
<span class="math display" id="eq:singleBreakDownContribution">\[\begin{equation}
v(i, x_*) = \beta^i (x^i_* - \bar x^i).
\tag{7.1}
\end{equation}\]</span>
<p>Here <span class="math inline">\(v(x_*, i)\)</span> is the contribution of the <span class="math inline">\(i\)</span>-th explanatory variable to the prediction of model <span class="math inline">\(f()\)</span> at point <span class="math inline">\(x_*\)</span>. Assume that <span class="math inline">\(E_Y(y | x_*) \approx f(x_*)\)</span>, where <span class="math inline">\(f(x_*)\)</span> is the value of the model at <span class="math inline">\(x_*\)</span>. A possible approach to define <span class="math inline">\(v(x_*, i)\)</span> is to measure how much the expected model response changes after conditioning on <span class="math inline">\(x^i_*\)</span>:</p>
<span class="math display">\[\begin{equation}
v(i, x_*) = E_Y(y | x_*) - E_{X^i}\{E_Y[y | (x^1_*,\ldots,x^{i-1}_*,X^i,x^{i+1}_*,x^p_*)]\}\approx f(x_*) - E_{X^i}[f(x^{-i}_*)],
\end{equation}\]</span>
<p>where <span class="math inline">\(x^{-i}_*\)</span> indicates that variable <span class="math inline">\(X^i\)</span> in vector <span class="math inline">\(x_*\)</span> is treated as random. For the classical linear model, if the explanatory variables are independent, <span class="math inline">\(v(x_*, i)\)</span> can be expressed as follows:</p>
<span class="math display">\[\begin{equation}
v(i, x_*) = f(x_*) - E_{X^i}[f(x^{-i}_*)] = \beta^0 + x^1_* \beta^1 + \ldots + x^p_* \beta^p - E_{X^i}[\beta^0 + x^1_* \beta^1 + \ldots +\beta^i X^i \ldots + x^p_* \beta^p] = ...
\end{equation}\begin{equation}
... = \beta^i[x_*^i - E_{X^i}(X^i)].
\end{equation}\]</span>
<p>In practice, given a dataset, the expected value of <span class="math inline">\(X^i\)</span> can be estimated by the sample mean <span class="math inline">\(\bar x^i\)</span>. This leads to</p>
<span class="math display">\[\begin{equation}
v(i, x_*) = \beta^i (x_*^i - \bar x^i).
\end{equation}\]</span>
Note that the linear-model-based prediction may be re-expressed in the following way: <span class="math display">\[
f(x_*) = [\beta^0 + \bar x^1 \beta^1 + ... + \bar x^p \beta^p] + [(x^1_* - \bar x^1) \beta^1 + ... + (x^p_* - \bar x^p) \beta^p] 
\]</span>
<span class="math display" id="eq:singleBreakDownResult">\[\begin{equation}
 \equiv [average \ prediction] + \sum_{j=1}^p v(i, x_*).
\tag{7.2}
\end{equation}\]</span>
<p>Thus, the contributions of the explanatory variables <span class="math inline">\(v(i, x_*)\)</span> sum up to the difference between the model prediction for <span class="math inline">\(x_*\)</span> and the average model prediction.</p>
<p><strong>NOTE for careful readers</strong></p>
<p>Obviously, sample mean <span class="math inline">\(\bar x^i\)</span> is an estimator of the expected value <span class="math inline">\(E_{X^i}(X^i)\)</span>, calculated using a training data. For the sake of simplicity we do not emphasize these differences in the notation. Also, we ignore the fact that, in practice, we never know the true model coefficients and we work with an estimated coefficients.</p>
</div>
<div id="break-down-for-a-general-case" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Break-down for a general case</h3>
<p>Note that the method is similar to the <code>EXPLAIN</code> algorithm introduced in ,,Explaining Classifications for Individual Instances’’ <span class="citation">(Robnik-Šikonja and Kononenko <a href="#ref-explainPaper">2008</a>)</span> and implemented in the <code>ExplainPrediction</code> package <span class="citation">(Robnik-Šikonja <a href="#ref-explainPackage">2018</a>)</span>.</p>
<p>Again, let <span class="math inline">\(v(j, x_*)\)</span> denote the variable-importance measure of the <span class="math inline">\(j\)</span>-th variable and instance <span class="math inline">\(x_*\)</span>, i.e., the contribution of the <span class="math inline">\(j\)</span>-th variable to prediction at <span class="math inline">\(x_*\)</span>.</p>
<p>We would like the sum of the <span class="math inline">\(v(j, x_*)\)</span> for all explanatory variables to be equal to the instance prediction (property called <em>local accuracy</em>), so that</p>
<span class="math display" id="eq:generalBreakDownLocalAccuracy">\[\begin{equation}
f(x_*) = v_0 + \sum_{j=1}^p v(j, x_*),
\tag{7.3}
\end{equation}\]</span>
<p>where <span class="math inline">\(v_0\)</span> denotes the average model response. If we rewrite the equation above as follows:</p>
<span class="math display">\[\begin{equation}
E_X[f(X)|X^1 = x^1_*, \ldots, X^p = x^p_*] = E_X[f(X)] + \sum_{j=1}^p v(j, x_*),
\end{equation}\]</span>
<p>then a natural proposal for <span class="math inline">\(v(j, x_*)\)</span> is</p>
<span class="math display" id="eq:generalBreakDownProposition">\[\begin{equation}
v(j, x_*) = E_X[f(X) | X^1 = x^1_*, \ldots, X^j = x^j_*] - E_X[f(X) | X^1 = x^1_*, \ldots, X^{j-1} = x^{j-1}_*]. 
\tag{7.4}
\end{equation}\]</span>
<p>In other words, the contribution of the <span class="math inline">\(j\)</span>-th variable is the difference between the expected value of the prediction conditional on setting the values of the first <span class="math inline">\(j\)</span> variables equal to their values in <span class="math inline">\(x_*\)</span> and the expected value conditional on setting the values of the first <span class="math inline">\(j-1\)</span> variables equal to their values in <span class="math inline">\(x_*\)</span>.</p>
<p>Note that the definition does imply the dependence of <span class="math inline">\(v(j, x_*)\)</span> on the order of the explanatory variables that is reflected in their indices.</p>
<p>To consider more general cases, let <span class="math inline">\(J\)</span> denote a subset of <span class="math inline">\(K\)</span> (<span class="math inline">\(K\leq p\)</span>) indices from <span class="math inline">\(\{1,2,\ldots,p\}\)</span>, i.e., <span class="math inline">\(J=\{j_1,j_2,\ldots,j_K\}\)</span> where each <span class="math inline">\(j_k \in \{1,2,\ldots,p\}\)</span>. Furthermore, let <span class="math inline">\(L\)</span> denote another subset of <span class="math inline">\(M\)</span> (<span class="math inline">\(M \leq p-K\)</span>) indices from <span class="math inline">\({1,2,\ldots,p}\)</span> distinct from <span class="math inline">\(J\)</span>. That is, <span class="math inline">\(L=\{l_1,l_2,\ldots,l_M\}\)</span> where each <span class="math inline">\(l_m \in \{1,2,\ldots,p\}\)</span> and <span class="math inline">\(J \cap L = \emptyset\)</span>. Let us define now</p>
<span class="math display">\[\begin{eqnarray}
\Delta^{L|J}(x_*) &amp;\equiv&amp; E_X[f(X) | X^{l_1} = x_*^{l_1},\ldots,X^{l_M} = x_*^{l_M},X^{j_1} = x_*^{j_1},\ldots,X^{j_K} = x_*^{j_K}]\\
&amp;-&amp; E_X[f(X) | X^{j_1} = x_*^{j_1},\ldots,X^{j_K} = x_*^{j_K}].
\end{eqnarray}\]</span>
<p>In other words, <span class="math inline">\(\Delta^{L|J}(x_*)\)</span> is the change between the expected model prediction when setting the values of the explanatory variables with indices from the set <span class="math inline">\(J \cup L\)</span> equal to their values in <span class="math inline">\(x_*\)</span> and the expected prediction conditional on setting the values of the explanatory variables with indices from the set <span class="math inline">\(J\)</span> equal to their values in <span class="math inline">\(x_*\)</span>.</p>
In particular, for the <span class="math inline">\(l\)</span>-th explanatory variable, let
<span class="math display">\[\begin{eqnarray}
\Delta^{l|J}(x_*) \equiv \Delta^{\{l\}|J}(x_*) &amp;=&amp; E_X[f(X) | X^{j_1} = x_*^{j_1},\ldots,X^{j_K} = x_*^{j_K}, X^{l} = x_*^{l}]\\
&amp;-&amp; E_X[f(X) | X^{j_1} = x_*^{j_1},\ldots,X^{j_K} = x_*^{j_K}].
\end{eqnarray}\]</span>
<p>Thus, <span class="math inline">\(\Delta^{l|J}\)</span> is the change between the expected prediction when setting the values of the explanatory variables with indices from the set <span class="math inline">\(J \cup \{l\}\)</span> equal to their values in <span class="math inline">\(x_*\)</span> and the expected prediction conditional on setting the values of the explanatory variables with indices from the set <span class="math inline">\(J\)</span> equal to their values in <span class="math inline">\(x_*\)</span>. Note that, if <span class="math inline">\(J=\emptyset\)</span>, then</p>
<span class="math display" id="eq:deltaBreakDownAdditive">\[\begin{equation}
\Delta^{l|\emptyset}(x_*) = E_X[f(X) | X^{l} = x_*^{l}] - E_X[f(X)].
\tag{7.5}
\end{equation}\]</span>
<p>It follows that</p>
<span class="math display">\[\begin{equation}
v(j, x_*) = \Delta^{j|\{1,  ..., j-1\}}(x_*).
\end{equation}\]</span>
<p>Unfortunately, for non-additive models (that include interactions), the value of so-defined variable-importance measure depends on the order, in which one sets the values of the explanatory variables. Figure <a href="breakDown.html#fig:ordering">7.2</a> presents an example. We fit the random forest model to predict whether a passenger survived or not, then, we explain the model’s prediction for a 2-year old boy that travels in the second class. The model predicts survival with a probability of <span class="math inline">\(0.964\)</span>. We would like to explain this probability and understand which factors drive this prediction. Consider two explanations.</p>
<p><strong>Explanation 1:</strong> The passenger is a boy, and this feature alone decreases the chances of survival. He traveled in the second class which also lower survival probability. Yet, he is very young, which makes odds higher. The reasoning behind such an explanation on this level is that most passengers in the second class are adults, therefore a kid from the second class has high chances of survival.</p>
<p><strong>Explanation 2:</strong> The passenger is a boy, and this feature alone decreases survival probability. However, he is very young, therefore odds are higher than adult men. Explanation in the last step says that he traveled in the second class, which make odds of survival even more higher. The interpretation of this explanation is that most kids are from the third class and being a child in the second class should increase chances of survival.</p>
<p>Note that the effect of <em>the second class</em> is negative in explanations for scenario 1 but positive in explanations for scenario 2.</p>
<div class="figure" style="text-align: center"><span id="fig:ordering"></span>
<img src="figure/ordering.png" alt="An illustration of the order-dependence of the variable-contribution values. Two *Break-down* explanations for the same observation from Titanic data set. The underlying model is a random forest. Scenarios differ due to the order of variables in *Break-down* algorithm. Last bar indicates the difference between the model's prediction for a particular observation and an average model prediction. Other bars show contributions of variables. Red color means a negative effect on the survival probability, while green color means a positive effect. Order of variables on the y-axis corresponds to their sequence used in *Break-down* algorithm." width="50%" />
<p class="caption">
Figure 7.2: An illustration of the order-dependence of the variable-contribution values. Two <em>Break-down</em> explanations for the same observation from Titanic data set. The underlying model is a random forest. Scenarios differ due to the order of variables in <em>Break-down</em> algorithm. Last bar indicates the difference between the model’s prediction for a particular observation and an average model prediction. Other bars show contributions of variables. Red color means a negative effect on the survival probability, while green color means a positive effect. Order of variables on the y-axis corresponds to their sequence used in <em>Break-down</em> algorithm.
</p>
</div>
<p>There are three approaches that can be used to address the issue of the dependence of <span class="math inline">\(v(j, x_*)\)</span> on the order, in which one sets the values of the explanatory variables.</p>
<p>In the first approach, one chooses an ordering according to which the variables with the largest contributions are selected first. In this chapter, we describe a heuristic behind this approach.</p>
<p>In the second approach, one identifies the interactions that cause a difference in variable-importance measure for different orderings and focuses on those interactions. This approach is discussed in Chapter <a href="iBreakDown.html#iBreakDown">8</a>.</p>
<p>Finally, one can calculate an average value of the variance-importance measure across all possible orderings. This approach is presented in Chapter <a href="shapley.html#shapley">9</a>.</p>
<p>To choose an ordering according to which the variables with the largest contributions are selected first, one can apply a two-step procedure. In the first step, the explanatory variables are ordered. In the second step, the conditioning is applied according to the chosen order of variables.</p>
<p>In the first step, the ordering is chosen based on the decreasing value of the scores equal to <span class="math inline">\(|\Delta^{k|\emptyset}|\)</span>. Note that the absolute value is needed, because the variable contributions can be positive or negative. In the second step, the variable-importance measure for the <span class="math inline">\(j\)</span>-th variable is calculated as <span class="math display">\[
v(j, x_*) = \Delta ^{j|J},
\]</span> where <span class="math display">\[
J = \{k: |\Delta^{k|\emptyset}| &lt; |\Delta^{j|\emptyset}|\},
\]</span> that is, <span class="math inline">\(J\)</span> is the set of indices of explanatory variables that have scores <span class="math inline">\(|\Delta^{k|\emptyset}|\)</span> smaller than the corresponding score for variable <span class="math inline">\(j\)</span>.</p>
<p>The time complexity of each of the two steps of the procedure is <span class="math inline">\(O(p)\)</span>, where <span class="math inline">\(p\)</span> is the number of explanatory variables.</p>
</div>
</div>
<div id="BDExample" class="section level2">
<h2><span class="header-section-number">7.3</span> Example: Titanic data</h2>
<p>Let us consider the random-forest model <code>titanic_rf_v6</code> (see Section <a href="dataSetsIntro.html#model-titanic-rf">5.1.3</a> and passenger <code>johny_d</code> (see Section <a href="dataSetsIntro.html#predictions-titanic">5.1.6</a>) as the instance of interest in the Titanic data.</p>
<p>The average of model predictions for all passengers is equal to <span class="math inline">\(v_0 = 0.2353095\)</span>. Table <a href="breakDown.html#tab:titanicBreakDownDeltas">7.1</a> presents the scores <span class="math inline">\(|\Delta^{j|\emptyset}|\)</span> and the expected values <span class="math inline">\(E[f(X | X^j = x^j_*)]\)</span>. Note that <span class="math inline">\(\Delta^{j|\emptyset}=E[f(X) | X^j = x^j_*]-v_0\)</span> and, since for all variables <span class="math inline">\(E[f(X) | X^j = x^j_*]&gt;v_0\)</span>, we have got <span class="math inline">\(E[f(X | X^j = x^j_*)]=|\Delta^{j|\emptyset}|+v_0\)</span>.</p>
<table>
<caption><span id="tab:titanicBreakDownDeltas">Table 7.1: </span> Expected values <span class="math inline">\(E[f(X) | X^j = x^j_*]\)</span> and scores <span class="math inline">\(|\Delta^{j|\emptyset}|\)</span> for the random-forest model <code>titanic_rf_v6</code> for the Titanic data and <code>johny_d</code>. The scores are sorted in the decreasing order.</caption>
<thead>
<tr class="header">
<th align="left">variable <span class="math inline">\(j\)</span></th>
<th align="right">$E[f(X)</th>
<th align="right">X^j = x^j_*]$</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">age</td>
<td align="right">0.7407795</td>
<td align="right">0.5051210</td>
</tr>
<tr class="even">
<td align="left">class</td>
<td align="right">0.6561034</td>
<td align="right">0.4204449</td>
</tr>
<tr class="odd">
<td align="left">fare</td>
<td align="right">0.6141968</td>
<td align="right">0.3785383</td>
</tr>
<tr class="even">
<td align="left">sibsp</td>
<td align="right">0.4786182</td>
<td align="right">0.2429597</td>
</tr>
<tr class="odd">
<td align="left">parch</td>
<td align="right">0.4679240</td>
<td align="right">0.2322655</td>
</tr>
<tr class="even">
<td align="left">embarked</td>
<td align="right">0.4602620</td>
<td align="right">0.2246035</td>
</tr>
<tr class="odd">
<td align="left">gender</td>
<td align="right">0.3459458</td>
<td align="right">0.1102873</td>
</tr>
</tbody>
</table>
<p>Based on the ordering defined by the scores <span class="math inline">\(|\Delta^{j|\emptyset}|\)</span> from Table <a href="breakDown.html#tab:titanicBreakDownDeltas">7.1</a>, we can compute the variable-importance measures based on the sequential contributions <span class="math inline">\(\Delta^{j|J}\)</span>. The computed values are presented in Table <a href="breakDown.html#tab:titanicBreakDownDeltasConseq">7.2</a>.</p>
<table>
<caption><span id="tab:titanicBreakDownDeltasConseq">Table 7.2: </span> Variable-importance measures <span class="math inline">\(\Delta^{j|\{1,\ldots,j\}}\)</span> for the random-forest model <code>titanic_rf_v6</code> for the Titanic data and <code>johny_d</code> computed by using the ordering of variables defined in Table <a href="breakDown.html#tab:titanicBreakDownDeltas">7.1</a>.</caption>
<thead>
<tr class="header">
<th align="left">variable <span class="math inline">\(j\)</span></th>
<th align="right">$E[f(X)</th>
<th align="right">X^{{1,,j}} = x^{{1,,j}}_*)]$</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">0.2353095</td>
<td align="right">0.2353095</td>
</tr>
<tr class="even">
<td align="left">age = 8</td>
<td align="right">0.5051210</td>
<td align="right">0.2698115</td>
</tr>
<tr class="odd">
<td align="left">class = 1st</td>
<td align="right">0.5906969</td>
<td align="right">0.0855759</td>
</tr>
<tr class="even">
<td align="left">fare = 72</td>
<td align="right">0.5443561</td>
<td align="right">-0.0463407</td>
</tr>
<tr class="odd">
<td align="left">gender = male</td>
<td align="right">0.4611518</td>
<td align="right">-0.0832043</td>
</tr>
<tr class="even">
<td align="left">embarked = Southampton</td>
<td align="right">0.4584422</td>
<td align="right">-0.0027096</td>
</tr>
<tr class="odd">
<td align="left">sibsp = 0</td>
<td align="right">0.4523398</td>
<td align="right">-0.0061024</td>
</tr>
<tr class="even">
<td align="left">parch = 0</td>
<td align="right">0.4220000</td>
<td align="right">-0.0303398</td>
</tr>
<tr class="odd">
<td align="left">prediction</td>
<td align="right">0.4220000</td>
<td align="right">0.4220000</td>
</tr>
</tbody>
</table>
<p>Results from Table <a href="breakDown.html#tab:titanicBreakDownDeltasConseq">7.2</a> are presented as a waterfall plot in Figure <a href="breakDown.html#fig:BDjohnyExample">7.3</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:BDjohnyExample"></span>
<img src="ema_files/figure-html/BDjohnyExample-1.png" alt="Break-down plot for the titanic_rf_v6 model and johny_d for the Titanic data." width="70%" />
<p class="caption">
Figure 7.3: Break-down plot for the <code>titanic_rf_v6</code> model and <code>johny_d</code> for the Titanic data.
</p>
</div>
</div>
<div id="BDProsCons" class="section level2">
<h2><span class="header-section-number">7.4</span> Pros and cons</h2>
<p>Break-down plots offer a model-agnostic approach that can be applied to any predictive model that returns a single number for a single instance. The approach offers several advantages. The plots are easy to understand. They are compact; results for many variables may be presented in a small space. The approach reduces to an intuitive interpretation for the generalized-linear models. Numerical complexity of the Break-down algorithm is linear in the number of explanatory variables.</p>
<p>Break-down plots for non-additive models may be misleading, as they show only the additive contributions. An important issue is the choice of the ordering of the explanatory variables that is used in the calculation of the variable-importance measures. Also, for models with a large number of variables, the Break-down plot may be complex and include many variables with small contributions to the instance prediction.</p>
</div>
<div id="BDR" class="section level2">
<h2><span class="header-section-number">7.5</span> Code snippets for R</h2>
<p>In this section, we use an <code>DALEX::variable_attribution()</code> function which is a wrapper for <code>iBreakDown</code> R package <span class="citation">(Gosiewska and Biecek <a href="#ref-iBreakDownRPackage">2019</a><a href="#ref-iBreakDownRPackage">a</a>)</span>. The package covers all methods presented in this chapter. It is available on CRAN and GitHub.</p>
<p>For illustration purposes, we use the <code>titanic_rf_v6</code> random-forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-titanic-rf">5.1.3</a>. Recall that it is developed to predict the probability of survival from sinking of Titanic. Instance-level explanations are calculated for a single observation: <code>henry</code> - a 47-year-old passenger that travelled in the 1st class.</p>
<p><code>DALEX</code> explainers for the model and the <code>henry</code> data are retrieved via <code>archivist</code> hooks as listed in Section <a href="dataSetsIntro.html#ListOfModelsTitanic">5.1.8</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)
explain_rf_v6 &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/6ed54&quot;</span>)

<span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)
henry &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/a6538&quot;</span>)
henry</code></pre></div>
<pre><code>##   class gender age sibsp parch fare  embarked
## 1   1st   male  47     0     0   25 Cherbourg</code></pre>
<div id="basic-use-of-the-variable_attribution-function" class="section level3">
<h3><span class="header-section-number">7.5.1</span> Basic use of the <code>variable_attribution()</code> function</h3>
<p>The <code>DALEX::variable_attribution()</code> function calculates the variable-importance measures for a selected model and the instance of interest. The result of applying the <code>variable_attribution()</code> function is a data frame containing the calculated measures. In the simplest call, the function requires only three arguments: the model explainer, the data frame for the instance of interest and the method for calculation of variable attribution, here <code>break_down</code>. The call below essentially re-creates the variable-importance values (<span class="math inline">\(\Delta^{j|\{1,\ldots,j\}}\)</span>) presented in Table <a href="breakDown.html#tab:titanicBreakDownDeltasConseq">7.2</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bd_rf &lt;-<span class="st"> </span><span class="kw">variable_attribution</span>(explain_rf_v6,
                 <span class="dt">new_observation =</span> henry,
                 <span class="dt">type =</span> <span class="st">&quot;break_down&quot;</span>)</code></pre></div>
<p>Applying the generic <code>plot()</code> function to the object resulting from the application of the <code>variable_attribution()</code> function creates a BD plot. In this case, it is the plot from Figure <a href="breakDown.html#fig:BDhenryExample">7.4</a>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(bd_rf) </code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BDhenryExample"></span>
<img src="ema_files/figure-html/BDhenryExample-1.png" alt="Generic plot() function for the BreakDown method calculated for henry." width="70%" />
<p class="caption">
Figure 7.4: Generic plot() function for the BreakDown method calculated for <code>henry</code>.
</p>
</div>
<p>Now we can compare contributions calculated for <code>johny_d</code> presented in Figure <a href="breakDown.html#fig:BDjohnyExample">7.3</a> with contributions calculated for <code>henry</code> presented in <a href="breakDown.html#fig:BDhenryExample">7.4</a>. Both explanations refer to the same model <code>model_rf_v6</code>. In both cases the <code>class=1st</code> increases chances of survival. For <code>johny_d</code> young age increases chances of survival while for <code>henry</code> the <code>age=47</code> decreases chances of survival.</p>
</div>
<div id="advanced-use-of-the-variable_attribution-function" class="section level3">
<h3><span class="header-section-number">7.5.2</span> Advanced use of the <code>variable_attribution()</code> function</h3>
<p>The function <code>variable_attribution()</code> allows more arguments. The most commonly used are:</p>
<ul>
<li><code>x</code> - a wrapper over a model created with function <code>DALEX::explain()</code>,</li>
<li><code>new_observation</code> - an observation to be explained is should be a data frame with structure that matches the training data,</li>
<li><code>order</code> - a vector of characters (column names) or integers (column indexes) that specify order of explanatory variables that is used for computing the variable-importance measures. If not specified (default), then a one-step heuristic is used to determine the order,</li>
<li><code>keep_distributions</code> - a logical value; if <code>TRUE</code>, then additional diagnostic information about conditional distributions is stored in the resulting object and can be plotted with the generic <code>plot()</code> function.</li>
</ul>
<p>In what follows we illustrate the use of the arguments.</p>
<p>First, we will specify the ordering of the explanatory variables. Toward this end we can use integer indexes or variable names. The latter option is prerferable in most cases because of transparency. Additionally, to reduce clutter in the plot, we set <code>max_features = 3</code> argument in the <code>plot()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bd_rf_order &lt;-<span class="st"> </span><span class="kw">variable_attribution</span>(explain_rf_v6,
         <span class="dt">new_observation =</span> henry, <span class="dt">type =</span> <span class="st">&quot;break_down&quot;</span>,
         <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;class&quot;</span>, <span class="st">&quot;age&quot;</span>, <span class="st">&quot;gender&quot;</span>, <span class="st">&quot;fare&quot;</span>, <span class="st">&quot;parch&quot;</span>, 
                           <span class="st">&quot;sibsp&quot;</span>, <span class="st">&quot;embarked&quot;</span>))

<span class="kw">plot</span>(bd_rf_order, <span class="dt">max_features =</span> <span class="dv">3</span>) </code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-27"></span>
<img src="ema_files/figure-html/unnamed-chunk-27-1.png" alt="Break Down plot for top three variables." width="70%" />
<p class="caption">
Figure 7.5: Break Down plot for top three variables.
</p>
</div>
<p>We can use the<code>keep_distributions = TRUE</code> argument to enrich the resulting object with additional information about conditional distributions. Subsequently, we can apply the <code>plot_distributions = TRUE</code> argument in the <code>plot()</code> function to present the distributions as violin plots. Red dots in the plots indicate the average model predictions. Thin black lines between violin plots correspond to predictions for individual observations. They can be used to trace how model predictions change after consecutive conditionings.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bd_rf_distr &lt;-<span class="st"> </span><span class="kw">variable_attribution</span>(explain_rf_v6,
          <span class="dt">new_observation =</span> henry, <span class="dt">type =</span> <span class="st">&quot;break_down&quot;</span>,
          <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;class&quot;</span>, <span class="st">&quot;age&quot;</span>, <span class="st">&quot;gender&quot;</span>, <span class="st">&quot;fare&quot;</span>, 
                           <span class="st">&quot;parch&quot;</span>, <span class="st">&quot;sibsp&quot;</span>, <span class="st">&quot;embarked&quot;</span>),
          <span class="dt">keep_distributions =</span> <span class="ot">TRUE</span>)

<span class="kw">plot</span>(bd_rf_distr, <span class="dt">plot_distributions =</span> <span class="ot">TRUE</span>) </code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-28"></span>
<img src="ema_files/figure-html/unnamed-chunk-28-1.png" alt="Break Down plot with distributions for a defined order of variables." width="70%" />
<p class="caption">
Figure 7.6: Break Down plot with distributions for a defined order of variables.
</p>
</div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-iBreakDownRPackage">
<p>Gosiewska, Alicja, and Przemyslaw Biecek. 2019a. “iBreakDown: Uncertainty of Model Explanations for Non-additive Predictive Models.” <a href="https://arxiv.org/abs/1903.11420v1" class="uri">https://arxiv.org/abs/1903.11420v1</a>.</p>
</div>
<div id="ref-explainPaper">
<p>Robnik-Šikonja, Marco, and Igor Kononenko. 2008. “Explaining Classifications for Individual Instances.” <em>IEEE Transactions on Knowledge and Data Engineering</em> 20 (5): 589–600. doi:<a href="https://doi.org/10.1109/tkde.2007.190734">10.1109/tkde.2007.190734</a>.</p>
</div>
<div id="ref-explainPackage">
<p>Robnik-Šikonja, Marko. 2018. <em>ExplainPrediction: Explanation of Predictions for Classification and Regression Models</em>. <a href="https://CRAN.R-project.org/package=ExplainPrediction" class="uri">https://CRAN.R-project.org/package=ExplainPrediction</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="InstanceLevelExploration.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="iBreakDown.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ema.pdf", "ema.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
