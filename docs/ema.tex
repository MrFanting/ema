\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[]{krantz}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Explanatory Model Analysis},
            pdfauthor={Przemyslaw Biecek and Tomasz Burzykowski},
            colorlinks=true,
            linkcolor=Maroon,
            filecolor=Maroon,
            citecolor=Blue,
            urlcolor=Blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Explanatory Model Analysis}
\providecommand{\subtitle}[1]{}
\subtitle{Explore, Explain and Examine Predictive Models}
\author{Przemyslaw Biecek and Tomasz Burzykowski}
\date{2020-03-08}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}
\listoftables
\listoffigures
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\begin{center}\includegraphics[width=0.99\linewidth]{figure/front4} \end{center}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\hypertarget{notes-to-readers}{%
\section{Notes to readers}\label{notes-to-readers}}

A note to readers: this text is a work in progress.

We've released this initial version to get more feedback. Feedback can be given at the GitHub repo \url{https://github.com/pbiecek/ema/issues}. We are primarily interested in the organization and consistency of the content, but any comments will be welcomed.

We'd like to thank everyone that contributed feedback, found typos, or ignited discussions while the book was being written, including GitHub contributors: \href{https://github.com/agosiewska/}{agosiewska}, Rees Morrison, \href{https://github.com/kasiapekala/}{kasiapekala}, \href{https://github.com/hbaniecki/}{hbaniecki}, \href{https://github.com/AsiaHenzel/}{AsiaHenzel}, \href{https://github.com/kozaka93/}{kozaka93},
\href{https://github.com/agilebean/}{agilebean}.

\hypertarget{the-aim-of-the-book}{%
\section{The aim of the book}\label{the-aim-of-the-book}}

Predictive models are used to guess (statisticians would say: predict) values of a variable of interest based on other variables. As an example, consider prediction of sales based on historical data, prediction of risk of heart disease based on patient characteristics, or prediction of political attitudes based on Facebook comments.

Predictive models have been constructed through the entire human history. Ancient Egyptians, for instance, used observations of the rising of Sirius to predict flooding of the Nile. A more rigorous approach to model construction may be attributed to the method of least squares, published more than two centuries ago by Legendre in 1805 and by Gauss in 1809. With time, the number of applications in economy, medicine, biology, and agriculture has grown. The term \emph{regression} was coined by Francis Galton in 1886. Initially, it was referring to biological applications, while today it is used for various models that allow prediction of continuous variables. Prediction of nominal variables is called \emph{classification}, and its beginning may be attributed to works of Ronald Fisher in 1936.

During the last century, many statistical models that can be used for predictive purposes have been developed. These include linear models, generalized linear models, regression and classification trees, rule-based models, and many others. Developments in mathematical foundations of predictive models were boosted by increasing computational power of personal computers and availability of large datasets in the era of ,,big data'' that we have entered.

With the increasing demand for predictive models, model features such as flexibility, ability to perform internally variable selection (feature engineering), and high precision of predictions are of interest. To obtain robust models, ensembles of models are used. Techniques like bagging, boosting, or model stacking combine hundreds or thousands of small models into a one super-model. Large deep neural models have over a billion parameters.

There is a cost of this progress. Complex models may seem to operate like ,,black boxes'`. It may be difficult, or even impossible, to understand how thousands of coefficients affect the model prediction. At the same time, complex models may not work as well as we would like them to. An overview of real problems with massive-scale black-box models may be found in an excellent book of Cathy O'Neil \citep{ONeil} or in her TED Talk ,,\emph{The era of blind faith in big data must end}''. There is a growing number of examples of predictive models with performance that deteriorated over time or became biased in some sense. For instance, IBM's Watson for Oncology was criticized by oncologists for delivering unsafe and inaccurate recommendations \citep{IBMWatson}. Amazon's system for CV screening was found to be biased against women \citep{AmazonAI}. The COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) algorithm for predicting recidivism, developed by Northpointe (now Equivant), is accused to be biased against blacks \citep{COMPAS}. Algorithms beyond Apple Credit Card are accused to be gender-biased \citep{AppleCreditCard}. Some tools for sentiment analysis are suspected to be age-biased \citep{Diaz2018}. These are examples of models and algorithms that led to serious violations of fairness and ethical principles. An example of situation when data drift led to deterioration in model performance is the Google Flu model, which gave worse predictions after two years than at baseline \citep{GoogleFLU}, \citep{Lazer1203}.

A reaction to some of these examples and problems are new regulations, like the General Data Protection Regulation \citep{EUGDPR}. Also, new civic rights are being formulated \citep{RightToExpl}, \citep{RightToExpl2}, \citep{RightToExpl3}. A noteworthy example is the \emph{,,Right to Explanation''}, i.e., the right to be provided an explanation for an output of an automated algorithm \citep{RightToExpl}. To exercise the right, we need new methods for verification, exploration, and explanation of predictive models.

Figure \ref{fig:UMEPImportance} shows how the increase in the model complexity affects the relative importance of domain understanding vs.~modeling vs.~validation. Simplest models are usually built on top of a good understanding of the domain. Domain knowledge helps to create and select most important variables that can be transformed into predictive scores. Machine learning exploits the tradeoff between availability of data and domain knowledge. Flexible models can use massive data to learn good features and filter out bad ones. The effort is shifted from a deep understanding of the domain towards computationally heavy training of models. The validation part is of an increased importance because it creates a feedback loop with the modeling. Results from model validation lead to next decisions related to model training. This is different than in case of statistical hypothesis testing. Statistical hypotheses shall be stated in advance of data analysis and obtained p-values shall not interfere in the way how data or models were prepared.

What will be next? The increasing automation in the EDA (Exploratory Data Analysis) and modeling part of the process shift the focus towards the validation of models. The purpose of validation is not only to measure how good is the model but also what other risks are associated with models. Risks like concept drift, gender, age or race bias. This book is about new methods that can be used for validation and justification.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{figure/UMEPImportance} 

}

\caption{Shift in the relative importance and effort put in different phases of the data-driven modeling. (A) Statistical modeling is often based on deep understanding of the domain. Manual data exploration, consultations with domain experts, variable transformations lead to good models. Structures of models are often based on (generalized) linear models. Model verification is done through hypothesis testing. (B) Machine learning modeling is often based on elastic models fitted to large volumes of data. Domain exploration is often shallow while the focus is based on predictive performance. Lots of attention is put in cross validation and other strategies that deal with overfitting. (C) What will be next? Human-centered modeling? Better tools for auto EDA and auto ML will shift focus into the part related with validation against the domain knowledge like fairness, bias or new techniques for data exploration. Arrows show feedback loops in the modeling process. The feedback loop is even larger now, as the results from model validation are helping also in the domain understanding.}\label{fig:UMEPImportance}
\end{figure}

Out of this we can conclude that, today, the true bottleneck in predictive modelling is not the lack of data, nor the lack of computational power, nor inadequate algorithms, nor the lack of flexible models. It is the lack of tools for model validation, model exploration, and explanation of model decisions. Thus, in this book, we present a collection of methods that may be used for this purpose. As development of such methods is a very active area of research and new methods become available almost on a continuous basis, we do not aim at being exhaustive. Rather, we present the mind-set, key problems, and several examples of methods that can be used in model exploration.

\hypertarget{three-single-laws}{%
\section{A bit of philosophy: three laws of model explanation}\label{three-single-laws}}

In 1942, Isaac Asimov forumlated \href{https://en.wikipedia.org/wiki/Three_Laws_of_Robotics}{Three Laws of Robotics}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  a robot may not injure a human being,
\item
  a robot must obey the orders given it by human beings, and
\item
  a robot must protect its own existence.
\end{enumerate}

Today's robots, like cleaning robots, robotic pets, or autonomous cars are far from being conscious enough to fall under Asimov's ethics. However, we are more and more surrounded by complex predictive models and algorithms used for decision making. Artificial Intelligence models are used in health care, politics, education, justice, and many other areas. The models and algorithms have a far larger influence on our lives than physical robots. Yet, applications of such models are left unregulated despite examples of their potential harmfulness. See \emph{Weapons of Math Destruction} by Cathy O'Neil \citep{ONeil} for an excellent overview of selected problems.

It's clear that we need to control the models and algorithms that may affect us. Thus, Asimov's laws are referred to in the context of the discussion around \href{https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence}{Ethics of Artificial Intelligence}. Initiatives to formulate principles for AI development have been undertaken, for instance, in the UK {[}Olhede \& Wolfe, Significance 2018, 15: 6-7{]}. Following Asimov's approach, we propose three requirements that any predictive model should fulfill:

\begin{itemize}
\tightlist
\item
  \textbf{Prediction's validation}. For every prediction of a model, one should be able to verify how strong is the evidence that confirms the prediction.
\item
  \textbf{Prediction's justification}. For every prediction of a model, one should be able to understand which variables affect the prediction and to what extent.
\item
  \textbf{Prediction's speculation}. For every prediction of a model, one should be able to understand how the model prediction would change if input variables changed.
\end{itemize}

We see two ways to comply with these requirements. One is to use only models that fulfill these conditions by design. There are so called interpretable by design models like linear models, rule based models or classification trees with small number of parameters \citep{molnar2019}. However, the price for transparency may be a reduction in performance. Another way is to use tools that allow, perhaps by using approximations or simplifications, to ,,explain'' predictions for any model. In our book, we will focus on the latter approach.

\hypertarget{bookstructure}{%
\section{The structure of this book}\label{bookstructure}}

This book is split in two major parts. In the part \emph{Instance-level explainers}, we present techniques for exploration and explanation of model predictions for a single observation. On the other hand, in the part \emph{Dataset-level explainers}, we present techniques for exploration and explanation of a model for an entire dataset.

Before embarking on the description of the methods, in Chapter
\ref{modelDevelopmentProcess}, we provide a short introduction to the process of data exploration and model assembly along with notation and definition of key concepts that are used in consecutive chapters.
In Chapters \ref{doItYourselfWithR} and \ref{doItYourselfWithPython}, we provide a short description of R and Python tools and packages that are necessary to replicate the results presented in this book. In Chapter \ref{dataSetsIntro}, we describe two datasets that are used throughout the book to illustrate the presented methods and tools.



\begin{figure}

{\centering \includegraphics[width=0.85\linewidth]{figure/UMEPpiramide} 

}

\caption{Stack with model exploration methods presented in this book. Left side is focused on instance-level explanation while the right side is focused on dataset-level explanation. Consecutive layers of the stack are linked with a deeper level of model exploration. These layers are linked with law's of model exploration introduced in Section \ref{three-single-laws}}\label{fig:UMEPpiramide}
\end{figure}

Rest of the book is structured in Figure \ref{fig:UMEPpiramide}.

The \textbf{Instance-level} part of the book consists of Chapters \ref{breakDown}-\ref{summaryInstanceLevel}.
Chapters \ref{breakDown}-\ref{shapley} present methods to decompose model predictions into variable contributions. In particular, Chapter \ref{breakDown} introduces Break-down (BD) plots for models with additive effects. On the other hand, Chapter \ref{iBreakDown} presents a method that allows for interactions. Finally, Chapter \ref{shapley} describes SHAP \citep{SHAP} an alternative method for decomposing model predictions that is closely linked with Shapley values \citep{shapleybook1952} developed originally for cooperative games.
Chapter \ref{LIME} presents a different approach to explanation of single-instance predictions. It is based on a local approximation of a black-box model by a simpler, glass-box one. In this chapter, we discuss the Local Interpretable Model-Agnostic Explanations (LIME) method \citep{lime}. These chapters corresponds to the second layer of the stack in Figure \ref{fig:UMEPpiramide}.

In Chapters \ref{ceterisParibus}-\ref{localDiagnostics} we present methods based on Ceteris-paribus (CP) profiles. The profiles show the change of model-based predictions induced by a change of a single variable. These profiles are introduced in Chapter \ref{ceterisParibus} while Chapter \ref{ceterisParibusOscillations} presents a CP-profile-based measure that summarizes the impact of a selected variable on model's predictions. This measure can be used to determine the order of variables in model exploration. It is particularly important for models with large numbers of explanatory variables. Chapter \ref{localDiagnostics} is focused on model diagnostic. It describes local-fidelity plots that are useful to investigate the sources of a poor prediction for a particular single observation.
The final chapter of the first part, Chapter \ref{summaryInstanceLevel} compares various instance-level explainers.

The \textbf{Dataset-level explainers} part of the book consists of Chapters \ref{modelLevelExploration}-\ref{residualDiagnostic}. These chapters present methods in the same order as appeared in the Model Exploration Stack in Figure \ref{fig:UMEPpiramide}.
Chapter \ref{modelPerformance} shows selected measures for model benchmarking along with performance measures for classification and regression models.
On top of these measures, the Chapter \ref{featureImportance} presented an algorithm for assessment of importance of variables based on selected performance measure. This method is model agnostic and can be used for cross models comparisons.
Next layer of the Model Exploration Stack is presented in Chapters \ref{partialDependenceProfiles} and \ref{accumulatedLocalProfiles}. Here we introduce Partial Dependency and Accumulated Dependency methods for univariate exploration of variable effects.
This part of the book is closed with the Chapter \ref{residualDiagnostic} that summarises diagnostic techniques for model residuals.

To make the exploration of the book easier, in each chapter we introduce a single method and each chapter has the same structure:

\begin{itemize}
\tightlist
\item
  Section \emph{Introduction} explains the goal of and the general idea behind the method.
\item
  Section \emph{Method} shows mathematical or computational details related to the method. This subsection can be skipped if you are not interested in the details.
\item
  Section \emph{Example} shows an exemplary application of the method with discussion of results.
\item
  Section \emph{Pros and cons} summarizes the advantages and disadvantages of the method. It also provides some guidance regarding when to use the method.
\item
  Section \emph{Code snippets} shows the implementation of the method in R and Python. This subsection can be skipped if you are not interested in the implementation.
\end{itemize}

\hypertarget{terminology}{%
\section{Terminology}\label{terminology}}

It is worth noting that, when it comes to predictive models, the same concepts have often been given different names in statistics and in machine learning. For instance, in the statistical-modelling literature, one refers to ,,explanatory variables,'' with ,,independent variables,'' ,,predictors,'' or ,,covariates'' as often-used equivalents. Explanatory variables are used in the model as means to explain (predict) the ,,dependent variable,'' also called ,,predicted'' variable or ,,response.'' In machine-learning terminology, ,,input variables'' or ,,features'' are used to predict the ,,output'' or ,,target'' variable. In statistical modelling, models are fit to the data that contain ,,observations'`, whereas in the machine-learning world a dataset may contain ,,instances'' or ,,cases'`. When we talk about values that define a single instance of a model in statistical modelling we refer to model ,,coefficients'' while in machine-learning it is more common to use phrase model ,,parameters'`. In statistics it is common to say that model coefficients are ,,estimated'' while in machine learning it is more common to say that parameters are ,,trained'' or are obtained in the process of ,,model training''.

To the extent possible, in our book we try to consistently use the statistical-modelling terminology. However, the reader may find references to a ,,feature'' here and there. Somewhat inconsistently, we also introduce the term ,,instance-level'' explanation. Instance-level explanation methods are designed to extract information about the behavior of the model related to a specific observation (or instance). On the other hand, ,,dataset-level'' explanation techniques allow obtaining information about the behavior of the model for an entire dataset.

We consider models for dependent variables that can be continuous or nominal/categorical. The values of a continuous variable can be represented by numbers with an ordering that makes some sense (zip codes or phone numbers are not considered as continuous variables while age, number of children are). A continuous variable does not have to be continuous in the mathematical sense; counts (number of floors, steps, etc.) will be treated as continuous variables as well. A nominal/categorical variable can assume only a finite set of values that are not numbers in the mathematical sense, i.e.~it makes no sense to subtract or divide these values.

In this book we focus on ,,black-box'' approach. We discuss this approach in a bit more detail in the next section.

\hypertarget{glass-box-models-vs.black-box-models}{%
\section{Glass-box models vs.~black-box models}\label{glass-box-models-vs.black-box-models}}

Black-box models are models with a complex structure that is hard to understand by humans. Usually this refers to a large number of model coefficients or complex mathematical transformations. As people vary in their capacity to understand complex models, there is no strict threshold for the number of coefficients that makes a model a black-box. In practice, for most people this threshold is probably closer to 10 than to 100.

A ,,glass-box'' (sometimes called white-box or transparent-box) model, which is opposite to a ,,black-box'' one, is a model that is easy to understand (though maybe not by every person). It has a simple structure and a limited number of coefficients.

The most common classes of glass-box models are decision or regression trees, as an example in Figure \ref{fig:BILLCD8}, rules, or models with an explicit compact structure, like the following model for obesity based on the BMI index.

\[
BMI = \frac{mass_{kg}}{height_{m^2}}.
\]

In the model, two explanatory variables are used, mass in kilograms and height in meters. Based on them a BMI index is derived that commonly used for classification into \emph{Underweight} (BMI \textless{} 18), \emph{Normal} (18 \textless{} BMI \textless{} 25) or \emph{Overweight} (BMI \textgreater{} 25) categories. Having the model in a compact form it is easy to understand how changes in one variable affect the model output.

The structure of a glass-box model is, in general, easy to understand. It may be difficult to collect the necessary data, build the model, fit it to the data, or perform model validation, but once the model has been developed its interpretation and mode of working is straightforward.

Why is it important to understand the model structure? There are several important advantages. If the model structure is clear, we can easily see which variables are included in the model and which are not. Hence, for instance, we may be able to, question the model when a particular explanatory variable was excluded from it. Also, in the case of a model with a clear structure and a limited number of coefficients, we can easily link changes in model predictions with changes in particular explanatory variables. This, in turn, may allow us to challenge the model against domain knowledge if, for instance, the effect of a particular variable on predictions is inconsistent with previously established results. Note that linking changes in model predictions with changes in particular explanatory variables may be difficult when there are many variables and/or coefficients in the model. For instance, a classification tree with hundreds of nodes is difficult to understand, as is a linear regression model with hundreds of coefficients.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{figure/wbBILL8model} 

}

\caption{Example classification tree model for melanoma risk patients based on [@BILLCD8]. The model is based on two explanatory variables, Breslow thickness and Tumor infiltration lymphocytes. These two variables lead to three groups of paritents with different odds of survival.}\label{fig:BILLCD8}
\end{figure}

Note that some glass-box models, like the decision tree model presented in Figure \ref{fig:BILLCD8} by design satisfies explainability laws introduced in Section \ref{three-single-laws}.
For \emph{Prediction's validation} we see in each node how many patients fall in a given category. For \emph{Prediction's justification} we see which variables are used in every decision path. For \emph{Prediction's speculation} we can trace how changes in particular variables will affect the model prediction. We can, of course, argue if the model is good or not, but obviously the model structure is transparent.

Comprehending the performance of a black-box models presents more challenges. The structure of a complex model, such as a neural-network model, may be far from transparent. Consequently, we may not understand which features influence the model decisions and by how much. Consequently, it may be difficult to decide whether the model is consistent with our domain knowledge. In our book we present tools that can help in extracting the information necessary for the evaluation of complex models.

\hypertarget{model-agnostic-vs.model-specific-approach}{%
\section{Model-agnostic vs.~model-specific approach}\label{model-agnostic-vs.model-specific-approach}}

Interest in model interpretability is as old as the statistical modeling itself.
Some classes of models have been developed for a long period of time or have attracted intensive research. Consequently, those classes of models are equipped with excellent tools for model exploration or visualisation. For example:

\begin{itemize}
\tightlist
\item
  There are many tools for diagnostics and evaluation of linear models, see for example \citep{Galecki2013} or \citep{Faraway02practicalregression}. Model assumptions are formally defined (normality, linear structure, homogenous variance) and can be checked by using normality tests or plots (normal qq-plot), diagnostic plots, tests for model structure, tools for identification of outliers, etc.
\item
  For many more advanced models with an additive structure, like the proportional hazards model, many tools can be used for checking model assumptions, see for example \citep{rms} or \citep{sheather2009modern}.
\item
  Random-forest models are equipped with the out-of-bag method of evaluating performance and several tools for measuring variable importance \citep{R-randomForest}. Methods have been developed to extract information from the model structure about possible interactions \citep{randomForestExplainer}. Similar tools have been developed for other ensembles of trees, like boosting models (xgboost, gbm). See \citep{xgboostExplainer} or \citep{EIXkarbowiak}.
\item
  Neural networks enjoy a large collection of dedicated model-explanation tools that use, for instance, the layer-wise relevance propagation technique \citep{BachLWRP}, or saliency maps technique \citep{SaliencyMaps}, or a mixed approach. Broader summary is presented in \citep{samek2017explainable} and \citep{alber2018innvestigate}.
\item
  BERT family of models leads to high-performance models in Natural Language Processing. The exBERT method \citep{hoover2019exbert} is designed to visualize the activation of attention heads in this model.
\end{itemize}

Of course, the list of model classes with dedicated collections of model-explanation and/or diagnostics methods is much longer. This variety of model-specific approaches does lead to issues, though. For instance, one cannot easily compare explanations for two models with different structures. Also, every time a new architecture or a new ensemble of models is proposed, one needs to look for new methods of model exploration. Finally, for brand-new models no tools for model explanation or diagnostics may be immediately available.

For these reasons, in our book we focus on model-agnostic techniques. In particular, we prefer not to assume anything about the model structure, as we may be dealing with a black-box model with an unspecified structure. Often we do not have access to model parameters just to a specified Application Programming Interface (API) that allows for querying remote models (for example in Microsoft Cognitive Services \citep{MicrosofrCognitiveServices}).
In that case, the only operation that we may be able to perform is the evaluation of a model for a specified data.

However, while we do not assume anything about the structure of the model, we will assume that the model operates on \(p\)-dimensional vector of variables/features and, for a single observation, it returns a single value (score/probability) which is a real number. This assumption holds for a broad range of models for data such as tabular data, images, text data, videos, etc. It may not be suitable for, e.g., models with memory like sequence-to-sequence models \citep{seq2seq} or Long Short Term Memory models \citep{lstm} in which the model output depends also on sequence of previous inputs or generative models that output text of images.

\hypertarget{what-is-in-this-book-and-what-is-not}{%
\section{What is in this book and what is not}\label{what-is-in-this-book-and-what-is-not}}

The area of model exploration and explainability is quickly growing and is present in many different flavors. Instead of showing every existing method (is it really possible?) we rather selected a subset of consistent tools that are a good starting set for model exploration. Our focus was on the impact of the model exploration and explanation tools rather than on selected methods. We believe that once we become aware of potential beyond visual model exploration, once we will learn a language of model explanation, we will improve our process of data modeling.

Taking this goal into account \textbf{in this book, we do show}

\begin{itemize}
\tightlist
\item
  how to determine features that affect model prediction for a single observation. In particular, we present the theory and examples of methods that can be used to explain prediction like Break Down plots, Ceteris Paribus profiles, local-model approximations, or Shapley values;
\item
  techniques to examine fully-trained machine-learning models as a whole. In particular, we review the theory and examples of methods that can be used to explain model performance globally, like partial-dependence plots, variable-importance plots, and others;
\item
  charts that can be used to present key information in a quick way;
\item
  tools and methods for model comparison;
\item
  code snippets for R and Python that explain how to use the described methods.
\end{itemize}

On the other hand, \textbf{in this book, we do not focus on}

\begin{itemize}
\tightlist
\item
  any specific model. The techniques presented are model agnostic and do not make any assumptions related to the model structure;
\item
  data exploration. There are very good books on this topic, like \emph{R for Data Science} by Garrett Grolemund and Hadley Wickham \citep{r4ds2019} or \emph{Python for Data Analysis} \citep{Wes2012} by Wes McKinney or an excellent \emph{Exploratory Data Analysis} by John Tukey \citep{tukey1977};
\item
  the process of model building. There are also very good books on this topic, see \emph{Modern Applied Statistics with S} by W. Venables and B. Ripley \citep{MASSbook}, \emph{An Introduction to Statistical Learning} by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani \citep{James20147} or \emph{Computer Age Statistical Inference} by Bradley Efron and Trevor Hastie \citep{Efron2016};
\item
  any particular tools for model building. These are discussed, for instance, in \emph{Applied Predictive Modeling} by Max Kuhn and Kjell Johnson \citep{Kuhn2013}.
\end{itemize}

\hypertarget{thanksto}{%
\section{Acknowledgements}\label{thanksto}}

This book has been prepared using the \texttt{bookdown} package \citep{R-bookdown}, created thanks to the amazing work of Yihui Xie.
Figures and tables are created in R language for statistical computing \citep{RcoreT} with numerous libraries that support predictive modeling. Just to name few frequently used in this book \texttt{randomForest} \citep{randomForest}, \texttt{ranger} \citep{rangerRpackage}, \texttt{rms} \citep{rms}, \texttt{gbm} \citep{gbm} or \texttt{caret} \citep{caret}. For statistical graphics we used the \texttt{ggplot2} library \citep{ggplot2} and for model governance we used \texttt{archivist} \citep{archivist}.

Przemek's work on interpretability started during research trips within the RENOIR (H2020 grant no. 691152) secondments to Nanyang Technological University (Singapour) and Davis University of California (USA). So he would like to thank Prof.~Janusz Holyst for the chance to take part in this project. Przemek would also like to thank Prof.~Chris Drake for her hospitality. This book would have never been created without perfect conditions that Przemek found at Chris's house in Woodland.

\hypertarget{modelDevelopmentProcess}{%
\chapter{Model Development}\label{modelDevelopmentProcess}}

\hypertarget{MDPIntro}{%
\section{Introduction}\label{MDPIntro}}

In this book we present methods that can be used for exploration and explanation of predictive models. But before we can explore a model, first we need to train one.

In this part of the book we overview the process of model development and introduce steps that lead to a model creation. It is not a comprehensive manual ,,how to train a model in 5 steps''. The goal of this chapter is to show what needs to be performed before we can do any diagnostic or exploration of a trained model.

Predictive models are created for different purposes. Sometimes it is a team of data scientists that spend months on a single model that will be used for model scoring in a big financial company. Every detail is important for models that operate on large scale and have long-term consequences. Another time it is an in-house model trained for prediction of a demand for pizza. The model is developed by a single person in few hours. If model will not perform well it will be updated, replaced or removed.

Whatever it is a large model or small one, similar steps are to be taken during model development.

\hypertarget{MDPprocess}{%
\section{The Process}\label{MDPprocess}}

Several approaches are proposed in order to describe the process of model development. Their main goal is to standardize the process. And the standardisation is important because it helps to plan resources needed to develop and maintain the model and also to not miss any important step.

The most known methodology for data science projects is CRISP-DM \citep{crisp1999}, \citep{crisp2019wiki} which is a tool agnostic procedure. The key component of CRISP-DM is the break down of the whole process into six phases, that are iterated: business understanding, data understanding, data preparation, modeling, evaluation and deployment. CRISP-DM is general, it was designed for any data science project. For predictive models some methodologies are introduced in ,,R for Data Science'' \citep{r4ds2019} and ,,On XAI Misconceptions'' \citep{misconceptions2019}.Both are focused on iterative repetitions of some phases.
Figure \ref{fig:MDPwashmachine} presents a variant of iterative process divided into five steps. Data preparation is needed prior to any modeling. Better data is needed for better models. On the other hand, garbage-in garbage-out. Once the data is gathered, steps that are usually highlighted are Data understanding, Model assembly and Model audit. This is the common thinking about model development. Repeat these steps until some convergence, e.g.~repeat until best model is identified.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figure/MDP_washmachine} 

}

\caption{Lifecycle of predictive model can be decomposed into five tasks. First we need data that is poured into the model development cycle. The model development is highly iterative, learn something new about the data, assemble a new model based on current understanding, and validate the new model. Repeat these steps as long as needed to be satisfied with model performance. Once the model is created we can deliver the model to the production along with required tests and documentation.}\label{fig:MDPwashmachine}
\end{figure}

In this book we use \emph{Model Development Process} \citep{mdp2019}. It is motivated by Rational Unified Process for Software Development \citep{rup1998}, \citep{usdp1999}, \citep{spiral1988}. One can think about MDP as an extension of process introduced in Figure \ref{fig:MDPwashmachine}. What is important is to notice that consecutive iterations are not identical. Our knowledge increases during the process and consecutive iterations are performed with different goals in mind.

This is why MDP is build as an untangled version of Figure \ref{fig:MDPwashmachine}. The MDP process is shown in Figure \ref{fig:mdpGeneral}. Each vertical stripe is a single run of the cycle.
First iterations are usually focused on \emph{formulation of the problem}. Sometimes the problem is well stated, however it's a rare situation valid maybe only for kaggle competitions. In most real-life problems the problem formulation requires lots of discussions and experiments. Once the problem is defined we can start building first prototypes, first \emph{crisp versions of models}. These initial versions of models are needed to verify if the problem can be solved and how far we are form the solution. Usually we gather more information and go for the next phase, the \emph{fine tuning}. We repeat these iterations until a final version of a model is developed. Then we move to the last phase \emph{maintenance and} (one day) \emph{decommissioning}.



\begin{figure}

{\centering \includegraphics[width=0.99\linewidth]{figure/mdp_general} 

}

\caption{Overview of the Model Development Process. Horizontal axis show how time passes from the problem formulation to the model decommissioning. Vertical axis shows tasks are performed in a given phase. Each vertical strip is a next iteration of cycle presented in Figure \ref{fig:MDPwashmachine}}\label{fig:mdpGeneral}
\end{figure}

Having in mind the map of model development we can point places where one can use methods presented in this book.

As suggested in the title of this book, three primary applications are: exploration, explanation and debugging. \emph{Exploration} refers to situations in which we better understand the data and the domain. Presented techniques can be used to speed up the variable engineering or variable selection. \emph{Explanation} refers to situations in which we are interested in decision paths beyond particular predictions. \emph{Debugging} refers to situations in which we want to understand weak points of a model and correct them. These applications target phases Data understanding, Model assembly and Model audit.

In this book we present various examples based on three use cases. Two introduced in Chapter \ref{dataSetsIntro} (binary classification in surviving Titanic sinking and regression in apartments pricing) and one in Chapter \ref{UseCaseFIFA} (estimation of soccer player value based on its skills). Due to space limitation we do not show the full life cycle of these problems, but we are focused on phases Crisp modeling and Fine tuning.

Rest of this chapter is focused on a brief overview of the notation and commonly used methods for data exploration, model training and model validation.

\hypertarget{notation}{%
\section{Notation}\label{notation}}

Methods described in this book were developed by different authors, who used different mathematical notations.
We try to keep the mathematical notation consistent throughout the entire book. In some cases this may result in formulas with a fairly complex system of indices.

In this section, we provide a general overview of the notation we use. Whenever necessary, parts of the notation will be explained again in subsequent chapters.

We assume that the data consist \(n\) observations/instances. Each observation is described by \(p\) explanatory variables. Thus data is described as a set of points on a \(p\)-dimensional input space \(\mathcal X \equiv \mathcal R^p\). By \(x \in \mathcal X\) we will refer to a single point in this input space.
By \(x_i\) we refer to the \(i\)-th observation in this dataset. Of course, \(x_i \in \mathcal X\). By \(X\) we denote a matrix \(n\times p\) with rows corresponding to consecutive observations.

Some methods of model exploration are constructed around an observation of interest which will be denoted by \(x_{*}\). The observation may not necessarily belong to the analyzed dataset; hence, the use of the asterisk in the index. Of course, \(x_* \in \mathcal X\).

Points in \(\mathcal X\) are \(p\) dimensional vectors. We refer to the \(j\)-th coordinate by using \(j\) in superscript. Thus, \(x^j_i\) denotes the \(j\)-th coordinate of the \(i\)-th observation from the analyzed dataset. If \(\mathcal J\) denotes a subset of indices, then \(x^{\mathcal J}\) denotes the elements of vector \(x\) corresponding to the indices included in \(\mathcal J\).

We will use the notation \(x^{-j}\) to refer to a vector that results from removing the \(j\)-th coordinate from vector \(x\). By \textbf{\(x^{j|=z}\)}, we denote a vector with the values at all coordinates equal to the values in \(x\), except of the \(j\)-th coordinate, which is set equal to \(z\). So, if \(w=x^{j|=z}\), then \(w^j = z\) and \(\forall_{k\neq j} w^k = x^k\). In other words \(x^{j|=z} = (x^1, ..., x^{j-1}, z, x^{j+1}, ..., x^p)\).

By \(x^{*j}\) we denote a matrix with the values as in \(x\) except the \(j\)th column which is permuted.

In this book, a model is a function \(f:\mathcal X \rightarrow \mathcal R\) that transforms a point from \(\mathcal X\) into a real number. In most cases, the presented methods can be used directly for multivariate dependent variables; however, we use examples with uni-variate responses to simplify the notation.
Typically, during the model development, we create many competing models. Formally we shall index models to refer to a specific version of a trained model. But for the sake of simplicity we omit these indexes where they are not important.

Later in this book we will use the term \textbf{model residual} as the the difference between the observed value of the dependent variable \(Y\) for the \(i\)-th observation from a particular dataset and the model prediction for the observation

\begin{equation}
r_i = y_i - f(x_i) = y_i - \hat y_i.
\label{eq:modelResiduals}
\end{equation}

\hypertarget{data-exploration}{%
\section{Data exploration}\label{data-exploration}}

Before we start the modeling we need to understand the data.
Visual, tabular and statistical tools for data exploration are used depending on the character of variables.

The most know introduction to data exploration is the famous book by John Tukey \citep{tukey1977}. It introduces new tools for data exploration, like for example boxplots or stem-and-leaf plots. Availability of computational tools makes the process of data exploration easier and more interactive. Find a good overview of techniques for data exploration in ,,Data Science in R'' \citep{Nolan2015} or ,,R for Data Science'' \citep{Wickham2017}.

In this book we will rely on five visual methods for data exploration presented in Figure \ref{fig:UMEPEDA}. Two of them are used to present distribution of explanatory or target variables; three others are used to explore pairwise relations between variables.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{figure/UMEPEDA} 

}

\caption{Basic methods for visual exploration. Histogram for distribution of continuous or categorical variables, empirical cumulative distribution for continuous variables. Mosaic plot for relation between two categorical variables, boxplots for relation between continuous and categorical variables or scatterplot for relation between two continuous variables.}\label{fig:UMEPEDA}
\end{figure}

Distribution of categorical variable is summarized with a barplot, distribution of numerical variable is summarized with a histogram or empirical cumulative distribution function.

Primary goal for exploration of target variable is to decide if some variable transformation is needed (e.g.~if the variable is skewed or with fat tails) or to verify if target variable is balanced (because some methods are not working well with unbalanced data). Exploration of dependent variables is performed mainly to decide if any variable transformation is needed.

Relations between two variables, mostly between a single dependent variable and target variable, are visualized with mosaic plots (for two categorical variables), boxplots (for numerical and categorical variable) and scatter plots (for two numerical variables). Such exploration may provide some insights for variable selection/filtering (if the variable is not related with the target then variable may be removed from the model) or variable engineering (if from the exploration we gain information how a variable may be transformed).

\hypertarget{notationTraining}{%
\section{Model training}\label{notationTraining}}

In predictive modeling, we are interested in a distribution of a dependent variable \(Y\) given vector \(x_*\). The latter contains values of explanatory variables. In the ideal world, we would like to know the conditional distribution of \(Y\) given \(x_*\). In practical applications, however, we usually do not predict the entire distribution, but just some of its characteristics like the expected (mean) value, a quantile, or variance. Without loss of generality we will assume that we model the conditional expected value \(E_Y(Y | x_*)\).

Assume that we have got model \(f()\), for which \(f(x_*)\) is an approximation of \(E_Y(Y | x_*)\), i.e., \(E_Y(Y | x_*) \approx f(x_*)\). Note that we do not assume that it is a ``good'' model, nor that the approximation is precise. We simply assume that we have a model that is used to estimate the conditional expected value and to form predictions of the values of the dependent variable. Our interest lies in the evaluation of the quality of the predictions. If the model offers a ``good'' approximation of the conditional expected value, it should be reflected in its satisfactory predictive performance.

Usually the available data is split into two parts. One will be used for model training (estimation of model parameters), second will be used for model validation. The splitting may be repeated as in k-fold cross validation or repeated k-fold cross validation (see for example ,,Applied predictive modeling'' \citep{Kuhn2013}). We leave the topic of model validation for Chapter \ref{modelPerformance}.

Training procedures are different for different models, but most of them can be written as an optimization problem. Let \(\Theta\) be a space for possible model parameters. Model training is a procedure of selection a \(\theta \in \Theta\) that maximize some loss function \(L(y, f_\theta(X))\). For models with large parameter spaces it is common to add additional term \(\lambda(\theta)\) that control the model complexity.

\begin{equation}
\hat\theta = \arg \min_{\theta \in \Theta}  L (y, f_\theta(X)) + \lambda(\theta). 
\label{eq:modelTrainingEq1}
\end{equation}

For statistical models it is common to assume some family of probability distributions for \(y|x\). In such case the loss function \(L\) may be defined as a minus log-likelihood function for \(\theta\). Likelihood is probability of observing \(y|x\) as a function of parameter \(\theta\).

For example, in linear regression we assume that that observed vector of values \(y\) follow a multidimensional Gaussian distribution
\[
y \sim \mathcal N(X \beta, I\sigma^2),
\]
where \(\theta = (\beta, \sigma^2)\). In this case equation \eqref{eq:modelTrainingEq1} become

\begin{equation}
\hat\theta = \arg \min_{\theta \in \Theta}  ||y - X \beta||_{2} + \lambda(\beta). 
\label{eq:modelTrainingEq2}
\end{equation}

For linear regression, the penalty term \(\lambda(\beta)\) is equal to \(0\), and optimal parameters \(\beta\) in equation \eqref{eq:modelTrainingEq2} have close analytical solution \(\hat \beta = (X^TX)^{-1}X^Ty\). In ridge regression the penalty \(\lambda(\beta) = \lambda ||\beta||_2\) and also \eqref{eq:modelTrainingEq2} have analytical solution \(\hat \beta = (X^TX + \lambda I)^{-1}X^Ty\). For LASSO regression the penalty \(\lambda(\beta) = \lambda ||\beta||_1\) and \(\beta\) are estimated through a numerical optimization.

For classification, the natural choice for distribution of \(y\) is a Binomial distribution. This leads to logistic regression and logistic loss function. For multi label classification frequent choice is the cross-entropy loss function.

Apart from linear models for \(y\) there is a large variety of predictive models. Find a good overview of different techniques for model development in ,,Modern Applied Statistics with S'' \citep{MASSbook} or ,,Applied predictive modeling'' \citep{Kuhn2013}.

\hypertarget{model-understanding}{%
\section{Model understanding}\label{model-understanding}}

Usually the model development starts with some crisp early versions that are refined in consecutive iterations. In order to train a final model we need to try numerous candidate models that will be explored, examined and diagnosed. In this book we will introduce techniques that:

\begin{itemize}
\tightlist
\item
  summarise how good is the current version of a model. Section \ref{modelPerformance} overviews measures for model performance. These measures are usually used to trace the progress in model development.
\item
  assess the feature importance. Section \ref{featureImportance} shows how to assess influence of a single variable on model performance. Features that are not important are usually removed from a model during the model refinement.
\item
  shows how a single feature affects the model response. Sections \ref{partialDependenceProfiles} -- \ref{accumulatedLocalProfiles} present Partial Dependence Profiles, Accumulated Local Effects and Marginal Profiles. All these techniques help to understand how model consumes particular features.
\item
  identifies potential problems with a model. Section \ref{residualDiagnostic} shows techniques for exploration of model residuals. Looking closer on residuals often help to improve the model. This is possible with tools for local model exploration which are presented in the fist part of the book.
\item
  performs sensitivity analysis for a model. Section \ref{ceterisParibus} introduces Ceteris Paribus profiles that helps in a what-if analysis for a model.
\item
  validated local fit for a model. Section \ref{localDiagnostics} introduces techniques for assessment if for a single observation the model support its prediction.
\item
  decompose model predictions into pieces that can be attributed to particular variables. Sections \ref{breakDown} -- \ref{LIME} show different techniques like SHAP, LIME or Break Down for local exploration of a model.
\end{itemize}

\hypertarget{doItYourselfWithR}{%
\chapter{Do-it-yourself with R}\label{doItYourselfWithR}}

In this book we introduce various methods for instance-level and dataset-level explanation and exploration of predictive models. In each chapter, there is a section with code snippets for R and Python that shows how to use a particular method. In this chapter we provide a short description of steps that are needed to set-up the environment with required libraries.

\hypertarget{what-to-install}{%
\section{What to install?}\label{what-to-install}}

Obviously, the R software \citep{RcoreT} is needed. It is always a good idea to use the newest version. At least R in version 3.6 is recommended. R can be downloaded from the CRAN website \url{https://cran.r-project.org/}.

A good editor makes working with R much easier. There is a plenty of choices, but, especially for beginners, it is worth considering the RStudio editor, an open-source and enterprise-ready tool for R. It can be downloaded from \url{https://www.rstudio.com/}.

Once R and the editor are available, the required packages should be installed.

The most important one is the \texttt{DALEX} package in version 1.0 or newer. It is the entry point to solutions introduced in this book. The package can be installed by executing the following command from the R command line:

\begin{verbatim}
install.packages("DALEX")
\end{verbatim}

Installation of \texttt{DALEX} will automatically take care about installation of other hard requirements (packages required by it), like the \texttt{ggplot2} package for data visualization.

To repeat all examples in this book, two additional packages are needed: \texttt{ingredients} and \texttt{iBreakDown}. The easiest way to get them, including other useful weak dependencies, is to execute the following command:

\begin{verbatim}
DALEX::install_dependencies()
\end{verbatim}

\hypertarget{how-to-work-with-dalex}{%
\section{\texorpdfstring{How to work with \texttt{DALEX}?}{How to work with DALEX?}}\label{how-to-work-with-dalex}}

To conduct model exploration with \texttt{DALEX}, first, a model has to be created. Then the model has got to be prepared for exploration.

There are many packages in R that can be used to construct a model. Some packages are structure-specific, like \texttt{randomForest} for Random-Forest Classification and Regression models \citep{randomForest}, \texttt{gbm} for Generalized Boosted Regression Models \citep{gbm}, extensions for Generalized Linear Models \citep{rms}, or many others. There is also a number of packages that can be used for constructing models with different structures. These include the \texttt{h2o} package \citep{h2oPackage}, \texttt{caret} \citep{caret} and its successor \texttt{parsnip} \citep{parsnipPackage}, a very powerful and extensible framework \texttt{mlr} \citep{mlr}, or \texttt{keras} that is a wrapper to Python library with the same name \citep{kerasPackage}.

While it is great to have such a large choice of tools for constructing models, the downside is that different packages have different interfaces and different arguments. Moreover, model-objects created with different packages may have different internal structures. The main goal of the \texttt{DALEX} package is to create a level of abstraction around a model that makes it easier to explore and explain the model.

Function \texttt{DALEX::explain} is THE function for model wrapping. The function requires five arguments:

\begin{itemize}
\tightlist
\item
  \texttt{model}, a model-object;
\item
  \texttt{data}, a data frame with validation data;
\item
  \texttt{y}, observed values of the dependent variable for the validation data; it is an optional argument, required for explainers focused on model validation and benchmarking.
\item
  \texttt{predict\_function}, a function that returns prediction scores; if not specified, then a default \texttt{predict()} function is used. Note that, for some models, the default \texttt{predict()} function returns classes; in such cases you should provide a function that will return numerical scores.
\item
  \texttt{label}, a name of a model; if not specified, then it is extracted from the \texttt{class(model)}. This name will be presented in figures, so it is recommended to make the name informative.
\end{itemize}

For an example, see Section \ref{ExplainersTitanicRCode}.

\hypertarget{how-to-work-with-archivist}{%
\section{\texorpdfstring{How to work with \texttt{archivist}?}{How to work with archivist?}}\label{how-to-work-with-archivist}}

As we will focus on exploration of predictive models, we prefer not to waste space nor time on replication of the code necessary for model development. This is where the \texttt{archivist} packages helps.

The \texttt{archivist} package \citep{archivist} is designed to store, share, and manage R objects. We will use it to easily access pretrained R models and precalculated explainers. To install the package, the following command should be executed in the R command line:

\begin{verbatim}
install.packages("archivist")
\end{verbatim}

Once the package has been installed, function \texttt{aread()} can be used to retrieve R objects from any remote repository. For this book, we use a GitHub repository \texttt{models} hosted at \url{https://github.com/pbiecek/models}. For instance, to download a model with the md5 hash \texttt{ceb40}, the following command has to be executed:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/ceb40"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Since the md5 hash \texttt{ceb40} uniquely defines the model, referring to the repository object results in using exactly the same model and the same explanations. Thus, in the subsequent chapters, pre-constructed model explainers will be accessed with \texttt{archivist} hooks. In following sections we will also use \texttt{archivist} hooks in references to datasets.

\hypertarget{doItYourselfWithPython}{%
\chapter{Do-it-yourself with Python}\label{doItYourselfWithPython}}

\hypertarget{dataSetsIntro}{%
\chapter{Data sets and models}\label{dataSetsIntro}}

We illustrate the methods presented in this book by using two datasets:

\begin{itemize}
\tightlist
\item
  Predicting odds of survival out of \emph{Sinking of the RMS Titanic}
\item
  Predicting prices for \emph{Apartments in Warsaw}
\end{itemize}

The first dataset will be used to illustrate the application of the techniques in the case of a predictive model for a binary dependent variable. The second one will provide an example for models for a continuous variable.

In this chapter, we provide a short description of each of the datasets, together with results of exploratory analyses. We also introduce models that will be used for illustration purposes in subsequent chapters.

\hypertarget{TitanicDataset}{%
\section{Sinking of the RMS Titanic}\label{TitanicDataset}}

\begin{figure}
\centering
\includegraphics{figure/Titanic.jpg}
\caption{Titanic sinking by Willy Stöwer}
\end{figure}

Sinking of the RMS Titanic is one of the deadliest maritime disasters in history (during peacetime). Over 1500 people died as a consequence of collision with an iceberg. Projects like \emph{Encyclopedia titanica} \texttt{https://www.encyclopedia-titanica.org/} are a source of rich and precise data about Titanic's passengers.
The \texttt{stablelearner} package includes a data frame with some passenger characteristics.
The dataset, after some data cleaning and variable transformations, is also available in the \texttt{DALEX} package. In particular, the \texttt{titanic} data frame contains 2207 observations (for 1317 passengers and 890 crew members) and nine variables:

\begin{itemize}
\tightlist
\item
  \emph{gender}, person's (passenger's or crew member's) gender, a factor (categorical variable) with two levels (categories) \texttt{male} (78\%) and \texttt{female} (22\%);
\item
  \emph{age}, person's age in years, a numerical variable; the age is given in (integer) years, range 0 -- 74 years;
\item
  \emph{class}, the class in which the passenger travelled, or the duty class of a crew member; a factor with seven levels: \texttt{1st} (14.7\%), \texttt{2nd} (12.9\%), \texttt{3rd} (32.1\%), \texttt{deck\ crew} (3\%), \texttt{engineering\ crew} (14.7\%), \texttt{restaurant\ staff} (3.1\%), \texttt{victualling\ crew} (19.5\%);
\item
  \emph{embarked}, the harbor in which the person embarked on the ship, a factor with four levels, \texttt{Belfast} (8.9\%), \texttt{Cherbourg} (12.3\%), \texttt{Queenstown} (5.6\%), \texttt{Southampton} (73.2\%);
\item
  \emph{country}, person's home country, a factor with 48 levels, the most common are \texttt{England} (51\%), \texttt{United\ States} (12\%), \texttt{Ireland} (6.2\%) and \texttt{Sweden} (4.8\%);
\item
  \emph{fare}, the price of the ticket (only available for passengers; 0 for crew members), a numerical variable range 0 -- 512;
\item
  \emph{sibsp}, the number of siblings/spouses aboard the ship, a numerical variable range 0 -- 8;
\item
  \emph{parch}, the number of parents/children aboard the ship, a numerical variable range 0 -- 9;
\item
  \emph{survived}, a factor with two levels \texttt{yes} (67.8\%), \texttt{no} (32.2\%), indicating whether the person survived or not.
\end{itemize}

The R code below provides more info about the contents of the dataset, values of the variables, etc.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(titanic, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   gender age class    embarked       country  fare sibsp parch survived
## 1   male  42   3rd Southampton United States  7.11     0     0       no
## 2   male  13   3rd Southampton United States 20.05     0     2       no
\end{verbatim}

Models considered for this dataset will use \emph{survived} as the (binary) dependent variable.

\hypertarget{exploration-titanic}{%
\subsection{Data exploration}\label{exploration-titanic}}

It is always advisable to explore data before modelling. However, as this book is focused on model exploration, we will limit the data exploration part.

Before exploring the data, we first do some pre-processing. In particular, the value of variables \emph{age}, \emph{country}, \emph{sibsp}, \emph{parch}, and \emph{fare} is missing for a limited number of observations (2, 81, 10, 10, and 26, respectively). Analyzing data with missing values is a topic on its own (Little and Rubin 1987; Schafer 1997; Molenberghs and Kenward 2007). An often-used approach is to impute the missing values. Toward this end, multiple imputation should be considered (Schafer 1997; Molenberghs and Kenward 2007; van Buuren 2012). However, given the limited number of missing values and the intended illustrative use of the dataset, we will limit ourselves to, admittedly inferior, single imputation. In particular, we replace the missing \emph{age} values by the mean of the observed ones, i.e., 30. Missing \emph{country} will be coded by ``X''. For \emph{sibsp} and \emph{parch}, we replace the missing values by the most frequently observed value, i.e., 0. Finally, for \emph{fare}, we use the mean fare for a given \emph{class}, i.e., 0 pounds for crew, 89 pounds for the 1st, 22 pounds for the 2nd, and 13 pounds for the 3rd class. The R code presented below implements the imputation steps.

\begin{itemize}
\tightlist
\item
  missing \texttt{age} is replaced by its average, that is 30
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic}\OperatorTok{$}\NormalTok{age[}\KeywordTok{is.na}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{age)] =}\StringTok{ }\DecValTok{30}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  missing \texttt{country} is replaced by \texttt{"X"}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic}\OperatorTok{$}\NormalTok{country <-}\StringTok{ }\KeywordTok{as.character}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{country)}
\NormalTok{titanic}\OperatorTok{$}\NormalTok{country[}\KeywordTok{is.na}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{country)] =}\StringTok{ "X"}
\NormalTok{titanic}\OperatorTok{$}\NormalTok{country <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{country)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  missing \texttt{fare} is replaced by within \texttt{class} average, that is 89, 22 and 13 correspondingly
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic}\OperatorTok{$}\NormalTok{fare[}\KeywordTok{is.na}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{fare) }\OperatorTok{&}\StringTok{ }\NormalTok{titanic}\OperatorTok{$}\NormalTok{class }\OperatorTok{==}\StringTok{ "1st"}\NormalTok{] =}\StringTok{ }\DecValTok{89}
\NormalTok{titanic}\OperatorTok{$}\NormalTok{fare[}\KeywordTok{is.na}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{fare) }\OperatorTok{&}\StringTok{ }\NormalTok{titanic}\OperatorTok{$}\NormalTok{class }\OperatorTok{==}\StringTok{ "2nd"}\NormalTok{] =}\StringTok{ }\DecValTok{22}
\NormalTok{titanic}\OperatorTok{$}\NormalTok{fare[}\KeywordTok{is.na}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{fare) }\OperatorTok{&}\StringTok{ }\NormalTok{titanic}\OperatorTok{$}\NormalTok{class }\OperatorTok{==}\StringTok{ "3rd"}\NormalTok{] =}\StringTok{ }\DecValTok{13}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  missing \texttt{sibsp} and \texttt{parch} are replaced by 0
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic}\OperatorTok{$}\NormalTok{sibsp[}\KeywordTok{is.na}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{sibsp)] =}\StringTok{ }\DecValTok{0}
\NormalTok{titanic}\OperatorTok{$}\NormalTok{parch[}\KeywordTok{is.na}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{parch)] =}\StringTok{ }\DecValTok{0}
\end{Highlighting}
\end{Shaded}

After imputing the missing values, we investigate the association between survival status and other variables. Most variables in the Titanic dataset are categorical, except Age and Fare. In order to keep the exploration uniform we first transformed them into categorical variables. Figure \ref{fig:titanicExplorationHistograms} shows histograms for both variables. Age is discretized into 5 categories with cutoffs 5, 10, 20 and 30 while Fare is discretized with cutoffs 1, 10, 25, and 50.

Figures \ref{fig:titanicExplorationGenderAge}-\ref{fig:titanicExplorationCountry} present graphically the proportion non- and survivors for different levels of the other variables with the use of mosaic plots. The height of the bars (on the y-axis) reflects the marginal distribution (proportions) of the observed levels of the variable. On the other hand, the width of the bars (on the x-axis) provides the information about the proportion of non- and survivors. Note that, to construct the graphs for \emph{age} and \emph{fare}, we categorized the range of the observed values.

Figure \ref{fig:titanicExplorationGenderAge} indicates that the proportion of survivors was larger for females and children below 5 years of age. This is most likely the result of the ``women and children first'' principle that is often evoked in situations that require evacuation of persons whose life is in danger. The principle can, perhaps, partially explain the trend seen in Figure \ref{fig:titanicExplorationParch}, i.e., a higher proportion of survivors among those with 1-3 parents/children and 1-2 siblings/spouses aboard. Figure \ref{fig:titanicExplorationClass} indicates that passengers travelling in the first and second class had a higher chance of survival, perhaps due to the proximity of the location of their cabins to the deck. Interestingly, the proportion of survivors among crew deck was similar to the proportion of the first-class passengers. It also shows that the proportion of survivors increased with the fare, which is consistent with the fact that the proportion was higher for passengers travelling in the first and second class. Finally, Figure \ref{fig:titanicExplorationCountry} does not suggest any noteworthy trends.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/titanicExplorationHistograms-1} 

}

\caption{Histogram of Age and Fare for the Titanic data.}\label{fig:titanicExplorationHistograms}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/titanicExplorationGenderAge-1} 

}

\caption{Survival status in groups defined be Gender and Age for the Titanic data.}\label{fig:titanicExplorationGenderAge}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/titanicExplorationParch-1} 

}

\caption{Survival according to the number of parents/children and siblings/spouses in the Titanic data.}\label{fig:titanicExplorationParch}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/titanicExplorationClass-1} 

}

\caption{Survival according to the class and port of embarking in the Titanic data.}\label{fig:titanicExplorationClass}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/titanicExplorationCountry-1} 

}

\caption{Survival according to fare and country in the Titanic data.}\label{fig:titanicExplorationCountry}
\end{figure}

\hypertarget{model-titanic-lmr}{%
\subsection{Logistic regression model}\label{model-titanic-lmr}}

The dependent variable of interest, \emph{survival}, is binary. Thus, a natural choice is to start the predictive modelling with logistic regression model. As there is no reason to expect a linear relationship between age and odds of survival, we use linear tail-restricted cubic splines, available in the \texttt{rcs()} function of the \texttt{rms} package \citep{rms}, to model the effect of age. We also do not expect linear relation for the \texttt{fare} variable, but because of it's skewness, we do not use splines for this variable. The results of the model are stored in model-object \texttt{titanic\_lmr\_v6}, which will be used in subsequent chapters.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"rms"}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1313}\NormalTok{)}
\NormalTok{titanic_lmr_v6 <-}\StringTok{ }\KeywordTok{lrm}\NormalTok{(survived }\OperatorTok{==}\StringTok{ "yes"} \OperatorTok{~}\StringTok{ }\NormalTok{gender }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(age) }\OperatorTok{+}\StringTok{ }\NormalTok{class }\OperatorTok{+}
\StringTok{         }\NormalTok{sibsp }\OperatorTok{+}\StringTok{ }\NormalTok{parch }\OperatorTok{+}\StringTok{ }\NormalTok{fare }\OperatorTok{+}\StringTok{ }\NormalTok{embarked, titanic)}
\NormalTok{titanic_lmr_v6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Logistic Regression Model
##  
##  lrm(formula = survived == "yes" ~ gender + rcs(age) + class + 
##      sibsp + parch + fare + embarked, data = titanic)
##  
##                         Model Likelihood     Discrimination    Rank Discrim.    
##                            Ratio Test           Indexes           Indexes       
##  Obs           2207    LR chi2     752.06    R2       0.404    C       0.817    
##   FALSE        1496    d.f.            17    g        1.647    Dxy     0.635    
##   TRUE          711    Pr(> chi2) <0.0001    gr       5.191    gamma   0.636    
##  max |deriv| 0.0001                          gp       0.282    tau-a   0.277    
##                                              Brier    0.146                     
##  
##                         Coef    S.E.   Wald Z Pr(>|Z|)
##  Intercept               4.5746 0.5480   8.35 <0.0001 
##  gender=male            -2.7687 0.1586 -17.45 <0.0001 
##  age                    -0.1180 0.0221  -5.35 <0.0001 
##  age'                    0.6313 0.1628   3.88 0.0001  
##  age''                  -2.6583 0.7840  -3.39 0.0007  
##  age'''                  2.8977 1.0130   2.86 0.0042  
##  class=2nd              -1.1390 0.2501  -4.56 <0.0001 
##  class=3rd              -2.0627 0.2490  -8.28 <0.0001 
##  class=deck crew         1.0672 0.3498   3.05 0.0023  
##  class=engineering crew -0.9702 0.2648  -3.66 0.0002  
##  class=restaurant staff -3.1712 0.6583  -4.82 <0.0001 
##  class=victualling crew -1.0877 0.2596  -4.19 <0.0001 
##  sibsp                  -0.4504 0.1006  -4.48 <0.0001 
##  parch                  -0.0871 0.0987  -0.88 0.3776  
##  fare                    0.0014 0.0020   0.70 0.4842  
##  embarked=Cherbourg      0.7881 0.2836   2.78 0.0055  
##  embarked=Queenstown     0.2745 0.3409   0.80 0.4208  
##  embarked=Southampton    0.2343 0.2119   1.11 0.2689  
## 
\end{verbatim}

Note that our prime interest is not in the assessment of model performance, but rather in the understanding of model behavior. This is why we do not split the data into train/test subsets. The model is trained and will be explained on the whole dataset.

\hypertarget{model-titanic-rf}{%
\subsection{Random forest model}\label{model-titanic-rf}}

As a challenger to the logistic regression model, we consider a random forest model. Random forest is known for good predictive performance, is able to grasp low-order variable interactions, and is quite stable \citep{randomForestBreiman}. To fit the model, we apply the \texttt{randomForest()} function, with default settings, from the package with the same name \citep{randomForest}.

In the first instance, we fit a model with the same set of explanatory variables as the logistic regression model. The results of the model are stored in model-object \texttt{titanic\_rf\_v6}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1313}\NormalTok{)}
\NormalTok{titanic_rf_v6 <-}\StringTok{ }\KeywordTok{randomForest}\NormalTok{(survived }\OperatorTok{~}\StringTok{ }\NormalTok{class }\OperatorTok{+}\StringTok{ }\NormalTok{gender }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{sibsp }\OperatorTok{+}\StringTok{ }
\StringTok{         }\NormalTok{parch }\OperatorTok{+}\StringTok{ }\NormalTok{fare }\OperatorTok{+}\StringTok{ }\NormalTok{embarked, }\DataTypeTok{data =}\NormalTok{ titanic)}
\NormalTok{titanic_rf_v6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
##  randomForest(formula = survived ~ class + gender + age + sibsp +      parch + fare + embarked, data = titanic) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 18.62%
## Confusion matrix:
##       no yes class.error
## no  1393 103  0.06885027
## yes  308 403  0.43319269
\end{verbatim}

For comparison purposes, we also consider a model with only three explanatory variables: \emph{class}, \emph{gender}, and \emph{age}. The results of the model are stored in model-object \texttt{titanic\_rf\_v3}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic_rf_v3 <-}\StringTok{ }\KeywordTok{randomForest}\NormalTok{(survived }\OperatorTok{~}\StringTok{ }\NormalTok{class }\OperatorTok{+}\StringTok{ }\NormalTok{gender }\OperatorTok{+}\StringTok{ }\NormalTok{age, }
         \DataTypeTok{data =}\NormalTok{ titanic)}
\NormalTok{titanic_rf_v3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
##  randomForest(formula = survived ~ class + gender + age, data = titanic) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##         OOB estimate of  error rate: 21.02%
## Confusion matrix:
##       no yes class.error
## no  1367 129  0.08622995
## yes  335 376  0.47116737
\end{verbatim}

\hypertarget{model-titanic-gbm}{%
\subsection{Gradient boosting model}\label{model-titanic-gbm}}

Let's consider an another challenger -- the gradient-boosting model \citep{Friedman00greedyfunction}. The tree based boosting models are known for being able to accommodate higher-order interactions between variables. We use the same set of six explanatory variables as for the logistic regression model. To fit the gradient-boosting model, we use function \texttt{gbm()} from the \texttt{gbm} package \citep{gbm}. The results of the model are stored in model-object \texttt{titanic\_gbm\_v6}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"gbm"}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1313}\NormalTok{)}
\NormalTok{titanic_gbm_v6 <-}\StringTok{ }\KeywordTok{gbm}\NormalTok{(survived }\OperatorTok{==}\StringTok{ "yes"} \OperatorTok{~}\StringTok{ }\NormalTok{class }\OperatorTok{+}\StringTok{ }\NormalTok{gender }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{sibsp }\OperatorTok{+}\StringTok{ }
\StringTok{         }\NormalTok{parch }\OperatorTok{+}\StringTok{ }\NormalTok{fare }\OperatorTok{+}\StringTok{ }\NormalTok{embarked, }\DataTypeTok{data =}\NormalTok{ titanic, }\DataTypeTok{n.trees =} \DecValTok{15000}\NormalTok{, }
         \DataTypeTok{distribution =} \StringTok{"bernoulli"}\NormalTok{)}
\NormalTok{titanic_gbm_v6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## gbm(formula = survived == "yes" ~ class + gender + age + sibsp + 
##     parch + fare + embarked, distribution = "bernoulli", data = titanic, 
##     n.trees = 15000)
## A gradient boosted model with bernoulli loss function.
## 15000 iterations were performed.
## There were 7 predictors of which 7 had non-zero influence.
\end{verbatim}

\hypertarget{model-titanic-svm}{%
\subsection{Support Vector Machine model}\label{model-titanic-svm}}

Finally, we consider also Support Vector Machine model \citep{svm95vapnik}. We use the C-classification mode. To fit the Support Vector Machine model, we use function \texttt{svm()} from the \texttt{e1071} package \citep{e1071}. The results of the model are stored in model-object \texttt{titanic\_svm\_v6}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"e1071"}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1313}\NormalTok{)}
\NormalTok{titanic_svm_v6 <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(survived }\OperatorTok{==}\StringTok{ "yes"} \OperatorTok{~}\StringTok{ }\NormalTok{class }\OperatorTok{+}\StringTok{ }\NormalTok{gender }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{sibsp }\OperatorTok{+}
\StringTok{            }\NormalTok{parch }\OperatorTok{+}\StringTok{ }\NormalTok{fare }\OperatorTok{+}\StringTok{ }\NormalTok{embarked, }\DataTypeTok{data =}\NormalTok{ titanic, }
            \DataTypeTok{type =} \StringTok{"C-classification"}\NormalTok{, }\DataTypeTok{probability =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{titanic_svm_v6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## svm(formula = survived == "yes" ~ class + gender + age + sibsp + 
##     parch + fare + embarked, data = titanic, type = "C-classification", 
##     probability = TRUE)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  radial 
##        cost:  1 
## 
## Number of Support Vectors:  1030
\end{verbatim}

\hypertarget{predictions-titanic}{%
\subsection{Model predictions}\label{predictions-titanic}}

Let us now compare predictions that are obtained from the three different models. In particular, we will compute the predicted probability of survival for an 8-year-old boy who embarked in Belfast and travelled in the 1-st class with no parents nor siblings and with a ticket costing 72 pounds.

First, we create a dataframe \texttt{johny\_d} that contains the data describing the passenger.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{johny_d <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
            \DataTypeTok{class =} \KeywordTok{factor}\NormalTok{(}\StringTok{"1st"}\NormalTok{, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"1st"}\NormalTok{, }\StringTok{"2nd"}\NormalTok{, }\StringTok{"3rd"}\NormalTok{, }\StringTok{"deck crew"}\NormalTok{,}
                        \StringTok{"engineering crew"}\NormalTok{, }\StringTok{"restaurant staff"}\NormalTok{, }\StringTok{"victualling crew"}\NormalTok{)),}
            \DataTypeTok{gender =} \KeywordTok{factor}\NormalTok{(}\StringTok{"male"}\NormalTok{, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"female"}\NormalTok{, }\StringTok{"male"}\NormalTok{)),}
            \DataTypeTok{age =} \DecValTok{8}\NormalTok{,}
            \DataTypeTok{sibsp =} \DecValTok{0}\NormalTok{,}
            \DataTypeTok{parch =} \DecValTok{0}\NormalTok{,}
            \DataTypeTok{fare =} \DecValTok{72}\NormalTok{,}
            \DataTypeTok{embarked =} \KeywordTok{factor}\NormalTok{(}\StringTok{"Southampton"}\NormalTok{, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Belfast"}\NormalTok{,}
                        \StringTok{"Cherbourg"}\NormalTok{,}\StringTok{"Queenstown"}\NormalTok{,}\StringTok{"Southampton"}\NormalTok{))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Subsequently, we use the generic function \texttt{predict()} to get the predicted probability of survival for the logistic regression model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(pred_lmr <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(titanic_lmr_v6, johny_d, }\DataTypeTok{type =} \StringTok{"fitted"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         1 
## 0.7677036
\end{verbatim}

The predicted probability is equal to 0.77.

We do the same for the random forest and gradient boosting models.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(pred_rf <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(titanic_rf_v6, johny_d, }\DataTypeTok{type =} \StringTok{"prob"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      no   yes
## 1 0.578 0.422
## attr(,"class")
## [1] "matrix" "votes"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(pred_gbm <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(titanic_gbm_v6, johny_d, }\DataTypeTok{type =} \StringTok{"response"}\NormalTok{, }\DataTypeTok{n.trees =} \DecValTok{15000}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6632574
\end{verbatim}

As a result, we obtain the predicted probabilities of 0.42 and 0.66, respectively.

The models lead to different probabilities. Thus, it might be of interest to understand the reason for the differences, as it could help us to decide which of the predictions we might want to trust.

Note that for some examples we will use another observation (instance) with lower chances of survival. Let's call this passenger Henry.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{henry <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
         \DataTypeTok{class =} \KeywordTok{factor}\NormalTok{(}\StringTok{"1st"}\NormalTok{, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"1st"}\NormalTok{, }\StringTok{"2nd"}\NormalTok{, }\StringTok{"3rd"}\NormalTok{, }\StringTok{"deck crew"}\NormalTok{, }
                     \StringTok{"engineering crew"}\NormalTok{, }\StringTok{"restaurant staff"}\NormalTok{, }\StringTok{"victualling crew"}\NormalTok{)),}
         \DataTypeTok{gender =} \KeywordTok{factor}\NormalTok{(}\StringTok{"male"}\NormalTok{, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"female"}\NormalTok{, }\StringTok{"male"}\NormalTok{)),}
         \DataTypeTok{age =} \DecValTok{47}\NormalTok{,}
         \DataTypeTok{sibsp =} \DecValTok{0}\NormalTok{,}
         \DataTypeTok{parch =} \DecValTok{0}\NormalTok{,}
         \DataTypeTok{fare =} \DecValTok{25}\NormalTok{,}
         \DataTypeTok{embarked =} \KeywordTok{factor}\NormalTok{(}\StringTok{"Cherbourg"}\NormalTok{, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Belfast"}\NormalTok{,}
                           \StringTok{"Cherbourg"}\NormalTok{,}\StringTok{"Queenstown"}\NormalTok{,}\StringTok{"Southampton"}\NormalTok{))}
\NormalTok{)}
\KeywordTok{predict}\NormalTok{(titanic_lmr_v6, henry, }\DataTypeTok{type =} \StringTok{"fitted"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         1 
## 0.4318245
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(titanic_rf_v6, henry, }\DataTypeTok{type =} \StringTok{"prob"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      no   yes
## 1 0.754 0.246
## attr(,"class")
## [1] "matrix" "votes"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(titanic_gbm_v6, henry, }\DataTypeTok{type =} \StringTok{"response"}\NormalTok{, }\DataTypeTok{n.trees =} \DecValTok{15000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3073358
\end{verbatim}

\hypertarget{ExplainersTitanicRCode}{%
\subsection{Model adapters}\label{ExplainersTitanicRCode}}

Model-objects created with different machine learning libraries may have different internal structures. Thus, first, we have got to create an adapter for the model that provides an uniform interface. Toward this end, we use the \texttt{explain()} function from the \texttt{DALEX} package \citep{DALEX}. The function requires five arguments:

\begin{itemize}
\tightlist
\item
  \texttt{model}, a model-object;
\item
  \texttt{data}, a validation data frame;
\item
  \texttt{y}, observed values of the dependent variable for the validation data;
\item
  \texttt{predict\_function}, a function that returns prediction scores; if not specified, then a default \texttt{predict()} function is used;
\item
  \texttt{label}, an unique name of the model; if not specified, then it is extracted from the \texttt{class(model)}.
\end{itemize}

Each adapter contains all elements needed to create a model explanation, i.e., a suitable \texttt{predict()} function, validation data set, and the model object. Thus, in subsequent chapters we will use the explainers instead of the model objects to keep code snippets more concise.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explain_titanic_lmr_v6 <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ titanic_lmr_v6, }
                                 \DataTypeTok{data =}\NormalTok{ titanic[, }\DecValTok{-9}\NormalTok{],}
                                 \DataTypeTok{y =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{survived }\OperatorTok{==}\StringTok{ "yes"}\NormalTok{, }
                                 \DataTypeTok{label =} \StringTok{"Logistic Regression"}\NormalTok{)}
\NormalTok{explain_titanic_lmr_v6}\OperatorTok{$}\NormalTok{model_info}\OperatorTok{$}\NormalTok{type =}\StringTok{ "classification"}
\NormalTok{explain_titanic_rf_v6 <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ titanic_rf_v6, }
                                 \DataTypeTok{data =}\NormalTok{ titanic[, }\DecValTok{-9}\NormalTok{],}
                                 \DataTypeTok{y =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{survived }\OperatorTok{==}\StringTok{ "yes"}\NormalTok{, }
                                 \DataTypeTok{label =} \StringTok{"Random Forest"}\NormalTok{)}
\NormalTok{explain_titanic_rf_v3 <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ titanic_rf_v3, }
                                 \DataTypeTok{data =}\NormalTok{ titanic[, }\DecValTok{-9}\NormalTok{],}
                                 \DataTypeTok{y =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{survived }\OperatorTok{==}\StringTok{ "yes"}\NormalTok{, }
                                 \DataTypeTok{label =} \StringTok{"Random Forest small"}\NormalTok{)}
\NormalTok{explain_titanic_gbm_v6 <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ titanic_gbm_v6, }
                                 \DataTypeTok{data =}\NormalTok{ titanic[, }\DecValTok{-9}\NormalTok{],}
                                 \DataTypeTok{y =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{survived }\OperatorTok{==}\StringTok{ "yes"}\NormalTok{, }
                                 \DataTypeTok{label =} \StringTok{"Generalized Boosted Regression"}\NormalTok{)}
\NormalTok{explain_titanic_svm_v6 <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ titanic_svm_v6, }
                                 \DataTypeTok{data =}\NormalTok{ titanic[, }\DecValTok{-9}\NormalTok{],}
                                 \DataTypeTok{y =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{survived }\OperatorTok{==}\StringTok{ "yes"}\NormalTok{, }
                                 \DataTypeTok{label =} \StringTok{"Support Vector Machine"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{ListOfModelsTitanic}{%
\subsection{\texorpdfstring{List of objects for the \texttt{titanic} example}{List of objects for the titanic example}}\label{ListOfModelsTitanic}}

In the previous sections we have built four predictive models for the \texttt{titanic} data set. The models will be used in the rest of the book to illustrate the model explanation methods and tools.

For the ease of reference, we summarize the models in Table \ref{tab:archivistHooksOfModelsTitanic}. The binary model-objects can be downloaded by using the indicated \texttt{archivist} hooks \citep{archivist}. By calling a function specified in the last column of the table, one can restore a selected model in its local R environment.

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:archivistHooksOfModelsTitanic} Predictive models created for the \texttt{titanic} dataset.}\tabularnewline
\toprule
\begin{minipage}[b]{0.21\columnwidth}\raggedright
Model name\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Model generator\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright
Variables\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Archivist hooks\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.21\columnwidth}\raggedright
Model name\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Model generator\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright
Variables\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Archivist hooks\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{titanic\_lmr\_v6}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\texttt{rms::\ lmr} v.5.1.3\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
gender, age, class, sibsp, parch, fare, embarked\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Get the model: \texttt{archivist::\ aread("pbiecek/models/56d8a")}. Get the explainer: \texttt{archivist::\ aread("pbiecek/models/ff1cd")}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{titanic\_rf\_v6}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\texttt{randomForest::\ randomForest} v.4.6.14\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
gender, age, class, sibsp, parch, fare, embarked\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Get the model: \texttt{archivist::\ aread("pbiecek/models/31570")}. Get the explainer: \texttt{archivist::\ aread("pbiecek/models/6ed54")}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{titanic\_rf\_v3}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\texttt{randomForest::\ randomForest} v.4.6.14\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
gender, age, class\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Get the model: \texttt{archivist::\ aread("pbiecek/models/855c1")}. Get the explainer: \texttt{archivist::\ aread("pbiecek/models/5b32a")}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{titanic\_gbm\_v6}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\texttt{gbm::\ gbm} v.2.1.5\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
gender, age, class, sibsp, parch, fare, embarked\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Get the model: \texttt{archivist::\ aread("pbiecek/models/08544")}. Get the explainer: \texttt{archivist::\ aread("pbiecek/models/87271")}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{titanic\_svm\_v6}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\texttt{e1071::\ svm} 1.7-2\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
gender, age, class, sibsp, parch, fare, embarked\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Get the model: \texttt{archivist::\ aread("pbiecek/models/be26e")}. Get the explainer: \texttt{archivist::\ aread("pbiecek/models/21966")}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Table \ref{tab:archivistHooksOfDataFramesTitanic} summarizes the data frames that will be used in examples in the subsequent chapters.

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:archivistHooksOfDataFramesTitanic} Data frames created for the \texttt{titanic} example.}\tabularnewline
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright
Description\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright
No.~rows\strut
\end{minipage} & \begin{minipage}[b]{0.19\columnwidth}\raggedright
Variables\strut
\end{minipage} & \begin{minipage}[b]{0.33\columnwidth}\raggedright
Link to this object\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright
Description\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright
No.~rows\strut
\end{minipage} & \begin{minipage}[b]{0.19\columnwidth}\raggedright
Variables\strut
\end{minipage} & \begin{minipage}[b]{0.33\columnwidth}\raggedright
Link to this object\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{titanic} dataset with imputed missing values\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
2207\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
gender, age, class, embarked, country, fare, sibsp, parch, survived\strut
\end{minipage} & \begin{minipage}[t]{0.33\columnwidth}\raggedright
\texttt{archivist::\ aread("pbiecek/models/27e5c")}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{johny\_d} 8-year-old boy that travelled in the 1st class without parents\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
class, gender, age, sibsp, parch, fare, embarked\strut
\end{minipage} & \begin{minipage}[t]{0.33\columnwidth}\raggedright
\texttt{archivist::\ aread("pbiecek/models/e3596")}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{henry} 47-year-old male passenger from the 1st class, paid 25 pounds and embarked at Cherbourg\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.19\columnwidth}\raggedright
class, gender, age, sibsp, parch, fare, embarked\strut
\end{minipage} & \begin{minipage}[t]{0.33\columnwidth}\raggedright
\texttt{archivist::\ aread("pbiecek/models/a6538")}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{ApartmentDataset}{%
\section{Apartment prices}\label{ApartmentDataset}}

\begin{figure}
\centering
\includegraphics{figure/am1974_flicker.jpg}
\caption{Warsaw skyscrapers by Artur Malinowski Flicker}
\end{figure}

Predicting house prices is a common exercise used in machine-learning courses. Various datasets for house prices are available at websites like Kaggle (\url{https://www.kaggle.com}) or UCI Machine Learning Repository (\url{https://archive.ics.uci.edu}).

In this book, we will work with an interesting variant of this problem. The \texttt{apartments} dataset is an artificial dataset created to match key characteristics of real apartments in Warsaw, the capital of Poland. However, the dataset is created in a way that two very different models, namely linear regression and random forest, have almost exactly the same accuracy. The natural question is then: which model should we choose? We will show that the model-explanation tools provide important insight into the key model characteristics and are helpful in model selection.

The dataset is available in the \texttt{DALEX} package \citep{DALEX}. It contains 1000 observations (apartments) and six variables:

\begin{itemize}
\tightlist
\item
  \emph{m2.price}, apartments price per meter-squared (in EUR), a numerical variable range 1607 -- 6595;
\item
  \emph{construction.year}, the year of construction of the block of flats in which the apartment is located, a numerical variable range 1920 -- 2010;
\item
  \emph{surface}, apartment's total surface in square meters, a numerical variable range 20 -- 150;
\item
  \emph{floor}, the floor at which the apartment is located (ground floor taken to be the first floor), a numerical integer variable with values from 1 to 10;
\item
  \emph{no.rooms}, the total number of rooms, a numerical variable with values from 1 to 6;
\item
  \emph{district}, a factor with 10 levels indicating the district of Warsaw where the apartment is located.
\end{itemize}

The R code below provides more info about the contents of the dataset, values of the variables, etc.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(apartments, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   m2.price construction.year surface floor no.rooms    district
## 1     5897              1953      25     3        1 Srodmiescie
## 2     1818              1992     143     9        5     Bielany
\end{verbatim}

Models considered for this dataset will use \emph{m2.price} as the (continuous) dependent variable.

Model predictions will be obtained for a set of six apartments included in data frame \texttt{apartments\_test}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(apartments_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      m2.price construction.year surface floor no.rooms    district
## 1001     4644              1976     131     3        5 Srodmiescie
## 1002     3082              1978     112     9        4     Mokotow
## 1003     2498              1958     100     7        4     Bielany
## 1004     2735              1951     112     3        5        Wola
## 1005     2781              1978     102     4        4      Bemowo
## 1006     2936              2001     116     7        4      Bemowo
\end{verbatim}

\hypertarget{exploration-apartments}{%
\subsection{Data exploration}\label{exploration-apartments}}

Note that \texttt{apartments} is an artificial dataset created to illustrate and explain differences between random forest and linear regression. Hence, the structure of the data, the form and strength of association between variables, plausibility of distributional assumptions, etc., is better than in a real-life dataset. In fact, all these characteristics of the data are known. Nevertheless, we conduct some data exploration to illustrate the important aspects of the data.

The variable of interest is \emph{m2.price}, the price per meter-squared. The histogram presented in Figure \ref{fig:appartmentsExplorationMi2} indicates that the distribution of the variable is slightly skewed to the right.
\includegraphics{ema_files/figure-latex/appartmentsExplorationMi2-1.pdf}

Figure \ref{fig:appartmentsMi2Construction} suggests (possibly) a nonlinear relation between \emph{construction.year} and \emph{m2.price} and a linear relation between \emph{surface} and \emph{m2.price}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/appartmentsMi2Construction-1} 

}

\caption{Left panel shows apartment price per m2 vs. year of construction, right panel shows price  vs. square footage}\label{fig:appartmentsMi2Construction}
\end{figure}

Relation between \emph{floor} and \emph{m2.price} is also close to linear, as well as relation between \emph{no.rooms} and \emph{m2.price} as seen in Figure \ref{fig:appartmentsMi2Floor}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/appartmentsMi2Floor-1} 

}

\caption{Price per meter-squared vs. floor and vs. number of rooms.}\label{fig:appartmentsMi2Floor}
\end{figure}

Surface and number of rooms are correlated and prices depend on district. Boxplots plots in Figure \ref{fig:appartmentsSurfaceNorooms} indicate that the highest prices per meter-squared are observed in Srodmiescie (Downtown).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/appartmentsSurfaceNorooms-1} 

}

\caption{Left panel: surface vs. number of rooms. Right panel: price per meter-squared for different districts}\label{fig:appartmentsSurfaceNorooms}
\end{figure}

\hypertarget{model-Apartments-lr}{%
\subsection{Linear regression model}\label{model-Apartments-lr}}

The dependent variable of interest, \emph{m2.price}, is continuous. Thus, a natural choice to build a predictive model is the linear regression. We treat all the other variables in the \texttt{apartments} dataframe as explanatory and include them in the model. The results of the model are stored in model-object \texttt{apartments\_lm\_v5}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{apartments_lm_v5 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(m2.price }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ apartments)}
\KeywordTok{anova}\NormalTok{(apartments_lm_v5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: m2.price
##                    Df    Sum Sq   Mean Sq  F value    Pr(>F)    
## construction.year   1   2629802   2629802   33.233 1.093e-08 ***
## surface             1 207840733 207840733 2626.541 < 2.2e-16 ***
## floor               1  79823027  79823027 1008.746 < 2.2e-16 ***
## no.rooms            1    956996    956996   12.094  0.000528 ***
## district            9 451993980  50221553  634.664 < 2.2e-16 ***
## Residuals         986  78023123     79131                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\hypertarget{model-Apartments-rf}{%
\subsection{Random forest model}\label{model-Apartments-rf}}

As a challenger to linear regression, we consider a random forest model. To fit the model, we apply the \texttt{randomForest()} function, with default settings, from the package with the same name \citep{randomForest}.\\
The results of the model are stored in model-object \texttt{apartments\_rf\_v5}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{72}\NormalTok{)}
\NormalTok{apartments_rf_v5 <-}\StringTok{ }\KeywordTok{randomForest}\NormalTok{(m2.price }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ apartments)}
\NormalTok{apartments_rf_v5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
##  randomForest(formula = m2.price ~ ., data = apartments) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##           Mean of squared residuals: 79789.39
##                     % Var explained: 90.28
\end{verbatim}

\hypertarget{model-Apartments-svm}{%
\subsection{Support vector model}\label{model-Apartments-svm}}

As an another challenger to the linear regression model, we consider a Support Vector Machines model. To fit the model, we use the \texttt{svm()} function, with default settings, from the package \texttt{e1071} \citep{R-e1071}.\\
The results of the model are stored in model-object \texttt{apartments\_svm\_v5}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"e1071"}\NormalTok{)}
\NormalTok{apartments_svm_v5 <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(m2.price }\OperatorTok{~}\StringTok{ }\NormalTok{construction.year }\OperatorTok{+}\StringTok{ }\NormalTok{surface }\OperatorTok{+}\StringTok{ }\NormalTok{floor }\OperatorTok{+}\StringTok{ }
\StringTok{         }\NormalTok{no.rooms }\OperatorTok{+}\StringTok{ }\NormalTok{district, }\DataTypeTok{data =}\NormalTok{ apartments)}
\NormalTok{apartments_svm_v5}
\end{Highlighting}
\end{Shaded}

\hypertarget{predictionsApartments}{%
\subsection{Model predictions}\label{predictionsApartments}}

The \texttt{predict()} function calculates predictions for a specific model. In the example below we use model-object \texttt{apartments\_lm\_v5} to calculate predictions for prices for first six rows.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(apartments_lm_v5, apartments_test[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{, ])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     1001     1002     1003     1004     1005     1006 
## 4820.009 3292.678 2717.910 2922.751 2974.086 2527.043
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(apartments_rf_v5, apartments_test[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{, ])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     1001     1002     1003     1004     1005     1006 
## 3399.854 2545.792 2695.787 2748.969 3682.974 3739.780
\end{verbatim}

In the example below we calculate predictive performance for \texttt{apartments\_lm\_v5} and \texttt{apartments\_rf\_v5} as the square root of the average of squared errors (RMSE).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predicted_apartments_lm <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(apartments_lm_v5, apartments_test)}
\NormalTok{(rmsd_lm <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((predicted_apartments_lm }\OperatorTok{-}\StringTok{ }\NormalTok{apartments_test}\OperatorTok{$}\NormalTok{m2.price)}\OperatorTok{^}\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 283.0865
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predicted_apartments_rf <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(apartments_rf_v5, apartments_test)}
\NormalTok{(rmsd_rf <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((predicted_apartments_rf }\OperatorTok{-}\StringTok{ }\NormalTok{apartments_test}\OperatorTok{$}\NormalTok{m2.price)}\OperatorTok{^}\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 795.2587
\end{verbatim}

For the random forest model, the root-mean-square of the mean squared difference is equal to 795.3. It is almost identical as root-mean-square for the linear regression model 283.1. Thus, the question we may face is: should we choose the more complex, but flexible random-forest model, or the simpler and easier to interpret linear model? In the subsequent chapters we will try to provide an answer to this question.

As we will show in following chapters, a proper model exploration helps to understand which model we should choose. And even more, it helps to understand weak and strong sides of both models and in consequence we can create a new model better than these two.

\hypertarget{ExplainersApartmentsRCode}{%
\subsection{Model adapters}\label{ExplainersApartmentsRCode}}

In similar spirit to the Section \ref{ExplainersTitanicRCode} we will use explainers also for predictive models created for the \texttt{apartments} dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explain_apartments_lm_v5 <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ apartments_lm_v5, }
         \DataTypeTok{data =}\NormalTok{ apartments_test, }\DataTypeTok{y =}\NormalTok{ apartments_test}\OperatorTok{$}\NormalTok{m2.price,}
         \DataTypeTok{label =} \StringTok{"Linear Regression"}\NormalTok{)}
\NormalTok{explain_apartments_rf_v5 <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ apartments_rf_v5, }
         \DataTypeTok{data =}\NormalTok{ apartments_test, }\DataTypeTok{y =}\NormalTok{ apartments_test}\OperatorTok{$}\NormalTok{m2.price,}
         \DataTypeTok{label =} \StringTok{"Random Forest"}\NormalTok{)}
\NormalTok{explain_apartments_svm_v5 <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ apartments_svm_v5, }
         \DataTypeTok{data =}\NormalTok{ apartments_test, }\DataTypeTok{y =}\NormalTok{ apartments_test}\OperatorTok{$}\NormalTok{m2.price,}
         \DataTypeTok{label =} \StringTok{"Support Vector Machines"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{ListOfModelsApartments}{%
\subsection{\texorpdfstring{List of objects for the \texttt{apartments} example}{List of objects for the apartments example}}\label{ListOfModelsApartments}}

In Sections \ref{model-Apartments-lr} and \ref{model-Apartments-rf} we have built two predictive models for the \texttt{apartments} data set. The models will be used in the rest of the book to illustrate the model explanation methods and tools.

For the ease of reference, we summarize the models in Table \ref{tab:archivistHooksOfModelsApartments}. The binary model-objects can be downloaded by using the indicated \texttt{archivist} hooks \citep{archivist}. By calling a function specified in the last column of the table, one can restore a selected model in a local R environment.

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:archivistHooksOfModelsApartments} Predictive models created for the \texttt{apartments} dataset.}\tabularnewline
\toprule
\begin{minipage}[b]{0.21\columnwidth}\raggedright
Model name\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Model generator\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright
Variables\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Archivist hooks\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.21\columnwidth}\raggedright
Model name\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Model generator\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright
Variables\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
Archivist hooks\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{apartments\_lm\_v5}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\texttt{stats::\ lm} v.3.5.3\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
construction .year, surface, floor, no.rooms, district\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Get the model: \texttt{archivist::\ aread("pbiecek/models/55f19")}. Get the explainer: \texttt{archivist::\ aread("pbiecek/models/78d4e")}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{apartments\_rf\_v5}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\texttt{randomForest::\ randomForest} v.4.6.14\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
construction .year, surface, floor, no.rooms, district\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Get the model: \texttt{archivist::\ aread("pbiecek/models/fe7a5")}. Get the explainer: \texttt{archivist::\ aread("pbiecek/models/b1739")}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\texttt{apartments\_svm\_v5}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\texttt{e1071::\ svm} v.1.7-2\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright
construction .year, surface, floor, no.rooms, district\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
Get the model: \texttt{archivist::\ aread("pbiecek/models/545fa")}. Get the explainer: \texttt{archivist::\ aread("pbiecek/models/16602")}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{instance-level}{%
\chapter*{Instance Level}\label{instance-level}}
\addcontentsline{toc}{chapter}{Instance Level}

\begin{center}\includegraphics[width=0.99\linewidth]{figure/UMEPpiramideInstance} \end{center}

\hypertarget{InstanceLevelExploration}{%
\chapter{Introduction to Instance Level Exploration}\label{InstanceLevelExploration}}

Instance-level methods help to understand how a model yields a prediction for a single observation. We can think about the following situations as examples:

\begin{itemize}
\tightlist
\item
  We may want to evaluate the effects of explanatory variables on model predictions. For instance, we may be interested in predicting the risk of heart attack based on person's age, sex, and smoking habits. A model may be used to construct a score (for instance, a linear combination of the explanatory variables representing age, sex, and smoking habits) that could be used for the purposes of prediction. For a particular patient we may want to learn how much the different variables contribute to the score of an individual patient?
\item
  We may want to understand how models predictions would change if values of some of the explanatory variables changed. For instance, what would be the predicted risk of heart attack if the patient cut the number of cigarettes smoked per day by half?
\item
  We may discover that the model is providing incorrect predictions and we may want to find the reason. For instance, a patient with a very low risk-score experienced a heart attack. What has driven the wrong prediction?
\end{itemize}

A model is a function with a \(p\)-dimensional vector \(x\) as an argument. Instance level methods are designed to explore the model around a single point of interest \(x^*\). In the following sections we will describe the most popular approaches to such exploration. They can be divided into three classes.

\begin{itemize}
\tightlist
\item
  One approach is to analyze how the model prediction for point \(x^*\) is different from the average model prediction and how the difference can be distributed among explanatory variables. It is often called the ,,variable attributions'' approach. An example is provided in panel A of Figure \ref{fig:cutsTechnikiReady}. Chapters \ref{breakDown}-\ref{shapley} present various methods implementing this approach.
\item
  Another approach is to analyze the curvature of the response surface around the point of interest \(x^*\). Treating the model as a function, we are interested in the local behavior of this function around \(x^*\). In case of a black-box model, we may approximate it with a simpler glass-box model around \(x^*\). An example is provided in panel B of Figure \ref{fig:cutsTechnikiReady}. Chapter \ref{LIME} presents the Local Interpretable Model-agnostic Explanations (LIME) method that exploits the concept of a ,,local model''.
\item
  Yet another approach is to investigate how the model prediction changes if the value of a single explanatory variable changes. The approach is useful in the so-called ,,What-If'' analyses. In particular, we can construct plots presenting the change in model-based predictions induced by a change of a single variable. Such plots are usually called Ceteris-paribus (CP) profiles. An example is provided in panel C in Figure \ref{fig:cutsTechnikiReady}. Chapters \ref{ceterisParibus}-\ref{localDiagnostics} introduce the CP profiles and methods based on them.
\end{itemize}

Each method has its own merits and limitations. They are briefly discussed in the corresponding chapters. Chapter \ref{summaryInstanceLevel} offers a comparison of the methods.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figure/cuts_techniki_ready} 

}

\caption{Response surface for a model that is a function of two variables. We are interested in understanding the response of a model in a single point x*. Illustration of different approaches to instance-level explanation. Panel A illustrates the concept of variable attributions like Break Down or SHAP. Additive effects of each variable show how the model response differs from the average. Panel B illustrates the concept of explanations through local models e.g. LIME. A simpler glass-box model is fitted around the point of interest. It describes the local behaviour of the black-box model. Panel C presents a What-If analysis with Ceteris-paribus profiles. The profiles show the model response as a function of a value of a single variable, while keeping the values of all other explanatory variables fixed.}\label{fig:cutsTechnikiReady}
\end{figure}

\hypertarget{breakDown}{%
\chapter{Break-down Plots for Additive Attributions}\label{breakDown}}

Probably the most common question related to the explanation of model prediction for a single instance is: \emph{which variables contributed to this result the most?}

Unfortunately, there is no silver bullet.
Fortunately, there are some bullets.
In this chapter we introduce Break-down (BD) plots, which offer a solution to this problem. Next two chapters are related to extensions of BD plot. Finally, Chapter \ref{LIME} offer a different approach to this problem.
The goal for BD plots is to show ``variables attributions'' i.e., the decomposition of the model prediction among explanatory variables.

\hypertarget{BDIntuition}{%
\section{Intuition}\label{BDIntuition}}

The underlying idea is to calculate contribution of an explanatory variable \(x^i\) to model's prediction \(f(x)\) as a shift in the expected model response after conditioning on other variables.

This idea is illustrated in Figure \ref{fig:BDPrice4}. Consider an example related to the prediction for the random-forest model \texttt{model\_rf\_v6} for Titanic data (see Section \ref{model-titanic-rf}). We are interested in chances of survival for \texttt{johny\_d} - an 8-years old passenger from first class. Panel A shows distribution of model predictions for all 2207 instances from dataset \(X\). The row \texttt{all\ data} shows the vioplot of the predictions for the entire dataset. The red dot indicates the average and it is an estimate of the expected model prediction \(E_X[f(X)]\) over the distribution of all explanatory variables. In this example the average model response is 23.5\%.

To evaluate the contribution of the explanatory variables to the particular instance prediction, we trace changes in model predictions when fixing the values of consecutive variables. For instance, the row \texttt{class=1st} in Panel A of Figure \ref{fig:BDPrice4} presents the distribution of the predictions obtained when the value of the \texttt{class} variable has been fixed to the \texttt{1st} class. Again, the red dot indicates the average of the predictions. The next row \texttt{age=8} shows the distribution and the average predictions with the value of variable \texttt{class} set to \texttt{1st} and \texttt{age} set to \texttt{8}, and so on. With this procedure after \(p\) steps every row in \(X\) will be filled up with variable values of \texttt{johny\_d}. All predictions for these rows will be equal, so the last row in the Figure corresponds to the prediction for \texttt{model\ response} for \texttt{johny\_d}.

The thin black lines in Panel A show how the individual prediction for a single person changes after the value of the \(j\)-th variable has been replaced by the value indicated in the name of the row.

As we see from lines between first and the second row, the conditioning over \texttt{class=1st} has different effect on different instances. For some the model prediction has not changes (probably these passengers were already in the 1st class). For some the model prediction increase (probably they were in 2nd or 3rd class) while for other passenger the model prediction decreases (probably these were desk crew members).

Eventually, however, we may be interested in the average predictions, as indicated in Panel B of Figure \ref{fig:BDPrice4}, or even only in the changes of the averages, as shown in Panel C. In Panel C, positive changes are presented with green bars, while negative differences are marked with red bar.
The changes sum up to the final prediction, which is illustrated by the violet bar at the bottom of Panel C.

What can be learned from Break-down plots? In this case we have concise summary of effects of particular variables on expected model response.
First, we see that average model response is 23.5 percent. These are odds of survival averaged over all people on Titanic. Note that it is not the fraction of people that survived, but the average model response, so for different models one can get different averages.
The model prediction for Johny D is 42.2 percent. It is much higher than an average prediction. Two variables that influence this prediction the most are class (=1st) and age (=8). Setting these two variables increase average model prediction by 33.5 percent points. Values in all other variables have rather negative effect. Low fare and being a male diminish odds of survival predicted by the model. Other variables do not change model predictions that much.
Note that value of variable attribution depends on the value not only a variable itself. In this example the \texttt{embarked\ =\ Southampton} has small effect on average model prediction. It may be because the variable \texttt{embarked} is not important or it is possible that variable \texttt{embarked} is important but \texttt{Southampton} has an average effect out of all other possible values of the \texttt{embarked} variable.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/break_down_distr} 

}

\caption{Break-down plots show how the contribution of individual explanatory variables change the average model prediction to the prediction for a single instance (observation). Panel A) The first row shows the distribution and the average (red dot) of model predictions for all data. The next rows show the distribution and the average of the predictions when fixing values of subsequent explanatory variables. The last row shows the prediction for a particular instance of interest. B) Red dots indicate the average predictions from Panel A. C) The green and red bars indicate, respectively, positive and negative changes in the average predictions (variable contributions). }\label{fig:BDPrice4}
\end{figure}

\hypertarget{BDMethod}{%
\section{Method}\label{BDMethod}}

First, let's see how variable attribution works for linear models. Because of the simple and additive structure of linear models it will be easier to build some intuitions.

\hypertarget{break-down-for-linear-models}{%
\subsection{Break-down for linear models}\label{break-down-for-linear-models}}

Assume a classical linear model for response \(y\) with \(p\) explanatory variables collected in the vector \(X = (X^1, X^2, \ldots, X^p)\) and coefficients \(\beta = (\beta^0, \beta^1, .., \beta^p)\), where \(\beta^0\) is the intercept. The prediction for \(y\) at point \(x=(x^1, x^2, \ldots, x^p)\) is given by the expected value of \(Y\) conditional on \(X=x\). For a linear model, the expected value is given by the following linear combination:

\[
E_Y(y | x) = f(x) = \beta^0 + x^1 \beta^1 + \ldots + x^p \beta^p.
\]

Now assume that we selected a single point from the input space \(x_* \in \mathcal R^p\).
We are interested in the contribution of the \(i\)-th explanatory variable to model prediction \(f(x_*)\) for a single observation described by \(x_*\). Because of additive structure of the linear model we expect that this contribution will be somehow linked to \(x_*^i\beta^i\), because the \(i\)-th variable occurs only in this term. As it will become clear in the sequel, it is easier to interpret the variable's contribution if \(x^i\) is centered by subtracting a constant \(\hat x^i\) (usually, the mean of \(x^i\)). This leads the following, proposition for the variable attribution:

\begin{equation}
v(i, x_*) = \beta^i (x^i_* - \bar x^i).
\label{eq:singleBreakDownContribution}
\end{equation}

Here \(v(x_*, i)\) is the contribution of the \(i\)-th explanatory variable to the prediction of model \(f()\) at point \(x_*\). Assume that \(E_Y(y | x_*) \approx f(x_*)\), where \(f(x_*)\) is the value of the model at \(x_*\). A possible approach to define \(v(x_*, i)\) is to measure how much the expected model response changes after conditioning on \(x^i_*\):

\begin{equation}
v(i, x_*) = E_Y(y | x_*) - E_{X^i}\{E_Y[y | (x^1_*,\ldots,x^{i-1}_*,X^i,x^{i+1}_*,x^p_*)]\}\approx f(x_*) - E_{X^i}[f(x^{-i}_*)],
\end{equation}

where \(x^{-i}_*\) indicates that variable \(X^i\) in vector \(x_*\) is treated as random. For the classical linear model, if the explanatory variables are independent, \(v(x_*, i)\) can be expressed as follows:

\begin{equation}
v(i, x_*) = f(x_*) - E_{X^i}[f(x^{-i}_*)] = \beta^0 + x^1_* \beta^1 + \ldots + x^p_* \beta^p - E_{X^i}[\beta^0 + x^1_* \beta^1 + \ldots +\beta^i X^i \ldots + x^p_* \beta^p] = ...
\end{equation}
\begin{equation}
... = \beta^i[x_*^i - E_{X^i}(X^i)].
\end{equation}

In practice, given a dataset, the expected value of \(X^i\) can be estimated by the sample mean \(\bar x^i\). This leads to

\begin{equation}
v(i, x_*) = \beta^i (x_*^i - \bar x^i).
\end{equation}

Note that the linear-model-based prediction may be re-expressed in the following way:
\[
f(x_*) = [\beta^0 + \bar x^1 \beta^1 + ... + \bar x^p \beta^p] + [(x^1_* - \bar x^1) \beta^1 + ... + (x^p_* - \bar x^p) \beta^p] 
\]
\begin{equation}
 \equiv [average \ prediction] + \sum_{j=1}^p v(i, x_*).
\label{eq:singleBreakDownResult}
\end{equation}

Thus, the contributions of the explanatory variables \(v(i, x_*)\) sum up to the difference between the model prediction for \(x_*\) and the average model prediction.

\textbf{NOTE for careful readers}

Obviously, sample mean \(\bar x^i\) is an estimator of the expected value \(E_{X^i}(X^i)\), calculated using a training data. For the sake of simplicity we do not emphasize these differences in the notation. Also, we ignore the fact that, in practice, we never know the true model coefficients and we work with an estimated coefficients.

\hypertarget{break-down-for-a-general-case}{%
\subsection{Break-down for a general case}\label{break-down-for-a-general-case}}

Note that the method is similar to the \texttt{EXPLAIN} algorithm introduced in ,,Explaining Classifications for Individual Instances'' \citep{explainPaper} and implemented in the \texttt{ExplainPrediction} package \citep{explainPackage}.

Again, let \(v(j, x_*)\) denote the variable-importance measure of the \(j\)-th variable and instance \(x_*\), i.e., the contribution of the \(j\)-th variable to prediction at \(x_*\).

We would like the sum of the \(v(j, x_*)\) for all explanatory variables to be equal to the instance prediction (property called \emph{local accuracy}), so that

\begin{equation}
f(x_*) = v_0 + \sum_{j=1}^p v(j, x_*),
\label{eq:generalBreakDownLocalAccuracy}
\end{equation}

where \(v_0\) denotes the average model response. If we rewrite the equation above as follows:

\begin{equation}
E_X[f(X)|X^1 = x^1_*, \ldots, X^p = x^p_*] = E_X[f(X)] + \sum_{j=1}^p v(j, x_*),
\end{equation}

then a natural proposal for \(v(j, x_*)\) is

\begin{equation}
v(j, x_*) = E_X[f(X) | X^1 = x^1_*, \ldots, X^j = x^j_*] - E_X[f(X) | X^1 = x^1_*, \ldots, X^{j-1} = x^{j-1}_*]. 
\label{eq:generalBreakDownProposition}
\end{equation}

In other words, the contribution of the \(j\)-th variable is the difference between the expected value of the prediction conditional on setting the values of the first \(j\) variables equal to their values in \(x_*\) and the expected value conditional on setting the values of the first \(j-1\) variables equal to their values in \(x_*\).

Note that the definition does imply the dependence of \(v(j, x_*)\) on the order of the explanatory variables that is reflected in their indices.

To consider more general cases, let \(J\) denote a subset of \(K\) (\(K\leq p\)) indices from \(\{1,2,\ldots,p\}\), i.e., \(J=\{j_1,j_2,\ldots,j_K\}\) where each \(j_k \in \{1,2,\ldots,p\}\). Furthermore, let \(L\) denote another subset of \(M\) (\(M \leq p-K\)) indices from \({1,2,\ldots,p}\) distinct from \(J\). That is, \(L=\{l_1,l_2,\ldots,l_M\}\) where each \(l_m \in \{1,2,\ldots,p\}\) and \(J \cap L = \emptyset\). Let us define now

\begin{eqnarray}
\Delta^{L|J}(x_*) &\equiv& E_X[f(X) | X^{l_1} = x_*^{l_1},\ldots,X^{l_M} = x_*^{l_M},X^{j_1} = x_*^{j_1},\ldots,X^{j_K} = x_*^{j_K}]\\
&-& E_X[f(X) | X^{j_1} = x_*^{j_1},\ldots,X^{j_K} = x_*^{j_K}].
\end{eqnarray}

In other words, \(\Delta^{L|J}(x_*)\) is the change between the expected model prediction when setting the values of the explanatory variables with indices from the set \(J \cup L\) equal to their values in \(x_*\) and the expected prediction conditional on setting the values of the explanatory variables with indices from the set \(J\) equal to their values in \(x_*\).

In particular, for the \(l\)-th explanatory variable, let
\begin{eqnarray}
\Delta^{l|J}(x_*) \equiv \Delta^{\{l\}|J}(x_*) &=& E_X[f(X) | X^{j_1} = x_*^{j_1},\ldots,X^{j_K} = x_*^{j_K}, X^{l} = x_*^{l}]\\
&-& E_X[f(X) | X^{j_1} = x_*^{j_1},\ldots,X^{j_K} = x_*^{j_K}].
\end{eqnarray}

Thus, \(\Delta^{l|J}\) is the change between the expected prediction when setting the values of the explanatory variables with indices from the set \(J \cup \{l\}\) equal to their values in \(x_*\) and the expected prediction conditional on setting the values of the explanatory variables with indices from the set \(J\) equal to their values in \(x_*\). Note that, if \(J=\emptyset\), then

\begin{equation}
\Delta^{l|\emptyset}(x_*) = E_X[f(X) | X^{l} = x_*^{l}] - E_X[f(X)].
\label{eq:deltaBreakDownAdditive}
\end{equation}

It follows that

\begin{equation}
v(j, x_*) = \Delta^{j|\{1,  ..., j-1\}}(x_*).
\end{equation}

Unfortunately, for non-additive models (that include interactions), the value of so-defined variable-importance measure depends on the order, in which one sets the values of the explanatory variables. Figure \ref{fig:ordering} presents an example.
We fit the random forest model to predict whether a passenger survived or not, then, we explain the model's prediction for a 2-year old boy that travels in the second class. The model predicts survival with a probability of \(0.964\). We would like to explain this probability and understand which factors drive this prediction. Consider two explanations.

\textbf{Explanation 1:}
The passenger is a boy, and this feature alone decreases the chances of survival. He traveled in the second class which also lower survival probability.
Yet, he is very young, which makes odds higher. The reasoning behind such an explanation on this level is that most passengers in the second class are adults, therefore a kid from the second class has high chances of survival.

\textbf{Explanation 2:}
The passenger is a boy, and this feature alone decreases survival probability.
However, he is very young, therefore odds are higher than adult men. Explanation in the last step says that he traveled in the second class, which make odds of survival even more higher. The interpretation of this explanation is that most kids are from the third class and being a child in the second class should increase chances of survival.

Note that the effect of \emph{the second class} is negative in explanations for scenario 1 but positive in explanations for scenario 2.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{figure/ordering} 

}

\caption{An illustration of the order-dependence of the variable-contribution values. Two *Break-down* explanations for the same observation from Titanic data set. The underlying model is a random forest. Scenarios differ due to the order of variables in *Break-down* algorithm. Last bar indicates the difference between the model's prediction for a particular observation and an average model prediction. Other bars show contributions of variables. Red color means a negative effect on the survival probability, while green color means a positive effect. Order of variables on the y-axis corresponds to their sequence used in *Break-down* algorithm.}\label{fig:ordering}
\end{figure}

There are three approaches that can be used to address the issue of the dependence of \(v(j, x_*)\) on the order, in which one sets the values of the explanatory variables.

In the first approach, one chooses an ordering according to which the variables with the largest contributions are selected first. In this chapter, we describe a heuristic behind this approach.

In the second approach, one identifies the interactions that cause a difference in variable-importance measure for different orderings and focuses on those interactions. This approach is discussed in Chapter \ref{iBreakDown}.

Finally, one can calculate an average value of the variance-importance measure across all possible orderings. This approach is presented in Chapter \ref{shapley}.

To choose an ordering according to which the variables with the largest contributions are selected first, one can apply a two-step procedure. In the first step, the explanatory variables are ordered. In the second step, the conditioning is applied according to the chosen order of variables.

In the first step, the ordering is chosen based on the decreasing value of the scores equal to \(|\Delta^{k|\emptyset}|\). Note that the absolute value is needed, because the variable contributions can be positive or negative. In the second step, the variable-importance measure for the \(j\)-th variable is calculated as
\[
v(j, x_*) = \Delta ^{j|J},
\]
where
\[
J = \{k: |\Delta^{k|\emptyset}| < |\Delta^{j|\emptyset}|\},
\]
that is, \(J\) is the set of indices of explanatory variables that have scores \(|\Delta^{k|\emptyset}|\) smaller than the corresponding score for variable \(j\).

The time complexity of each of the two steps of the procedure is \(O(p)\), where \(p\) is the number of explanatory variables.

\hypertarget{BDExample}{%
\section{Example: Titanic data}\label{BDExample}}

Let us consider the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf} and passenger \texttt{johny\_d} (see Section \ref{predictions-titanic}) as the instance of interest in the Titanic data.

The average of model predictions for all passengers is equal to \(v_0 = 0.2353095\). Table \ref{tab:titanicBreakDownDeltas} presents the scores \(|\Delta^{j|\emptyset}|\) and the expected values \(E[f(X | X^j = x^j_*)]\). Note that \(\Delta^{j|\emptyset}=E[f(X) | X^j = x^j_*]-v_0\) and, since for all variables \(E[f(X) | X^j = x^j_*]>v_0\), we have got \(E[f(X | X^j = x^j_*)]=|\Delta^{j|\emptyset}|+v_0\).

\begin{longtable}[]{@{}lrr@{}}
\caption{\label{tab:titanicBreakDownDeltas} Expected values \(E[f(X) | X^j = x^j_*]\) and scores \(|\Delta^{j|\emptyset}|\) for the random-forest model \texttt{titanic\_rf\_v6} for the Titanic data and \texttt{johny\_d}. The scores are sorted in the decreasing order.}\tabularnewline
\toprule
variable \(j\) & \(E[f(X) | X^j = x^j_*]\) & \(|\Delta^{j|\emptyset}|\)\tabularnewline
\midrule
\endfirsthead
\toprule
variable \(j\) & \(E[f(X) | X^j = x^j_*]\) & \(|\Delta^{j|\emptyset}|\)\tabularnewline
\midrule
\endhead
age & 0.7407795 & 0.5051210\tabularnewline
class & 0.6561034 & 0.4204449\tabularnewline
fare & 0.6141968 & 0.3785383\tabularnewline
sibsp & 0.4786182 & 0.2429597\tabularnewline
parch & 0.4679240 & 0.2322655\tabularnewline
embarked & 0.4602620 & 0.2246035\tabularnewline
gender & 0.3459458 & 0.1102873\tabularnewline
\bottomrule
\end{longtable}

Based on the ordering defined by the scores \(|\Delta^{j|\emptyset}|\) from Table \ref{tab:titanicBreakDownDeltas}, we can compute the variable-importance measures based on the sequential contributions \(\Delta^{j|J}\). The computed values are presented in Table \ref{tab:titanicBreakDownDeltasConseq}.

\begin{longtable}[]{@{}lrr@{}}
\caption{\label{tab:titanicBreakDownDeltasConseq} Variable-importance measures \(\Delta^{j|\{1,\ldots,j\}}\) for the random-forest model \texttt{titanic\_rf\_v6} for the Titanic data and \texttt{johny\_d} computed by using the ordering of variables defined in Table \ref{tab:titanicBreakDownDeltas}.}\tabularnewline
\toprule
\begin{minipage}[b]{0.44\columnwidth}\raggedright
variable \(j\)\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedleft
\(E[f(X) | X^{\{1,\ldots,j\}} = x^{\{1,\ldots,j\}}_*)]\)\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedleft
\(\Delta^{j|\{1,\ldots,j\}}\)\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.44\columnwidth}\raggedright
variable \(j\)\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedleft
\(E[f(X) | X^{\{1,\ldots,j\}} = x^{\{1,\ldots,j\}}_*)]\)\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedleft
\(\Delta^{j|\{1,\ldots,j\}}\)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.44\columnwidth}\raggedright
intercept\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.2353095\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
0.2353095\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
age = 8\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.5051210\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
0.2698115\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
class = 1st\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.5906969\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
0.0855759\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
fare = 72\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.5443561\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.0463407\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
gender = male\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.4611518\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.0832043\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
embarked = Southampton\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.4584422\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.0027096\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
sibsp = 0\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.4523398\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.0061024\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
parch = 0\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.4220000\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.0303398\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
prediction\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.4220000\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
0.4220000\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Results from Table \ref{tab:titanicBreakDownDeltasConseq} are presented as a waterfall plot in Figure \ref{fig:BDjohnyExample}.



\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/BDjohnyExample-1} 

}

\caption{Break-down plot for the \texttt{titanic\_rf\_v6} model and \texttt{johny\_d} for the Titanic data.}\label{fig:BDjohnyExample}
\end{figure}

\hypertarget{BDProsCons}{%
\section{Pros and cons}\label{BDProsCons}}

Break-down plots offer a model-agnostic approach that can be applied to any predictive model that returns a single number for a single instance. The approach offers several advantages. The plots are easy to understand. They are compact; results for many variables may be presented in a small space. The approach reduces to an intuitive interpretation for the generalized-linear models. Numerical complexity of the Break-down algorithm is linear in the number of explanatory variables.

Break-down plots for non-additive models may be misleading, as they show only the additive contributions. An important issue is the choice of the ordering of the explanatory variables that is used in the calculation of the variable-importance measures. Also, for models with a large number of variables, the Break-down plot may be complex and include many variables with small contributions to the instance prediction.

\hypertarget{BDR}{%
\section{Code snippets for R}\label{BDR}}

In this section, we use an \texttt{DALEX::variable\_attribution()} function which is a wrapper for \texttt{iBreakDown} R package \citep{iBreakDownRPackage}. The package covers all methods presented in this chapter. It is available on CRAN and GitHub.

For illustration purposes, we use the \texttt{titanic\_rf\_v6} random-forest model for the Titanic data developed in Section \ref{model-titanic-rf}. Recall that it is developed to predict the probability of survival from sinking of Titanic. Instance-level explanations are calculated for a single observation: \texttt{henry} - a 47-year-old passenger that travelled in the 1st class.

\texttt{DALEX} explainers for the model and the \texttt{henry} data are retrieved via \texttt{archivist} hooks as listed in Section \ref{ListOfModelsTitanic}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}
\NormalTok{explain_rf_v6 <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/6ed54"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{henry <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/a6538"}\NormalTok{)}
\NormalTok{henry}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   class gender age sibsp parch fare  embarked
## 1   1st   male  47     0     0   25 Cherbourg
\end{verbatim}

\hypertarget{basic-use-of-the-variable_attribution-function}{%
\subsection{\texorpdfstring{Basic use of the \texttt{variable\_attribution()} function}{Basic use of the variable\_attribution() function}}\label{basic-use-of-the-variable_attribution-function}}

The \texttt{DALEX::variable\_attribution()} function calculates the variable-importance measures for a selected model and the instance of interest.
The result of applying the \texttt{variable\_attribution()} function is a data frame containing the calculated measures. In the simplest call, the function requires only three arguments: the model explainer, the data frame for the instance of interest and the method for calculation of variable attribution, here \texttt{break\_down}. The call below essentially re-creates the variable-importance values (\(\Delta^{j|\{1,\ldots,j\}}\)) presented in Table \ref{tab:titanicBreakDownDeltasConseq}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bd_rf <-}\StringTok{ }\KeywordTok{variable_attribution}\NormalTok{(explain_rf_v6,}
                 \DataTypeTok{new_observation =}\NormalTok{ henry,}
                 \DataTypeTok{type =} \StringTok{"break_down"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Applying the generic \texttt{plot()} function to the object resulting from the application of the \texttt{variable\_attribution()} function creates a BD plot. In this case, it is the plot from Figure \ref{fig:BDhenryExample}.



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bd_rf) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/BDhenryExample-1} 

}

\caption{Generic plot() function for the BreakDown method calculated for \texttt{henry}.}\label{fig:BDhenryExample}
\end{figure}

Now we can compare contributions calculated for \texttt{johny\_d} presented in Figure \ref{fig:BDjohnyExample} with contributions calculated for \texttt{henry} presented in \ref{fig:BDhenryExample}.
Both explanations refer to the same model \texttt{model\_rf\_v6}. In both cases the \texttt{class=1st} increases chances of survival. For \texttt{johny\_d} young age increases chances of survival while for \texttt{henry} the \texttt{age=47} decreases chances of survival.

\hypertarget{advanced-use-of-the-variable_attribution-function}{%
\subsection{\texorpdfstring{Advanced use of the \texttt{variable\_attribution()} function}{Advanced use of the variable\_attribution() function}}\label{advanced-use-of-the-variable_attribution-function}}

The function \texttt{variable\_attribution()} allows more arguments. The most commonly used are:

\begin{itemize}
\tightlist
\item
  \texttt{x} - a wrapper over a model created with function \texttt{DALEX::explain()},
\item
  \texttt{new\_observation} - an observation to be explained is should be a data frame with structure that matches the training data,
\item
  \texttt{order} - a vector of characters (column names) or integers (column indexes) that specify order of explanatory variables that is used for computing the variable-importance measures. If not specified (default), then a one-step heuristic is used to determine the order,
\item
  \texttt{keep\_distributions} - a logical value; if \texttt{TRUE}, then additional diagnostic information about conditional distributions is stored in the resulting object and can be plotted with the generic \texttt{plot()} function.
\end{itemize}

In what follows we illustrate the use of the arguments.

First, we will specify the ordering of the explanatory variables. Toward this end we can use integer indexes or variable names. The latter option is prerferable in most cases because of transparency. Additionally, to reduce clutter in the plot, we set \texttt{max\_features\ =\ 3} argument in the \texttt{plot()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bd_rf_order <-}\StringTok{ }\KeywordTok{variable_attribution}\NormalTok{(explain_rf_v6,}
         \DataTypeTok{new_observation =}\NormalTok{ henry, }\DataTypeTok{type =} \StringTok{"break_down"}\NormalTok{,}
         \DataTypeTok{order =} \KeywordTok{c}\NormalTok{(}\StringTok{"class"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"gender"}\NormalTok{, }\StringTok{"fare"}\NormalTok{, }\StringTok{"parch"}\NormalTok{, }
                           \StringTok{"sibsp"}\NormalTok{, }\StringTok{"embarked"}\NormalTok{))}

\KeywordTok{plot}\NormalTok{(bd_rf_order, }\DataTypeTok{max_features =} \DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/unnamed-chunk-27-1} 

}

\caption{Break Down plot for top three variables.}\label{fig:unnamed-chunk-27}
\end{figure}

We can use the\texttt{keep\_distributions\ =\ TRUE} argument to enrich the resulting object with additional information about conditional distributions. Subsequently, we can apply the \texttt{plot\_distributions\ =\ TRUE} argument in the \texttt{plot()} function to present the distributions as violin plots. Red dots in the plots indicate the average model predictions. Thin black lines between violin plots correspond to predictions for individual observations. They can be used to trace how model predictions change after consecutive conditionings.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bd_rf_distr <-}\StringTok{ }\KeywordTok{variable_attribution}\NormalTok{(explain_rf_v6,}
          \DataTypeTok{new_observation =}\NormalTok{ henry, }\DataTypeTok{type =} \StringTok{"break_down"}\NormalTok{,}
          \DataTypeTok{order =} \KeywordTok{c}\NormalTok{(}\StringTok{"class"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"gender"}\NormalTok{, }\StringTok{"fare"}\NormalTok{, }
                           \StringTok{"parch"}\NormalTok{, }\StringTok{"sibsp"}\NormalTok{, }\StringTok{"embarked"}\NormalTok{),}
          \DataTypeTok{keep_distributions =} \OtherTok{TRUE}\NormalTok{)}

\KeywordTok{plot}\NormalTok{(bd_rf_distr, }\DataTypeTok{plot_distributions =} \OtherTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/unnamed-chunk-28-1} 

}

\caption{Break Down plot with distributions for a defined order of variables.}\label{fig:unnamed-chunk-28}
\end{figure}

\hypertarget{iBreakDown}{%
\chapter{Break-down Plots for Interactions (iBreak-down Plots)}\label{iBreakDown}}

In Chapter \ref{breakDown}, we presented a model-agnostic approach to evaluation of the importance of an explanatory variable for model predictions. An important issue is that, for some models, e.g.~models with interactions, the estimated value of the variable-importance measure depends on the ordering of the explanatory variables that is used when computing the measure.

In this chapter, we present an algorithm that addresses the issue. In particular, the algorithm identifies interactions between pairs of variables and takes them into account when constructing Break-down (BD) plots. In our presentation we focus on interactions that involve pairs of explanatory variables, but the algorithm can be easily extended to interactions involving a larger number of variables.

\hypertarget{iBDIntuition}{%
\section{Intuition}\label{iBDIntuition}}

Lack of additivness means that the effect of an explanatory variable depends on the value(s) of other variable(s). To illustrate such a situation, we will consider the Titanic dataset (see Section \ref{TitanicDataset}). For the sake of simplicity, we consider only two variables, \texttt{age} and \texttt{class}. In the data \texttt{age} is a continuous variable, but we will use a dichotomized version of it, with two levels: boys (0-16 years old) and adults (17+ years old). Also, we will consider just two classes: the 2nd and ``other''.

Table \ref{tab:titanicMaleSurvival} shows percentages of survivors for boys and adult men in the 2nd class and other classes on Titanic. Overall, the proportion of survivors among males is 20.5\%. However, among boys in the 2nd class, the proportion is 91.7\%. How do age and class contribute to this higher survival probability? Let us consider the following two decompositions.

\begin{itemize}
\item
  Decomposition 1: The overall probability of survival for males is 20.5\%, but for the male passengers from the 2nd class the probability is even lower, i.e.~13.5\%. Thus, the effect of the 2nd class is negative, as it decreases the probability of survival by 7\%. Now, if, for male passengers of the 2nd class, we consider age, we see that the survival probability for boys increases by 78.2\%, from 13.5\% (for a male in the 2nd class) to 91.7\%. Thus, by considering first the effect of the class, and then the effect of age, we can conclude the effect of -7\% for the 2nd class and +78.2\% for age (being a boy).
\item
  Decomposition 2: The overall probability of survival for males is 20.5\%, but for boys the probability is higher, i.e., 40.7\%. Thus, the effect of age (being a boy) is positive, as it increases the survival probability by 20.2\%. On the other hand, for boys, travelling in the 2nd class increases the probability further, from 40.7\% overall to 91.7\%. Thus, by considering first the effect of age, and then the effect of class, we can conclude the effect of +20.2\% for age (being a boy) and +51\% for the 2nd class.
\end{itemize}

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:titanicMaleSurvival} Proportions of survivors for men on Titanic.}\tabularnewline
\toprule
Class & Boys (0-16) & Adults (\textgreater{}16) & Total\tabularnewline
\midrule
\endfirsthead
\toprule
Class & Boys (0-16) & Adults (\textgreater{}16) & Total\tabularnewline
\midrule
\endhead
2nd & 11/12 = 91.7\% & 13/166 = 7.8\% & 24/178 = 13.5\%\tabularnewline
other & 22/69 = 31.9\% & 306/1469 = 20.8\% & 328/1538 = 21.3\%\tabularnewline
Total & 33/81 = 40.7\% & 319/1635 = 19.5\% & 352/1716 = 20.5\%\tabularnewline
\bottomrule
\end{longtable}

By considering effects of class and age in different order, we get very different contributions. This is because there is an interaction: the effect of class depends on the age and \texttt{vice\ versa}. In particular, from Table \ref{tab:titanicMaleSurvival} we could conclude that the overall effect of 2nd class is negative (-7\%), as it decreases the probability of survival from 20.5\% to 13.5\%. On the other hand, the overall effect of age (being a boy) is positive (+20.2\%), as it increases the probability of survival from 20.5\% to 40.7\%. Based on those effects, we would expect a probability of 20.5\%-7\%+20.2\%=33.7\% for a boy in the 2nd class. However, the actually observed proportion is much higher, 90.7\%. The difference of 90.7\%-33.7\%=57\% is the interaction effect. We can interpret it as an additional effect of the 2nd class specific for boys, or as an additional effect of age (being a boy) for the 2nd class male passengers.

The example illustrates that interactions complicate the evaluation of the importance of explanatory variables to model predictions. In what follows we present an algorithm to include interactions in the BD plots.

\hypertarget{iBDMethod}{%
\section{Method}\label{iBDMethod}}

Identification of interactions in the model is performed in three steps \citep{iBreakDownRPackage}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculate the variable-importance measure separately for each explanatory variable. In particular, for each variable, compute \(\Delta^{j|\emptyset}(x_*)\) (see Section \ref{BDMethod}).
\item
  Calculate the measure for each pair of variables. Subtract the obtained value from the sum of the measures for the particular variables to obtain a contribution attributable to an interaction. In particular, for each pair of variables, compute \(\Delta^{\{i,j\}|\emptyset}\) (see Section \ref{BDMethod}) and then
\end{enumerate}

\begin{equation}
\Delta^{\{i,j\}}_I(x_*) \equiv \Delta^{\{i,j\}|\emptyset}(x_*)-\Delta^{i|\emptyset}(x_*)-\Delta^{j|\emptyset}(x_*).
\label{eq:deltaBreakDownInteractions}
\end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Rank the so-obtained importance measures for the ``main'' and interaction effects to determine the final ordering for computing the variable-importance measures. Using the ordering, compute variable-importance measures \(v(j, x_*) = \Delta^{j|\{1, ..., j-1\}}(x_*)\) (see Section \ref{BDMethod}).
\end{enumerate}

The time complexity of the first step is \(O(p)\), where \(p\) is the number of explanatory variables. For the second step, the complexity is \(O(p^2)\), while for the third step it is \(O(p)\). Thus, the time complexity of the entire procedure is \(O(p^2)\).

\hypertarget{iBDExample}{%
\section{Example: Titanic data}\label{iBDExample}}

Let us consider the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf}) and passenger \texttt{johny\_d} (see Section \ref{predictions-titanic}) as the instance of interest in the Titanic data.

Table \ref{tab:titanicIBreakDownList} presents the expected model predictions \(E_X[f(X)|X^i = x_*^i, X^j = x_*^j]\), single-variable effects \(\Delta^{\{i,j\}|\emptyset}(x_*)\) (see Equation \eqref{eq:deltaBreakDownAdditive}), and interaction effects \(\Delta_{I}^{\{i,j\}}(x_*)\) (see Equation \eqref{eq:deltaBreakDownInteractions}) for each explanatory variable and each pair of variables. All the measures are calculated for \texttt{johny\_d}, the instance of interest.
The rows in the table are sorted according to the absolute value of the net impact of the variable or net impact of the interaction between two variables. For a single variable the net impact is simply measured by \(\Delta^{\{i,j\}}(x_*)\) while for the pairs of variables the net impact is measured by \(\Delta_{I}^{\{i,j\}}(x_*)\). This way if two variables are important but there is no interaction, then the net effect of interaction \(\Delta_{I}^{\{i,j\}}(x_*)\) is smaller than additive effect of each variable and the interaction will be lower in the table, see \texttt{age} and \texttt{gender}. Contrary, is the interaction is important then its net effect will be higher than each variable separately, see \texttt{fare} and \texttt{class}.

Based on the ordering of the rows, the following sequence of variables is identified as informative:

\begin{itemize}
\tightlist
\item
  \texttt{age} because it has largest net effect \(0.270\),
\item
  then \texttt{fare:class} because the net effect of the interaction is \(-0.231\),
\item
  then \texttt{gender} because its net effect if \(0.125\) and single variables like \texttt{class} or \texttt{fare} are already used in the interaction,
\item
  then \texttt{embarked} because of its net effect \(-0.011\),
\item
  then \texttt{sibsp}, and \texttt{parch} as variables with lowest net effects but still larger than effect of their interaction.
\end{itemize}

\begin{longtable}[]{@{}lrrr@{}}
\caption{\label{tab:titanicIBreakDownList} Expected model predictions \(E_X[f(X)|X^i = x_*^i, X^j = x_*^j]\), single-variable effects \(\Delta^{\{i,j\}|\emptyset}(x_*)\) (see Equation \eqref{eq:deltaBreakDownAdditive}), and interaction effects \(\Delta_{I}^{\{i,j\}}(x_*)\) (see Equation \eqref{eq:deltaBreakDownInteractions}) for the random-forest model \texttt{titanic\_rf\_v6} and passenger \texttt{johny\_d} in the Titanic data. The rows are sorted according to the absolute value of the net impact of the variable or net impact of the interaction between two variables. For a single variable the net impact is defined as \(\Delta^{\{i,j\}}(x_*)\) while for the pairs of variables the net impact is equal to \(\Delta_{I}^{\{i,j\}}(x_*)\).}\tabularnewline
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
Variable\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedleft
\(E_X[f(X)|X^{i}= x_*^{i},X^{j}= x_*^{j}]\)\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedleft
\(\Delta^{\{i,j\}|\emptyset}(x_*)\)\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedleft
\(\Delta_{I}^{\{i,j\}}(x_*)\)\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.36\columnwidth}\raggedright
Variable\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedleft
\(E_X[f(X)|X^{i}= x_*^{i},X^{j}= x_*^{j}]\)\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedleft
\(\Delta^{\{i,j\}|\emptyset}(x_*)\)\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedleft
\(\Delta_{I}^{\{i,j\}}(x_*)\)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.36\columnwidth}\raggedright
age\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.505\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.270\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
fare:class\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.333\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.098\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.231\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
class\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.420\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.185\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
fare:age\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.484\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.249\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.164\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
fare\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.379\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.143\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
gender\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.110\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
-0.125\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
age:class\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.591\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.355\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.100\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
age:gender\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.451\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.215\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.070\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
fare:gender\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.280\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.045\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.027\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
embarked\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.225\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
-0.011\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
embarked:age\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.504\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.269\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.010\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
parch:gender\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.100\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
-0.136\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.008\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
sibsp\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.243\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.008\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
sibsp:age\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.520\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.284\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.007\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
sibsp:class\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.422\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.187\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.006\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
embarked:fare\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.374\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.138\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.006\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
sibsp:gender\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.113\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
-0.123\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.005\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
fare:parch\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.380\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.145\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.005\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
parch:sibsp\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.236\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.001\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.004\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
parch\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.232\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
-0.003\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
parch:age\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.500\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.264\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.002\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
embarked:gender\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.101\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
-0.134\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.002\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
embarked:parch\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.223\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
-0.012\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.001\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
fare:sibsp\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.387\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.152\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.001\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
embarked:class\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.409\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.173\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
-0.001\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
gender:class\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.296\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.061\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.001\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
embarked:sibsp\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.233\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
-0.002\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.001\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.36\columnwidth}\raggedright
parch:class\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.418\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedleft
0.183\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.000\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Table \ref{tab:titanicIBreakDownList2} presents the variable-importance measures computed by using the sequence of variables \texttt{age}, \texttt{fare:class}, \texttt{gender}, \texttt{embarked}, \texttt{sibsp}, and \texttt{parch}.

\begin{longtable}[]{@{}lrr@{}}
\caption{\label{tab:titanicIBreakDownList2} Variable-importance measures \(\Delta^{j|\{1,\ldots,j\}}(x_*)\) computed by using the sequence of variables \texttt{age}, \texttt{fare:class}, \texttt{gender}, \texttt{embarked}, \texttt{sibsp}, and \texttt{parch} for the random-forest model \texttt{titanic\_rf\_v6} for the Titanic data and \texttt{johny\_d}.}\tabularnewline
\toprule
\begin{minipage}[b]{0.44\columnwidth}\raggedright
Variable\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedleft
\(\Delta^{j|\{1,\ldots,j\}}(x_*)\)\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedleft
\(E_X[f(X) | X^{\{1,\ldots,j\}} = x^{\{1,\ldots,j\}}_*)]\)\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.44\columnwidth}\raggedright
Variable\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedleft
\(\Delta^{j|\{1,\ldots,j\}}(x_*)\)\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedleft
\(E_X[f(X) | X^{\{1,\ldots,j\}} = x^{\{1,\ldots,j\}}_*)]\)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.44\columnwidth}\raggedright
intercept\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.235\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
age = 8\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
0.269\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.505\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
fare:class = 72:1st\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
0.039\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.544\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
gender = male\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.083\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.461\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
embarked = Southampton\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.002\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.458\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
sibsp = 0\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.006\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.452\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.44\columnwidth}\raggedright
parch = 0\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedleft
-0.030\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedleft
0.422\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Figure \ref{fig:iBreakDownTitanicExamplePlot} presents the BD plot corresponding to the results from Table \ref{tab:titanicIBreakDownList2}.

As we see the interaction between \texttt{fare} and \texttt{class} is included in the plot as a single bar. As effects of these two variables cannot be disentangled, the plot shows combination of both variables as a single contribution.
From Table \ref{tab:titanicIBreakDownList} we can read that \texttt{class} alone would increase average prediction by \(0.185\), \texttt{fare} would increase average prediction by \(0.143\), but together they increase the average prediction only by \(0.098\). It's because the \texttt{fare=72} is a high value on average, but is below median when it comes for the 1st class passengers. So these two values combined \texttt{fare:class=72:1st} signal a cheaper version of the fist class, this is why its contribution to model prediction is smaller than contribution of \texttt{class} and \texttt{fare} separately.



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/iBreakDownTitanicExamplePlot-1} 

}

\caption{Break-down plot with interactions for the \texttt{titanic\_rf\_v6} model and \texttt{johny\_d} for the Titanic data.}\label{fig:iBreakDownTitanicExamplePlot}
\end{figure}

\hypertarget{iBDProsCons}{%
\section{Pros and cons}\label{iBDProsCons}}

iBD plots share many pros and cons of BD plots for models without interactions (see section \ref{BDProsCons}). However, in case of interactions, the iBD plots provide more correct explanations.

Though the numerical complexity of the iBD procedure is quadratic, it may be time-consuming in case of models with a large number of explanatory variables. If \(p\) stands for the number of variables, then we need to estimate \(p*(p+1)/2\) net effects for single variables and pair of variables. For datasets with small number of observations calculations of net effects will suffer from larger variance and therefore larger randomness in the ranking of effects.
The identification of interactions in the presented procedure is not based on a formal statistical significance test. Thus, for small sample sizes, the procedure may be prone to errors.

\hypertarget{iBDRcode}{%
\section{Code snippets for R}\label{iBDRcode}}

In this section, we use an \texttt{DALEX()} package which is a wrapper for \texttt{iBreakDown} R package \citep{iBreakDownRPackage}. The package covers all methods presented in this chapter. It is available on CRAN and GitHub.

For illustration purposes, we use the \texttt{titanic\_rf\_v6} random-forest model for the Titanic data developed in Section \ref{model-titanic-rf}. Recall that it is developed to predict the probability of survival from sinking of Titanic. Instance-level explanations are calculated for a single observation: \texttt{henry} - an 47-years old passenger that travelled in the 1st class.

\texttt{DALEX} explainers for the model and the \texttt{henry} data are retrieved via \texttt{archivist} hooks as listed in Section \ref{ListOfModelsTitanic}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}
\NormalTok{explain_rf_v6 <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/6ed54"}\NormalTok{)}

\NormalTok{johny_d <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/e3596"}\NormalTok{)}
\NormalTok{henry}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   class gender age sibsp parch fare  embarked
## 1   1st   male  47     0     0   25 Cherbourg
\end{verbatim}

The key function to construct iBD plots is the \texttt{DALEX::varaible\_attribution()} function. The use of the function has already been explained in Section \ref{BDR}. In order to use Break-down plots the necessary argument is \texttt{type\ =\ "break\_down\_interactions"}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{bd_rf <-}\StringTok{ }\KeywordTok{variable_attribution}\NormalTok{(explain_rf_v6,}
                 \DataTypeTok{new_observation =}\NormalTok{ henry,}
                 \DataTypeTok{type =} \StringTok{"break_down_interactions"}\NormalTok{)}
\NormalTok{bd_rf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                             contribution
## Random Forest: intercept                           0.235
## Random Forest: class = 1st                         0.185
## Random Forest: gender = male                      -0.124
## Random Forest: embarked:fare = Cherbourg:25        0.107
## Random Forest: age = 47                           -0.125
## Random Forest: sibsp = 0                          -0.032
## Random Forest: parch = 0                          -0.001
## Random Forest: prediction                          0.246
\end{verbatim}

Now we can plot this object with the generic \texttt{plot()} function.



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bd_rf) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/iBDforHenry-1} 

}

\caption{Generic plot() function for the iBreakDown method calculated for \texttt{henry}.}\label{fig:iBDforHenry}
\end{figure}

The Figure \ref{fig:iBDforHenry} shows iBD plot for \texttt{henry} while Figure \ref{fig:iBreakDownTitanicExamplePlot} shows iBD plot for \texttt{johny\_d}. In this case different variables were identified as an interaction. As \texttt{fare=25} for \texttt{henry} is much lower than \texttt{fare=72} for \texttt{johny\_d} effect of \texttt{class} was not modified by \texttt{fare}.

\hypertarget{shapley}{%
\chapter{Shapley Additive Explanations (SHAP) and Average Variable Attributions}\label{shapley}}

In Chapter \ref{breakDown}, we introduced Break-down (BD) plots, a method of assessment of local variable-importance based on the contribution of an explanatory variable to model's prediction. We also indicated that, in the presence of interactions, the computed value of the contribution depends on the order of explanatory covariates that is used in calculations. One solution to the problem is to find an ordering in which the most important variables are placed at the beginning. Another solution, described in Chapter \ref{iBreakDown}, is to identify interactions and explicitly present their contributions to the predictions.

In this chapter, we introduce yet another approach to address the ordering issue. It is based on the idea of averaging the value of a variable's contribution over all, or a large number of, possible orderings. The idea is closely linked to ,,Shapley values'' \citep{shapleybook1952}, developed originally for cooperative games.

The approach was first introduced in ,,An Efficient Explanation of Individual Classifications Using Game Theory'' \citep{imeJLMR} and \citep{Strumbelj2014}. It was widely adopted after the publication of the NIPS paper ,,A Unified Approach to Interpreting Model Predictions'' \citep{SHAP} and Python's library SHAP \citep{shapPackage}. The authors of SHAP (SHapley Additive exPlanations) introduced an efficient algorithm for tree-based models \citep{TreeSHAP}. They also showed that SHAP values can be presented an unification of a collection of different commonly used techniques for model explanations \citep{SHAP}.

\hypertarget{SHAPIntuition}{%
\section{Intuition}\label{SHAPIntuition}}

Figure \ref{fig:shap10orderings} presents BD plots for ten random orderings (indicated by the order of the rows in each plot) of explanatory variables for the prediction for \texttt{johny\_d} (see Section \ref{predictions-titanic}) for the random-forest model (see Section \ref{model-titanic-rf}) for the Titanic dataset. The plots show clear differences in the contributions of various variables for different orderings. The most remarkable differences can be observed for variables \texttt{fare} and \texttt{class}, with contributions changing the sign depending on the ordering.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figure/shap_10_replicates} 

}

\caption{Break-down plots for ten random orderings of explanatory variables for the prediction for \texttt{johny\_d} for the random-forest model for the Titanic dataset. Each panel presents a single ordering, indicated by the order of the rows in the plot.}\label{fig:shap10orderings}
\end{figure}

To remove the influence of the ordering of the variables, we can compute an average value of the contributions.
Figure \ref{fig:shapOrdering} presents the average contributions, calculated over the ten orderings presented in Figure \ref{fig:shap10orderings}. Red and green bars present, respectively, the negative and positive averages. Violet box-plots summarize the distribution of the contributions for each explanatory variable across different orderings. The plot indicates that the most important variables, from the point of view of the prediction for \texttt{johny\_d} are \texttt{age} and \texttt{gender}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/shap_ordering} 

}

\caption{Average contributions for ten random orderings. Red and green bars present the averages. Box-plots summarize the distribution of contributions for each explanatory variable across the orderings.}\label{fig:shapOrdering}
\end{figure}

\hypertarget{SHAPMethod}{%
\section{Method}\label{SHAPMethod}}

SHapley Additive exPlanations (SHAP) are based on ,,Shapley values,'' a concept in cooperative game theory developed by Lloyd Shapley \citep{shapleybook1952}. Note that the notation may be confusing at the first glance. Shapley values are introduced for cooperative games. SHAP is an acronym for a method designed for ML models. We will use the name Shapley values.

Consider the following problem. A coalition of players cooperates, and obtains a certain overall gain from the cooperation. Players are not identical, and different players may have different importance. Cooperation is beneficial, because it may bring more benefit than individual actions. The problem to solve is how to distribute the generated surplus among the players? The Shapley value provides one possible fair answer to this question \citep{shapleybook1952}.

Now let's translate this problem to the context of model predictions. Explanatory variables are the players, while model \(f()\) plays the role of the coalition. The payoff from the coalition is the model prediction. The problem to solve is how to distribute the model prediction across particular variables?

The idea of using Shapley values for evaluation of local variable-importance was introduced in ,,An Efficient Explanation of Individual Classifications Using Game Theory'' \citep{imeJLMR}. We define them here in the notation introduced in Section \ref{BDMethod}.

Let us consider a permutation \(J\) of the set of indices \(\{1,2,\ldots,p\}\) corresponding to an ordering of \(p\) explanatory variables included in model \(f()\). Denote by \(\pi(J,j)\) the set of the indices of the variables that are positioned in \(J\) before the \(j\)-th variable. Note that, if the \(j\)-th variable is placed as the first, then \(\pi(J,j) = \emptyset\). Consider the model prediction \(f(x_*)\) for a particular instance of interest \(x_*\). The Shapley value is defined as follows:
\begin{equation}
\varphi(x_*,j) = \frac{1}{p!} \sum_{J} \Delta^{j|\pi(J,j)}(x_*),  
\label{eq:SHAP}
\end{equation}
where the sum is taken over all \(p!\) possible permutations (orderings of explanatory variables) and the variable-importance measure \(\Delta^{j|J}(x_*)\) was defined in Section \ref{BDMethod}. Essentially, \(\varphi(x_*,j)\) is the average of the variable-importance measures across all possible orderings of explanatory variables.

It is worth noting that the value of \(\Delta^{j|\pi(J,j)}(x_*)\) is constant for all ordering \(J\) that share with the same subset \(\pi(J,j)\). It follows that equation \eqref{eq:SHAP} can be expressed in an alternative form:

\begin{eqnarray}
\varphi(x_*,j) &=& \frac 1{p!}\sum_{s=0}^{p-1} \sum_{
\substack{
S \subseteq \{1,\dots,p\}\setminus \{j\} \\ |S|=s
}}  \left[s!(p-1-s)! \Delta^{j|S}(x_*)\right]\nonumber\\
&=&
\frac 1{p}\sum_{s=0}^{p-1} \sum_{
\substack{
S \subseteq \{1,\dots,p\}\setminus \{j\} \\ |S|=s
}}  \left[{{p-1}\choose{s}}^{-1} \Delta^{j|S}(x_*)\right],
\label{eq:SHAP1}
\end{eqnarray}
where \(|S|\) denotes the cardinal number (size) of set \(S\) and the second sum is taken over all subsets \(S\) of explanatory variables, excluding the \(j\)-th one, of size \(s\).

Note that the number of all subsets of sizes from 0 to \(p-1\) is \(2^{p}-1\), i.e., it is much smaller than number of all permutations \(p!\). Nevertheless, for a large \(p\), it may not be feasible to compute the Shapley values from Equations \eqref{eq:SHAP} nor \eqref{eq:SHAP1}. In that case, an estimate based on a sample of permutations may be considered. A Monte Carlo estimator was introduced in ,,Explaining prediction models and individual predictions with feature contributions'' \citep{Strumbelj2014}. An efficient implementation of computations of Shapley values was introduced in package SHAP \citep{SHAP}.

From the properties of Shapley values for cooperative games it follows that, in the context of predictive models, they enjoy the following properties:

\begin{itemize}
\tightlist
\item
  Symmetry: if two explanatory variables \(j\) and \(k\) are interchangeable, i.e., for any set of explanatory variables \(S \subseteq \{1,\dots,p\}\setminus \{j,k\}\) we have got
\end{itemize}

\[
\Delta^{j|S}(x_*) = \Delta^{k|S}(x_*),
\]
then their Shapley values are equal:

\[
\varphi(x_*,j) = \varphi(x_*,k).
\]

\begin{itemize}
\tightlist
\item
  Dummy feature: if an explanatory variable \(j\) does not contribute to any prediction for any set of explanatory variables \(S \subseteq \{1,\dots,p\}\setminus \{j\}\), that is,
\end{itemize}

\[
\Delta^{j|S}(x_*) = 0,
\]

then its Shapley value is equal to 0:

\[
\varphi(x_*,j) = 0.
\]

\begin{itemize}
\item
  Additivity: if model \(f()\) is a sum of two other models \(g()\) and \(h()\), then the Shapley value calculated for model \(f()\) is a sum of Shapley values for models \(g()\) and \(h()\).
\item
  Local accuracy: the sum of Shapley values is equal to the model prediction, that is,
\end{itemize}

\[
f(x_*) - E_X[f(X)] = \sum_{j=1}^p   \varphi(x_*,j). 
\]

\hypertarget{SHAPExample}{%
\section{Example: Titanic data}\label{SHAPExample}}

Let us consider the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf} and passenger \texttt{johny\_d} (see Section \ref{predictions-titanic}) as the instance of interest in the Titanic data.

Box-plots in Figure \ref{fig:shappJohny02} present the distribution of the contributions \(\Delta^{j|\pi(J,j)}(x_*)\) for each explanatory variable of the model for 25 random orderings of the explanatory variables. Red and green bars represent, respectively, the negative and positive Shapley values across the orderings. It is clear that the young age of Johny D results in a positive contribution for all orderings. The Shapley value is equal to \(0.2525\). On the other hand, the effect of gender is in all cases negative, with the Shapley value equal to \(-0.0908\).

The picture for \texttt{fare} and \texttt{class} is more complex, as their contributions can even change the sign, depending on the ordering. While Figure \ref{fig:shappJohny02} presents the Shapley values separately for each of the variables, it is worth noting that, by using the iBD plot in Section \ref{iBDExample} the pair was identified as one for each an interaction effect was present. Hence, the effect of the variables should not be separated.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/shappJohny02-1} 

}

\caption{Variable contributions for the prediction for \texttt{johny\_d} for the random-forest model \texttt{titanic\_rf\_v6} and the Titanic data for 25 random orderings. Left plot: Box-plots summarize the distribution of the contributions for each explanatory variable across the orderings. Red and green bars present the Shapley values. Right plot: Average attributions without boxplots.}\label{fig:shappJohny02}
\end{figure}

In most applications the detailed information about the distribution of variable contributions across the considered orderings of explanatory variables will not be necessary. Thus, one could simplify the plot by presenting only the Shapley values, as in right panel in Figure \ref{fig:shappJohny02}. Table \ref{tab:shapOrderingTable} presents the Shapley values underlying this plot.

\begin{longtable}[]{@{}lr@{}}
\caption{\label{tab:shapOrderingTable} Shapley values for the prediction for \texttt{johny\_d} for the random-forest model \texttt{titanic\_rf\_v6} and the Titanic data for 25 random orderings.}\tabularnewline
\toprule
Variable & Shapley value\tabularnewline
\midrule
\endfirsthead
\toprule
Variable & Shapley value\tabularnewline
\midrule
\endhead
age = 8 & 0.2525\tabularnewline
class = 1st & 0.0246\tabularnewline
embarked = Southampton & -0.0032\tabularnewline
fare = 72 & 0.0140\tabularnewline
gender = male & -0.0943\tabularnewline
parch = 0 & -0.0097\tabularnewline
sibsp = 0 & 0.0027\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{SHAProsCons}{%
\section{Pros and cons}\label{SHAProsCons}}

Shapley values provide a uniform approach to decompose model predictions into parts that can be attributed additively to different explanatory variables. In ,,A Unified Approach to Interpreting Model Predictions'' \citep{SHAP} it is shown that the method unifies different approaches to additive features attribution, like DeepLIFT \citep{DeepLIFT}, Layer-Wise Relevance Propagation \citep{LWRP}, or LIME \citep{lime}. The method has got a strong formal foundation derived from the cooperative games theory. It also enjoys an efficient implementation in Python, with ports or re-implementations in R.

An important drawback of the Shapley values is that they are additive attributions of variable effects. If the model is not additive, then the Shapley values may be misleading. This issue can be seen as arising from the fact that, in the cooperative games, the goal is to distribute the payoff among payers. However, in the predictive modeling context, we want to understand how do the players affect the payoff? Thus, we are not limited to independent payoff-splits for players.

It is worth noting that, for an additive model, the approaches presented in Chapters \ref{breakDown}, \ref{iBreakDown}, and in the current one lead to same variable contributions. It is because for additive models different orderings lead to same attributions. And since Shapley values can bee seen as an average across all ordering it's an average from identical values.

An important practical limitation of the method is that, for large models, the calculation of the Shapley values is time consuming. However, sub-sampling can be used to address the issue.

\hypertarget{SHAPRcode}{%
\section{Code snippets for R}\label{SHAPRcode}}

In this section, we use an \texttt{DALEX::variable\_attribution()} function which is a wrapper for \texttt{iBreakDown} R package \citep{iBreakDownRPackage}. The package covers all methods presented in this chapter. It is available on CRAN and GitHub.
Note that there are also other R packages that offer similar functionality, like \texttt{shapper} \citep{shapperPackage}, which is a wrapper for the Python library \texttt{SHAP} \citep{shapPackage}, and \texttt{iml} \citep{imlRPackage}.

For illustration purposes, we use the \texttt{titanic\_rf\_v6} random-forest model for the Titanic data developed in Section \ref{model-titanic-rf}. Recall that it is developed to predict the probability of survival from sinking of Titanic. Instance-level explanations are calculated for a single observation: \texttt{henry} - an 42-year-old passenger that travelled in the 1st class.

\texttt{DALEX} explainers for the model and the \texttt{jonhy\_d} data are retrieved via \texttt{archivist} hooks as listed in Section \ref{ListOfModelsTitanic}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}
\NormalTok{explain_rf_v6 <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/6ed54"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{henry <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/e3596"}\NormalTok{)}
\NormalTok{henry}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   class gender age sibsp parch fare  embarked
## 1   1st   male  47     0     0   25 Cherbourg
\end{verbatim}

We obtain the model prediction for this instance with the help of the `predict()' function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(explain_rf_v6, henry)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.246
\end{verbatim}

With the help of function \texttt{variable\_attribution()} we can re-create Figure \ref{fig:shappJohny02}. The function is applied to the explainer, created with the \texttt{explain()} function from the \texttt{DALEX} package, and a data frame for the instance of interest. Additionally, in the \texttt{B=25} argument we indicate that we want to select 25 random orderings of explanatory variables for which the Shapley values are to be computed. The resulting object is a data frame with variable contributions computed for every ordering. Applying the generic function \texttt{plot()} to the object constructs the plot that includes the Shapley values and the corresponding box-plots.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shap_henry <-}\StringTok{ }\KeywordTok{variable_attribution}\NormalTok{(explain_rf_v6, }
\NormalTok{                                   henry, }
                                   \DataTypeTok{type =} \StringTok{"shap"}\NormalTok{,}
                                   \DataTypeTok{B =} \DecValTok{25}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(shap_henry) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.5\linewidth]{ema_files/figure-latex/unnamed-chunk-38-1} \end{center}

To obtain a plot with only Shapley values, we can use the \texttt{show\_boxplots=FALSE} argument in the \texttt{plot()} function call.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(shap_henry, }\DataTypeTok{show_boxplots =} \OtherTok{FALSE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.5\linewidth]{ema_files/figure-latex/unnamed-chunk-39-1} \end{center}

When we compare this plot with the \texttt{johny\_d} in Figure \ref{fig:shappJohny02} the largest difference is related to effect of \texttt{age}. Young \texttt{johny\_d} has larger than average chances of survival, much larger than 47 years old \texttt{henry}.

The object obtained as a result of the application of function \texttt{shap()} allows to compute other summary statistics beyond the average.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shap_henry}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                             min           q1       median
## Random Forest: age = 47             -0.14872225 -0.115577707 -0.077651998
## Random Forest: class = 1st           0.12112732  0.142754644  0.176491618
## Random Forest: embarked = Cherbourg  0.01981876  0.034941097  0.051973267
## Random Forest: fare = 25            -0.03364295 -0.009764386 -0.009519710
## Random Forest: gender = male        -0.15592478 -0.130189397 -0.125022202
## Random Forest: parch = 0            -0.02795650 -0.011817399 -0.005084730
## Random Forest: sibsp = 0            -0.03593203 -0.011618034 -0.006115541
##                                             mean            q3
## Random Forest: age = 47             -0.076695025 -0.0294435886
## Random Forest: class = 1st           0.170520888  0.1925099683
## Random Forest: embarked = Cherbourg  0.062216294  0.0964676031
## Random Forest: fare = 25            -0.004429615  0.0039927503
## Random Forest: gender = male        -0.125052324 -0.1155987766
## Random Forest: parch = 0            -0.007256366 -0.0008337109
## Random Forest: sibsp = 0            -0.008613321  0.0067818305
##                                              max
## Random Forest: age = 47             -0.021961033
## Random Forest: class = 1st           0.246304486
## Random Forest: embarked = Cherbourg  0.109760761
## Random Forest: fare = 25             0.033626643
## Random Forest: gender = male        -0.101295877
## Random Forest: parch = 0             0.002820118
## Random Forest: sibsp = 0             0.007650204
\end{verbatim}

\hypertarget{LIME}{%
\chapter{Local Interpretable Model-agnostic Explanations (LIME)}\label{LIME}}

\hypertarget{LIMEIntroduction}{%
\section{Introduction}\label{LIMEIntroduction}}

Break-down (BD) and Shapley plots, introduced in Chapters \ref{breakDown} and \ref{shapley}, respectively, are most suitable for models with a small or moderate number of explanatory variables.

None of those approaches is well-suited for models with a very large number of explanatory variables. In genomics or image recognition, models with hundreds of thousands or millions of input variables are not uncommon. In such cases, sparse explainers with small number of non zero effects offer a useful alternative. The most popular example of such sparse explainers are Local Interpretable Model-agnostic Explanations (LIME) and their modifications.

The LIME method was originally proposed in ,,Why Should I Trust You?: Explaining the Predictions of Any Classifier'' \citep{lime}. The key idea behind this method is to locally approximate a black-box model by a simpler glass-box model, which is easier to interpret. In this chapter, we describe this approach.

\hypertarget{LIMEIntuition}{%
\section{Intuition}\label{LIMEIntuition}}

The intuition behind the LIME method is explained in Figure \ref{fig:limeIntroduction}. We want to understand factors that influence a complex black-box model around a single instance of interest. Areas presented in Figure \ref{fig:limeIntroduction} correspond to decision regions for a binary classifier, i.e., it pertains to a binary dependent variable. The axes represent the values of two continuous explanatory variables. The colored areas correspond to the decision regions, i.e., they indicate for which combinations of the variables the model classifies the observation to one of the two classes. The instance of interest is marked with the large black dot. By using an artificial dataset around the instance of interest, we can use a simpler glass-box model that will locally approximate the predictions of the black-box model. The glass-box model may then serve as a `'local explainer'' for the more complex model.

We may select different classes of glass-box models. The most typical choices are regularized linear models like LASSO regression \citep{Tibshirani94regressionshrinkage} or decision trees \citep{party2006}. The important point is to limit the complexity of the models, so that they are easier to explain.



\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/lime_introduction} 

}

\caption{The idea behind LIME approximation with local glass-box model. The colored areas correspond to decision regions for a complex binary classification model. The black cross corresponds to the instance of interest x*. Small dots correspond to the generated new data. Size of dots corresponds to proximity to the instance of interest, i.e.~to weights w'. Dashed line correspond to a simple linear model fitted for the artificial data. It approximates the black box model around the instance of interest. The simple linear model ,,explains'' local behaviour of the black box model.}\label{fig:limeIntroduction}
\end{figure}

\hypertarget{LIMEMethod}{%
\section{Method}\label{LIMEMethod}}

As an explanation, we want to find a model that locally approximates a black-box model \(f()\) around the instance of interest \(x_*\). Consider class \(G\) of interpretable models (linear models or decision trees). To find the required approximation, we consider the following ,,loss function''

\[
\hat g = \arg \min_{g \in G} L(f, g, \Pi_{x_*}) + \Omega (g), 
\]

where model \(g()\) belongs to class \(G\), \(\Pi_{x_*}\) defines a neighborhood of \(x_*\) in which approximation is sought, \(L()\) is a fidelity measure between models \(f()\) and \(g()\), and \(\Omega(g)\) is a penalty for the complexity of model \(g()\). The penalty is used to select simple models from class \(G\).

Note that the models \(f()\) and \(g()\) may operate on different variable spaces. The black-box model (function) \(f(x):\mathcal X \rightarrow \mathcal R\) is defined on the original, large, p-dimensional space \(\mathcal X\). The glass-box model (function) \(g:\mathcal X' \rightarrow \mathcal R\) applies to a lower q-dimensional, interpretable space \(\mathcal X'\), and usually \(q << p\). We will present some examples of \(\mathcal X'\) in the next section. For now we will just assume that some function \(h()\) transforms \(\mathcal X\) into \(\mathcal X'\).

If we limit class \(G\) to sparse linear models with \(K\) non zero coefficients, the following algorithm may be used to find an interpretable glass-box model \(g()\) that includes \(K\) most important, interpretable explanatory variables:

\begin{verbatim}
Input: x* - observation to be explained
Input: N  - sample size for the glass-box model 
Input: K  - complexity, number of variables for the glass-box model
Input: similarity - distance function in the original input space
1. Let x' = h(x*) be a version of x* in the interpretable space
2. for i in 1...N {
3.   z'[i] <- sample_around(x') 
     # prediction for a new observation z'[i] 
4.   y'[i] <- f(z[i]) 
5.   w'[i] <- similarity(x', z'[i]) 
6. }
7. return K-LASSO(y', x', w')
\end{verbatim}

In Step 7, \(K-LASSO(y', x', w')\) stands for a weighted LASSO linear-regression that selects \(K\) variables based on new dataset \((y', x')\) with weights \(w'\).

The practical implementation of this idea involves three important steps, which are discussed in the subsequent subsections.

\hypertarget{interpretable-data-representation}{%
\subsection{Interpretable data representation}\label{interpretable-data-representation}}

As it has been mentioned, the black-box model \(f()\) and the glass-box model \(g()\) operates on different data spaces. For example, let's consider a VGG16 neural network \citep{Simonyan15} trained for ImageNet data \citep{ImageNet}. The model uses an image of the size of \(244 \times 244\) pixels as input and predicts to which of 1000 potential categories does the image belong to. The original data space is of dimension \(3 \times 244 \times 244\) (three single-color channels \emph{red, green, blue} for a single pixel \(\times 244 \times 244\) pixels), i.e., the input space is 178,608-dimensional. Explaining predictions in such a high-dimensional space is difficult. Instead, the space can be transformed into superpixels, which are treated as binary features that can be turned on or off. Figure \ref{fig:duckHorse06} presents an example of 100 superpixels created for an ambiguous picture. Thus, in this case the black-box model \(f()\) operates in principle on data space \(\mathcal X=R^{178,608}\), while the glass-box model \(g()\) works on space \(\mathcal X' = \{0,1\}^{100}\).

It is worth noting that superpixels are frequent choices for image data. For text data, words are frequently used as interpretable variables. To reduce to complexity of the data space, continuous variables are often discretized to obtain interpretable tabular data. In case of categorical variables, combination of categories is often used. We will present examples in the next section.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figure/duck_horse_06} 

}

\caption{The left panel shows an ambiguous picture, half-horse and half-duck. The right panel shows 100 superpixels identified for this figure. Source: \url{https://twitter.com/finmaddison/status/352128550704398338}.}\label{fig:duckHorse06}
\end{figure}

\hypertarget{sampling-around-the-instance-of-interest}{%
\subsection{Sampling around the instance of interest}\label{sampling-around-the-instance-of-interest}}

To develop the locally-approximation glass-box model, we need new data points in the interpretable space around the instance of interest. It may not be enough to sample points from the original dataset, because in a high-dimensional data space the data are usually very sparse and data points are ,,far'' from each other. We need new artificial data points in the interpretable space. For this reason, the data for the development of the glass-box model are often created by using perturbations of the instance of interest.

For a set of binary variables in the interpretable space, the common choice is to flip (from 0 to 1 or from 1 to 0) the value of a randomly-selected number of variables describing the instance of interest.

For continuous variables, various proposals are introduced in different papers. For example ,,iml: An R package for Interpretable Machine Learning'' \citep{imlRPackage} and \citep{molnar2019} adds some Gaussian noise to continuous variables. In ,,lime: Local Interpretable Model-Agnostic Explanations'' \citep{limePackage} continuous variables are discretized with the use of quintiles and the perturbations are don on discretized variables. In ,,localModel: LIME-Based Explanations with Interpretable Inputs Based on Ceteris Paribus Profiles'' \citep{localModelPackage} continuous variables are discretized based on segmentation of local Ceteris Paribus profiles.

In the example of the duck-horse in Figure \ref{fig:duckHorse06}, the perturbations of the image would be created by randomly including or excluding some of the superpixels.
See an example in Figure \ref{fig:duckHorseProcess}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figure/duck_horse_process} 

}

\caption{In the original input space image is described by RGB colors for each pixel (left panel). The image is transformed into the interpretable input space with 100 super pixels (central panel). The artificial data is a subset of superpixels (right panel).}\label{fig:duckHorseProcess}
\end{figure}

\hypertarget{developing-the-glass-box-model}{%
\subsection{Developing the glass-box model}\label{developing-the-glass-box-model}}

Once the new data were sampled around the instance of interest, we may attempt to develop an interpretable glass-box model \(g()\) from class \(G\).

The most common choices for \(G\) are generalized linear models. To get sparse models, i.e., models with a limited number of variables, LASSO \citep{Tibshirani94regressionshrinkage} or similar regularization-modelling techniques are used. For instance, in the algorithm presented in Section \ref{LIMEMethod}, the K-LASSO method has been mentioned. An alternative choice are classification-and-regression trees \citep{CARTtree}.

The VGG16 network for each picture predicts 1000 probabilities that corresponds to the 1000 classes used for training.
For the duck-horse picture the two most likely classes are \emph{`standard poodle'} and \emph{`goose'}.
Figure \ref{fig:duckHorse04} presents LIME explanations for these top two classes. The explanations were obtained with the K-LASSO method which selected \(K\) superpixels that were the most influential from the model-prediction point of view. Here we show results for \(K=15\). For each of the selected two classes, the \(K\) superpixels with non-zero coefficients are highlighted. It is interesting to observe that the superpixel which contains the beak is influential for the prediction \emph{`goose'}, while the superpixels linked with the white colour are influential for the prediction \emph{`standard poodle'}. This is aligned with the intention thus such additional validation increases trust in model prediction.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figure/duck_horse_04} 

}

\caption{LIME for two predictions ('standard poodle' and 'goose') obtained by the VGG16 network with ImageNet weights for the half-duck, half-horse image.}\label{fig:duckHorse04}
\end{figure}

\hypertarget{LIMEExample}{%
\section{Example: Titanic data}\label{LIMEExample}}

Most examples of LIME method are related to the text or image data. Here we present examples for tabular data to facilitate comparisons between methods introduced in different chapters.
Let us consider the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf}) and passenger \texttt{johny\_d} (see Section \ref{predictions-titanic}) as the instance of interest in the Titanic data.

First, we need to define an interpretable input space. One option would be to gather similar variables into larger constructs corresponding to concepts. For example \texttt{class} and \texttt{fare} variables can be combined into a concept \texttt{wealth}, \texttt{age} and \texttt{gender} into a concept \texttt{demography} and so on. In this example we have relatively small number of variables so we will use a simpler interpretable data representation in the form of a binary vector. Each variable is dychotomized into two levels. For example \texttt{age} is transformed into a binary variable \texttt{\textless{}=}/\texttt{\textgreater{}} than 15, \texttt{class} is transformed into a binary variable \texttt{1st}/\texttt{2nd}/\texttt{deck\ crew} and so on.
The LIME algorithm is applied to this interpretable feature space and the K-LASSO method with \(K=3\) is used to identify 3 most important variables that will be transformed into an explanation.

Once the interpretable variable space is defined, we need to transform \texttt{johny\_d} to this space and generate a new dataset that will be used for K-LASSO approximations of random forest model. Figure \ref{fig:LIMEexample01} shows coefficients estimated in this K-LASSO model.

The three variables that are identified as the most influential are: \texttt{age}, \texttt{gender}, and \texttt{class}. Note that, for age, a dichotomized version of the originally continuous variable is used. On the other hand, for class, a dichotomized version based on the combination of several original categories is used.



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figure/LIMEexample01} 

}

\caption{LIME method for the prediction for \texttt{johny\_d} for the random-forest model \texttt{titanic\_rf\_v6} and the Titanic data. Presented values are beta coefficients in the K-LASSO model fitted locally to the response from the original model.}\label{fig:LIMEexample01}
\end{figure}

The interpretable features can be defined in a many different ways. One idea would to be use quartiles for the feature of interest. Another idea is to use Ceteris Paribus profiles (see Chapter \ref{ceterisParibus} and change-point method \citep{picard_1985} to find a instance specific discretization.
Different implementations of LIME differ in the way how the interpretable feature space is created.

\hypertarget{LIMEProsCons}{%
\section{Pros and cons}\label{LIMEProsCons}}

As mentioned by ,,Why Should I Trust You?: Explaining the Predictions of Any Classifier'' \citep{lime}, the LIME method

\begin{itemize}
\tightlist
\item
  is \emph{model-agnostic}, as it does not imply any assumptions on the black-box model structure,
\item
  offers an \emph{interpretable representation}, because the original data space is transformed into a more interpretable lower-dimension space (like transformation from individual pixels to super pixels for image data),
\item
  provides \emph{local fidelity}, i.e., the explanations are locally well-fitted to the black-box model.
\end{itemize}

The method has been widely adopted in text and image analysis, in part due to the interpretable data representation. Also, explanations are delivered as a subset of an image/text and our brain is good in the justification of such explanations. The underlying intuition for the method is easy to understand: a simpler model is used to approximate a more complex one. By using a simpler model, with a smaller number of interpretable explanatory variables, predictions are easier to explain. The LIME method can be applied to complex, high-dimensional models.

But there are several important limitations. For instance, despite several proposals, the issue of finding interpretable representations for continuous and categorical variables is not solved yet. Also, because the glass-box model is selected to approximate the black-box model, and the data themselves, the method does not control the quality of the local fit of the glass-box model to the data. Thus, the latter model may be misleading.

Finally, in high-dimensional data, data points are sparse. Defining a `'local neighborhood'' of the instance of interest may not be straightforward.
Importance of the local neighbourhood is presented for example in the article ,,On the Robustness of Interpretability Methods'' \citep{LIMESHAPstability}. Sometimes even slight changes in the neighbourhood affects strongly obtained explanations.

To summarise, the most useful applications of LIME are limited to high dimensional data for which one can defined a low-dimensional interpretable data representation, as in image analysis, text analysis or genomics.

\hypertarget{LIMERcode}{%
\section{Code snippets for R}\label{LIMERcode}}

LIME and similar methods are implemented in various R and Python packages. For example, \texttt{lime} \citep{limePackage} is a port of the LIME Python library \citep{shapPackage}, while \texttt{live} \citep{R-live}, \texttt{localModel} \citep{localModelPackage}, and \texttt{iml} \citep{imlRPackage} are separate R packages that implements this method from scratch.

Different implementations of LIME offer different algorithms for extraction of interpretable features, different methods for sampling, and different methods of weighting. For instance, regarding transformation of continuous variables into interpretable features, \texttt{lime} performs global discretization using quartiles, \texttt{localModel} performs local discretization using CP profiles, while \texttt{live} and \texttt{iml} work directly on continuous variables.
Due to these differences, the packages yield different results (explanations).

In what follows, for illustration purposes, we use the \texttt{titanic\_rf\_v6} random-forest model for the Titanic data developed in Section \ref{model-titanic-rf}. Recall that it is developed to predict the probability of survival from sinking of Titanic. Instance-level explanations are calculated for a single observation: \texttt{johny\_d} - an 8-year-old passenger that travelled in the 1st class. \texttt{DALEX} explainers for the model and the \texttt{jonhy\_d} data are retrieved via \texttt{archivist} hooks as listed in Section \ref{ListOfModelsTitanic}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}

\NormalTok{titanic <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/27e5c"}\NormalTok{)}
\NormalTok{titanic_rf_v6 <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/31570"}\NormalTok{)}
\NormalTok{johny_d <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/e3596"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-lime-package}{%
\subsection{The lime package}\label{the-lime-package}}

The key elements of the \texttt{lime} package are functions \texttt{lime()}, which creates an explainer, and \texttt{explain()}, which evaluates explanations.

The detailed results for the \texttt{titanic\_rf\_v6} random-forest model and \texttt{johny\_d} are presented below. First we need to specify that we will work with a model for classification.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"lime"}\NormalTok{)}
\NormalTok{model_type.randomForest <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, ...) }\StringTok{"classification"}
\end{Highlighting}
\end{Shaded}

Second we need to create an explainer - an object with all elements needed for calculation of explanations. This can be done with the \texttt{lime} function, the dataset and the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lime_rf <-}\StringTok{ }\KeywordTok{lime}\NormalTok{(titanic[,}\KeywordTok{colnames}\NormalTok{(johny_d)], titanic_rf_v6)}
\end{Highlighting}
\end{Shaded}

In the last step we generate an explanation. The \texttt{n\_features} set the K for K-LASSO method. Here we ask for explanations not larger than 4 variables. The \texttt{n\_permutations} argument defines how many points are to be sampled for a local model approximation. Here we use a set of 1000 artificial points for this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lime_expl <-}\StringTok{ }\NormalTok{lime}\OperatorTok{::}\KeywordTok{explain}\NormalTok{(johny_d, lime_rf, }\DataTypeTok{labels =} \StringTok{"yes"}\NormalTok{, }
                           \DataTypeTok{n_features =} \DecValTok{4}\NormalTok{, }\DataTypeTok{n_permutations =} \DecValTok{1000}\NormalTok{)}
\NormalTok{lime_expl}

\CommentTok{#      model_type case label label_prob  model_r2 model_intercept model_prediction}
\CommentTok{#1 classification    1    no      0.602 0.5806297       0.5365448        0.5805939}
\CommentTok{#2 classification    1    no      0.602 0.5806297       0.5365448        0.5805939}
\CommentTok{#3 classification    1    no      0.602 0.5806297       0.5365448        0.5805939}
\CommentTok{#4 classification    1    no      0.602 0.5806297       0.5365448        0.5805939}
\CommentTok{#  feature feature_value feature_weight  feature_desc                 data   prediction}
\CommentTok{#1    fare            72     0.00640936  21.00 < fare 1, 2, 8, 0, 0, 72, 4 0.602, 0.398}
\CommentTok{#2  gender             2     0.30481181 gender = male 1, 2, 8, 0, 0, 72, 4 0.602, 0.398}
\CommentTok{#3   class             1    -0.16690730   class = 1st 1, 2, 8, 0, 0, 72, 4 0.602, 0.398}
\CommentTok{#4     age             8    -0.10026475     age <= 22 1, 2, 8, 0, 0, 72, 4 0.602, 0.398}
\end{Highlighting}
\end{Shaded}

In this table the \texttt{feature\_weight} column has coefficients for the K-LASSO method in the explanation. In the column \texttt{case} one will find an index of observation for which the explanation is calculated. Here it's 1 since we asked for explanation for only one observation.
The \texttt{feature\_weight} columns shows the \(\beta\) coefficients in the K-LASSO model, \texttt{feature} column points out which variables have non zero coefficients in the K-LASSO method. The \texttt{feature\_value} column denotes values for the selected features for the observation of interest. The \texttt{feature\_description} column shows how the original feature was transformed into a interpretable feature.

This implementation of the LIME method dichotomizes continuous variables by using quartiles. Hence, in the output we get a binary variable \texttt{age\ \textless{}=\ 22}.

The corresponding local white box model is

\[
\hat y = 0.00640936 * 1_{fare > 21} + 0.30481181 * 1_{gender = male} - 
0.16690730 * 1_{class = 1st} -0.10026475 * 1_{age <= 22}
\]

Figure \ref{fig:limeExplLIMETitanic} shows the graphical presentation of the results, obtained by applying the generic \texttt{plot()} function.

Color corresponds to the sign of the \(\beta\) coefficient while length of the bar corresponds to the absolute value of \(\beta\) coefficient in the K-LASSO method.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_features}\NormalTok{(lime_expl)}
\end{Highlighting}
\end{Shaded}



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figure/lime_expl_lime_titanic} 

}

\caption{LIME-method results for the prediction for \texttt{johny\_d} for the random-forest model \texttt{titanic\_rf\_v6} and the Titanic data, generated by the \texttt{lime} package.}\label{fig:limeExplLIMETitanic}
\end{figure}

\hypertarget{the-localmodel-package}{%
\subsection{The localModel package}\label{the-localmodel-package}}

The \texttt{localModel} package operates on \texttt{DALEX::explain()} object. The main function in this package is \texttt{individual\_surrogate\_model()} which trains the local glass-box model.

The detailed results for the \texttt{titanic\_rf\_v6} random-forest model and \texttt{johny\_d} are presented below.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"localModel"}\NormalTok{)}

\NormalTok{explainer_titanic_rf <-}\StringTok{ }\NormalTok{DALEX}\OperatorTok{::}\KeywordTok{explain}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ titanic_rf_v6,}
            \DataTypeTok{data =}\NormalTok{ titanic[,}\KeywordTok{colnames}\NormalTok{(johny_d)])}
\NormalTok{local_model_rf <-}\StringTok{ }\KeywordTok{individual_surrogate_model}\NormalTok{(explainer_titanic_rf, }
\NormalTok{            johny_d, }\DataTypeTok{size =} \DecValTok{1000}\NormalTok{, }\DataTypeTok{seed =} \DecValTok{1313}\NormalTok{)}
\NormalTok{local_model_rf}
\CommentTok{#   estimated                    variable dev_ratio response}
\CommentTok{#1 0.23479837                (Model mean) 0.6521442         }
\CommentTok{#2 0.14483341                 (Intercept) 0.6521442         }
\CommentTok{#3 0.08081853 class = 1st, 2nd, deck crew 0.6521442         }
\CommentTok{#4 0.00000000     gender = female, NA, NA 0.6521442         }
\CommentTok{#5 0.23282293                age <= 15.36 0.6521442         }
\CommentTok{#6 0.02338929                fare > 31.05 0.6521442    }
\end{Highlighting}
\end{Shaded}

In the column \texttt{estimated} one will find \(\beta\) coefficients for LASSO logistic regression while in the \texttt{variable} column one will find corresponding values.

The implemented version of LIME dichotomizes continuous variables by using CP profiles. The CP profile for \texttt{johny\_d}, presented in Figure \ref{fig:titanicCeterisProfile01D} in Chapter \ref{ceterisParibus}, indicated that, for age, the largest drop in the predicted probability of survival was observed for the age increasing beyond 15 years. Hence, in the output of the \texttt{individual\_surrogate\_model()}, we see a binary variable \texttt{age\ \textless{}\ 15.36}.

Figure \ref{fig:LIMEexample02} illustrates how the two levels for age can be extracted from the Ceteris Paribus profile.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figure/LIMEexample02} 

}

\caption{Interpretable instance-level discretisation of age variable. Based on the Ceteris Paribus profiles we may estimate an optimal change-point as 15 years.}\label{fig:LIMEexample02}
\end{figure}

The graphical presentation of the results, obtained by applying the generic \texttt{plot()} function is provided in Figure \ref{fig:limeExplLocalModelTitanic}.
Bars correspond to \(\beta\) coefficients in the LASSO model.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(local_model_rf)}
\end{Highlighting}
\end{Shaded}



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figure/lime_expl_localModel_titanic} 

}

\caption{LIME-method results for the prediction for \texttt{johny\_d} for the random-forest model \texttt{titanic\_rf\_v6} and the Titanic data, generated by the \texttt{localModel} package.}\label{fig:limeExplLocalModelTitanic}
\end{figure}

\hypertarget{the-iml-package}{%
\subsection{The iml package}\label{the-iml-package}}

The key elements of the \texttt{iml} package are functions \texttt{Predictor\$new()}, which creates an explainer, and \texttt{LocalModel\$new()}, which develops the local glass-box model.

The detailed results for the \texttt{titanic\_rf\_v6} random-forest model and \texttt{johny\_d} are presented below.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"iml"}\NormalTok{)}
\NormalTok{iml_rf =}\StringTok{ }\NormalTok{Predictor}\OperatorTok{$}\KeywordTok{new}\NormalTok{(titanic_rf_v6, }\DataTypeTok{data =}\NormalTok{ titanic[,}\KeywordTok{colnames}\NormalTok{(johny_d)])}
\NormalTok{iml_glass_box =}\StringTok{ }\NormalTok{LocalModel}\OperatorTok{$}\KeywordTok{new}\NormalTok{(iml_rf, }\DataTypeTok{x.interest =}\NormalTok{ johny_d, }\DataTypeTok{k =} \DecValTok{6}\NormalTok{)}
\NormalTok{iml_glass_box}
\CommentTok{#Interpretation method:  LocalModel }
\CommentTok{#}
\CommentTok{#Analysed predictor: }
\CommentTok{#Prediction task: unknown }
\CommentTok{#}
\CommentTok{#Analysed data:}
\CommentTok{#Sampling from data.frame with 2207 rows and 7 columns.}
\CommentTok{#}
\CommentTok{#Head of results:}
\CommentTok{#          beta x.recoded     effect  x.original              feature}
\CommentTok{#1 -0.158368701         1 -0.1583687         1st            class=1st}
\CommentTok{#2  1.739826204         1  1.7398262        male          gender=male}
\CommentTok{#3  0.018515945         0  0.0000000           0                sibsp}
\CommentTok{#4 -0.001484918        72 -0.1069141          72                 fare}
\CommentTok{#5  0.131819869         1  0.1318199 Southampton embarked=Southampton}
\CommentTok{#6  0.158368701         1  0.1583687         1st            class=1st}
\end{Highlighting}
\end{Shaded}

In the \texttt{effect} column on can read \(\beta\) coefficients for the LASSO method.

The implemented version of LIME does not transform continuous variables. The CP profile for \texttt{johny\_d}, presented in Figure \ref{fig:titanicCeterisProfile01D} in Chapter \ref{ceterisParibus}, indicated that, for boys younger than 15-year-old, the predicted probability of survival did not change very much. Hence, in the printed output, age does not appear as an important variable.

The graphical presentation of the results, obtained by applying the generic \texttt{plot()} function to the object resulting from the application of the \texttt{explain()} function, is provided in Figure \ref{fig:limeExplIMLTitanic}. Note that only first 6 rows are listed in the table above. The whole table has 12 coefficients that corresponds to bars in the plot.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(iml_glass_box) }
\end{Highlighting}
\end{Shaded}



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figure/lime_expl_iml_titanic} 

}

\caption{LIME-method results for the prediction for \texttt{johny\_d} for the random-forest model \texttt{titanic\_rf\_v6} and the Titanic data, generated by the \texttt{iml} package.}\label{fig:limeExplIMLTitanic}
\end{figure}

\hypertarget{ceterisParibus}{%
\chapter{Ceteris-paribus Profiles}\label{ceterisParibus}}

\hypertarget{CPIntro}{%
\section{Introduction}\label{CPIntro}}

Chapters \ref{breakDown} -- \ref{LIME} are related to the decomposition of a prediction \(f(x)\) into parts linked with particular variables. In this chapter we focus on methods that analyse an effect of selected variables on model response. These techniques may be used for sensitivity analysis, how stable is the model response, or to what-if analysis, how model response would change if input is changes. It is important to remember that the what-if analysis is performed not in the sense of causal modeling, but in the sense of model exploration. We need causal model to do causal inference for the real-world phenomena. Here we focus on explanatory analysis of the model behaviour. To show the difference between these two things, think about a model for survival for lung-cancer patients based on some treatment parameters. We need causal model to say how the survival would change if the treatment is changed. Techniques presented in this chapter will explore how the model result will change if the treatment is changed.

\emph{Ceteris paribus} is a Latin phrase meaning ``other things held constant'' or ``all else unchanged.'' In this chapter, we introduce a technique for model exploration based on the \emph{Ceteris paribus} principle. In particular, we examine the influence of each explanatory variable, assuming that effects of all other variables are unchanged. The main goal is to understand how changes in a single explanatory variable affects model predictions.

Explanation tools (explainers) presented in this chapter are linked to the second law introduced in Section \ref{three-single-laws}, i.e.~the law of ``Prediction's speculation.'' This is why the tools are also known as \emph{What-If model analysis} or \emph{Individual Conditional Expectations} \citep{ICEbox}. It appears that it is easier to understand how a black-box model is working if we can explore the model by investigating the influence of explanatory variables separately, changing one at a time.

\hypertarget{CPIntuition}{%
\section{Intuition}\label{CPIntuition}}

Ceteris-paribus profiles show how the model response would change if a single variable is changed. For example, panel A of Figure \ref{fig:modelResponseCurveLine} presents response (prediction) surface for the \texttt{titanic\_lmr\_v6} model for two explanatory variables, \emph{age} and \emph{class}, from the \emph{titanic} dataset (see Section \ref{TitanicDataset}). We are interested in the change of the model prediction induced by each of the variables. Toward this end, we may want to explore the curvature of the response surface around a single point with \emph{age} equal to 47 and \emph{class} equal to ``1st,'' indicated in the plot. Ceteris-paribus (CP) profiles are one-dimensional profiles that examine the curvature across each dimension, i.e., for each variable. Panel B of Figure \ref{fig:modelResponseCurveLine} presents the CP profiles corresponding to \emph{age} and \emph{class}. Note that, in the CP profile for \emph{age}, the point of interest is indicated by the black dot. In essence, a CP profile shows a conditional expectation of the dependent variable (response) for the particular explanatory variable.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figure/profile_age_class} 

}

\caption{Panel A) Model response (prediction) surface. Ceteris-paribus (CP) profiles marked with black curves help to understand the curvature of the surface while changing only a single explanatory variable. Panel B) CP profiles for individual variables, age (continuous) and class (categorical).}\label{fig:modelResponseCurveLine}
\end{figure}



\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figure/profile_age_class} 

}

\caption{Animated model response for 2D surface as in \ref{fig:modelResponseCurveLine}.}\label{fig:modelResponseCurveAnimation}
\end{figure}

CP belongs to the class of techniques that examine local curvature of the model response surface. Other very popular technique from this class called LIME is presented in Chapter \ref{LIME}.
The difference between these two methods lies in the fact that LIME approximates the model of interest locally with a simpler glass-box model. Usually, the LIME model is sparse, i.e., contains fewer explanatory variables. Thus, one needs to investigate a plot across a smaller number of dimensions. On the other hand, the CP profiles present conditional predictions for a single variable and, in most cases, are easier to interpret. More detailed comparison of these techniques is presented in the Chapter \ref{summaryInstanceLevel}.

\hypertarget{CPMethod}{%
\section{Method}\label{CPMethod}}

In this section, we introduce more formally one-dimensional CP profiles.

Recall (see Section \ref{notation}) that we use \(x_i\) to refer to the vector corresponding to the \(i\)-th observation in a dataset. Let \(x^{j}_{*}\) denote the \(j\)-th element of \(x_{*}\), i.e., the \(j\)-th explanatory variable. We use \(x^{-j}_{*}\) to refer to a vector resulting from removing the \(j\)-th element from \(x_{*}\). By \(x^{j|=z}_{*}\), we denote a vector resulting from changing the value of the \(j\)-th element of \(x_{*}\) to (a scalar) \(z\).

We define a one-dimensional CP profile \(h()\) for model \(f()\), the \(j\)-th explanatory variable, and point \(x_*\) as follows:

\begin{equation}
h^{f,j}_{x_*}(z) := f(x_*^{j|=z}).
\label{eq:CPPdef}
\end{equation}

CP profile is a function that provides the dependence of the approximated expected value (prediction) of \(Y\) on the value \(z\) of the \(j\)-th explanatory variable. Note that, in practice, \(z\) is taken to go through the entire range of values typical for the variable, while values of all other explanatory variables are kept fixed at the values specified by \(x_*\).

Note that in the situation when only a single model is considered, we will skip the model index and we will denote the CP profile for the \(j\)-th explanatory variable and the point of interest \(x_*\) by \(h^{j}_{x_*}(z)\).

\hypertarget{CPExample}{%
\section{Example: Titanic}\label{CPExample}}

For continuous explanatory variables, a natural way to represent the CP function is to use a profile plot similar to the ones presented in Figure \ref{fig:profileAgeRf}. In the figure, the dot on the curves marks an instance prediction, i.e., prediction \(f(x_*)\) for a single observation \(x_*\). The curve itself shows how the prediction would change if the value of a particular explanatory variable changed.

Figure \ref{fig:profileAgeRf} presents CP profiles for the \emph{age} variable in the logistic regression \texttt{titanic\_lmr\_v6} and random forest model \texttt{titanic\_rf\_v6} for the Titanic dataset (see Sections \ref{model-titanic-lmr} and \ref{model-titanic-rf}, respectively). It is worth observing that the profile for the logistic regression model is smooth, while the one for the random forest model shows more variability. For this instance (observation), the prediction for the logistic regression model would increase substantially if the value of \emph{age} became lower than 20. For the random forest model, a substantial increase would be obtained if \emph{age} became lower than 13 or so.



\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/profile_age_rf} 

}

\caption{Ceteris-paribus profiles for variable \texttt{age} for the logistic regression (\texttt{titanic\_lmr\_v6}) and random forest (\texttt{titanic\_rf\_v6} ) models that predict the probability of surviving based on the Titanic data. Black dot corresponds to the passenger \texttt{johny\_d}.}\label{fig:profileAgeRf}
\end{figure}

For a categorical explanatory variable, a natural way to represent the CP function is to use a barplot similar to the ones presented in Figure \ref{fig:profileAgeRf2}. The barplots in Figure \ref{fig:profileAgeRf} present CP profiles for the \emph{class} variable in the logistic regression and random forest models for the Titanic dataset (see Sections \ref{model-titanic-lmr} and \ref{model-titanic-rf}, respectively). For this instance (observation), the predicted probability for the logistic regression model would decrease substantially if the value of \emph{class} changed to ``2nd''. On the other hand, for the random forest model, the largest change would be marked if \emph{class} changed to ``restaurant staff''.



\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/profile_class_rf} 

}

\caption{Ceteris-paribus profiles for variable \texttt{class} for the logistic regression (\texttt{titanic\_lmr\_v6}) and random forest (\texttt{titanic\_rf\_v6} ) models that predict the probability of surviving based on the Titanic data.}\label{fig:profileAgeRf2}
\end{figure}

Usually, black-box models contain a large number of explanatory variables. However, CP profiles are legible even for tiny subplots, created with techniques like sparklines or small multiples \citep{Tufte1986}. In this way we can display a large number of profiles at the same time keeping profiles for consecutive variables in separate panels, as shown in Figure \ref{fig:profileV4Rf} for the random forest model for the Titanic dataset. It helps if these panels are ordered so that the most important profiles are listed first. We discuss a method to assess the importance of CP profiles in the next chapter.



\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/profile_v4_rf3} 

}

\caption{Ceteris-paribus profiles for all continuous explanatory variables for the random forest (\texttt{titanic\_rf\_v6}) model for the \texttt{titanic} dataset.}\label{fig:profileV4Rf}
\end{figure}

\hypertarget{CPProsCons}{%
\section{Pros and cons}\label{CPProsCons}}

One-dimensional CP profiles, as presented in this chapter, offer a uniform, easy to communicate and extendable approach to model exploration. Their graphical representation is easy to understand and explain. It is possible to show profiles for many variables or models in a single plot. CP profiles are easy to compare, thus we can juxtapose two or more models to better understand differences between models. We can also compare two or more instances to better understand model stability. CP profiles are also a useful tool for sensitivity analysis.

But. There are several issues related to the use of the CP profiles. If explanatory variables are correlated, then changing one variable implies a change in the other. In such case, the application of the \emph{Ceteris paribus} principle may lead to unrealistic settings, as it is not possible to keep one variable fixed while varying the other one. For example, apartment's price prediction features like surface and number of rooms are correlated thus it is unrealistic to consider very small apartments with extremely large number of rooms. Special cases are interactions, which require the use of two-dimensional CP profiles that are more complex than one-dimensional ones. Also, in case of a model with hundreds or thousands of variables, the number of plots to inspect may be daunting. Finally, while barplots allow visualization of CP profiles for factors (categorical explanatory variables), their use becomes less trivial in case of factors with many nominal (unordered) categories (like, for example, a ZIP-code).

\hypertarget{CPR}{%
\section{Code snippets for R}\label{CPR}}

In this section, we present key features of the R package \texttt{DALEX} which is a part of \texttt{DrWhy.AI} universe and covers all methods presented in this chapter. Note that presented functions in fact are wrappers to package \texttt{ingredients} \citep{ingredientsRPackage}.

Note that there are also other R packages that offer similar functionality, like \texttt{condvis} \citep{condvisRPackage}, \texttt{pdp} \citep{pdpRPackage}, \texttt{ICEbox} \citep{ICEbox}, \texttt{ALEPlot} \citep{ALEPlotRPackage}, \texttt{iml} \citep{imlRPackage}.

For illustration, we use two classification models developed in Chapter \ref{TitanicDataset}, namely the logistic regression model \texttt{titanic\_lmr\_v6} (Section \ref{model-titanic-lmr}) and the random forest model \texttt{titanic\_rf\_v6} (Section \ref{model-titanic-rf}). They are developed to predict the probability of survival after sinking of Titanic. Instance-level explanations are calculated for a single observation \texttt{henry} - a 47 years old male passenger that travelled in the 1st class.

\texttt{DALEX} explainers for both models and the \texttt{henry} data frame are retrieved via the \texttt{archivist} hooks as listed in Section \ref{ListOfModelsTitanic}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"rms"}\NormalTok{)}
\NormalTok{explain_lmr_v6 <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/34e19"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}
\NormalTok{explain_rf_v6 <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/6ed54"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{henry <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/a6538"}\NormalTok{)}
\NormalTok{henry}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   class gender age sibsp parch fare  embarked
## 1   1st   male  47     0     0   25 Cherbourg
\end{verbatim}

\hypertarget{basic-use-of-the-individual_profile-function}{%
\subsection{\texorpdfstring{Basic use of the \texttt{individual\_profile} function}{Basic use of the individual\_profile function}}\label{basic-use-of-the-individual_profile-function}}

The easiest way to create and plot CP profiles is to call \texttt{individual\_profile()} function and then the generic \texttt{plot()} function. By default, profiles for all variables are being calculated and all numeric features are being plotted. One can limit the number of variables that should be considered with the \texttt{variables} argument.

To obtain CP profiles, the \texttt{individual\_profile()} function requires the explainer-object and the instance data frame as arguments. As a result, the function yields an object of the class \texttt{ceteris\_paribus\_explainer}. It is a data frame with model predictions.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{cp_titanic_rf <-}\StringTok{ }\KeywordTok{individual_profile}\NormalTok{(explain_rf_v6, }
                                    \DataTypeTok{new_observation =}\NormalTok{ henry)}
\NormalTok{cp_titanic_rf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Top profiles    : 
##                class gender age sibsp parch fare  embarked _yhat_ _vname_
## 1                1st   male  47     0     0   25 Cherbourg  0.246   class
## 1.1              2nd   male  47     0     0   25 Cherbourg  0.054   class
## 1.2              3rd   male  47     0     0   25 Cherbourg  0.100   class
## 1.3        deck crew   male  47     0     0   25 Cherbourg  0.454   class
## 1.4 engineering crew   male  47     0     0   25 Cherbourg  0.096   class
## 1.5 restaurant staff   male  47     0     0   25 Cherbourg  0.092   class
##     _ids_       _label_
## 1       1 Random Forest
## 1.1     1 Random Forest
## 1.2     1 Random Forest
## 1.3     1 Random Forest
## 1.4     1 Random Forest
## 1.5     1 Random Forest
## 
## 
## Top observations:
##   class gender age sibsp parch fare  embarked _yhat_       _label_ _ids_
## 1   1st   male  47     0     0   25 Cherbourg  0.246 Random Forest     1
\end{verbatim}

To obtain a graphical representation of CP profiles, the generic \texttt{plot()} function can be applied to the data frame returned by the \texttt{individual\_profile()} function. It returns a \texttt{ggplot2} object that can be processed further if needed. In the examples below, we use the \texttt{ggplot2} functions, like \texttt{ggtitle()} or \texttt{ylim()}, to modify plot's title or the range of the Y-axis.

The resulting plot can be enriched with additional data by applying functions \texttt{ingredients::show\_rugs} (adds rugs for the selected points), \texttt{ingredients::show\_observations} (adds dots that shows observations), or \texttt{ingredients::show\_aggreagated\_profiles}. All these functions can take additional arguments to modify size, color, or linetype.

Below we show an R snippet that can be used to replicate plots presented in the upper part of Figure \ref{fig:profileV4Rf}.



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(cp_titanic_rf, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus Profile"}\NormalTok{, }
            \StringTok{"For the random forest model and the titanic dataset"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicCeterisProfile01-1} 

}

\caption{Ceteris-paribus profiles for \texttt{age} and \texttt{fare} variables and the \texttt{titanic\_rf\_v6} model.}\label{fig:titanicCeterisProfile01}
\end{figure}

By default, all numerical variables are plotted.
To plot CP profiles for categorical variables, we have got to add the \texttt{variable\_type\ =\ "categorical"} argument to the \texttt{plot()} function. The code below an be used to recreate the right-hand-side plot from Figure \ref{fig:profileAgeRf2}.



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(cp_titanic_rf, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"class"}\NormalTok{, }\StringTok{"embarked"}\NormalTok{), }
     \DataTypeTok{variable_type =} \StringTok{"categorical"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus profile"}\NormalTok{, }
            \StringTok{"For the random forest model and the titanic dataset"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/titanicCeterisProfile01B-1} 

}

\caption{Ceteris-paribus profiles for \texttt{class} and \texttt{embarked} variables and the \texttt{titanic\_rf\_v6} model.}\label{fig:titanicCeterisProfile01B}
\end{figure}

\hypertarget{advanced-use-of-the-individual_profile-function}{%
\subsection{\texorpdfstring{Advanced use of the \texttt{individual\_profile} function}{Advanced use of the individual\_profile function}}\label{advanced-use-of-the-individual_profile-function}}

The \texttt{individual\_profile()} is a very flexible function. To better understand how it can be used, we briefly review its arguments.

\begin{itemize}
\tightlist
\item
  \texttt{x}, \texttt{data}, \texttt{predict\_function}, \texttt{label} - information about a model. If \texttt{x} is created with the \texttt{DALEX::explain} function, then other arguments are extracted from \texttt{x}; this is how we use the function in this chapter. Otherwise, we have got to specify directly the model, the validation data, the predict function, and the model label.
\item
  \texttt{new\_observation} - instance (one or more), for which we want to calculate CP profiles. It should be a data frame with same variables as in the validation data.
\item
  \texttt{y} - observed value of the dependent variable for \texttt{new\_observation}. The use of this argument is illustrated in Section \ref{cPLocDiagIntro}.
\item
  \texttt{variables} - names of explanatory variables, for which CP profiles are to be calculated. By default, the profiles will be constructed for all variables, which may be time consuming.
\item
  \texttt{variable\_splits} - a list of values for which CP profiles are to be calculated. By default, these are all values for categorical variables. For continuous variables, uniformly-placed values are selected; one can specify the number of the values with the \texttt{grid\_points} argument (the default is 101).
\end{itemize}

The code below allows to obtain the plots in the upper part of Figure \ref{fig:profileV4Rf}. The argument \texttt{variable\_splits} specifies the variables (\texttt{age} and \texttt{fare}) for which CP profiles are to be calculated, together with the list of values at which the profiles are to be evaluated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cp_titanic_rf <-}\StringTok{ }\KeywordTok{individual_profile}\NormalTok{(explain_rf_v6, henry,}
              \DataTypeTok{variable_splits =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{age =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{70}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                     \DataTypeTok{fare =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{, }\FloatTok{0.1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(cp_titanic_rf, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus profile"}\NormalTok{, }
          \StringTok{"For the random forest model and the titanic dataset"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicCeterisProfile01C-1} 

}

\caption{Ceteris-paribus profiles for \texttt{class} and \texttt{embarked} variables and the \texttt{titanic\_rf\_v6} model. Blue dot stands for \texttt{henry}.}\label{fig:titanicCeterisProfile01C}
\end{figure}

To enhance the plot, additional functions can be used. The generic \texttt{plot()} function creates a \texttt{ggplot2} object with a single \texttt{geom\_line} layer. Function \texttt{show\_observations} adds \texttt{geom\_point} layer, \texttt{show\_rugs} adds \texttt{geom\_rugs}, while \texttt{show\_profiles} adds another \texttt{geom\_line}. All these functions take, as the first argument, an object created with the \texttt{ceteris\_paribus} function. They can be combined freely to superimpose profiles for different models or observations.

In the example below, we present the code to create CP profiles for two passengers, \texttt{henry} and \texttt{johny\_d}. Their profiles are included in a plot presented in Figure \ref{fig:titanicCeterisProfile01D}. We use the \texttt{scale\_color\_manual} function to add names of passengers to the plot, and to control colors and positions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{johny_d <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/e3596"}\NormalTok{)}
\NormalTok{cp_titanic_rf2 <-}\StringTok{ }\KeywordTok{variable_profile}\NormalTok{(explain_rf_v6, }\KeywordTok{rbind}\NormalTok{(henry, johny_d))}
\end{Highlighting}
\end{Shaded}



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ingredients)}
\KeywordTok{plot}\NormalTok{(cp_titanic_rf2, }\DataTypeTok{color =} \StringTok{"_ids_"}\NormalTok{, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_color_manual}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Passenger:"}\NormalTok{, }\DataTypeTok{breaks =} \DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{, }
            \DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"#4378bf"}\NormalTok{, }\StringTok{"#8bdcbe"}\NormalTok{), }
            \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"henry"}\NormalTok{ , }\StringTok{"johny_d"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus profile"}\NormalTok{, }
            \StringTok{"For the random forest model and the titanic dataset"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicCeterisProfile01D-1} 

}

\caption{Ceteris-paribus profiles for the \texttt{titanic\_rf\_v6} model. Profiles for different passengers are color-coded.}\label{fig:titanicCeterisProfile01D}
\end{figure}

\hypertarget{champion-challenger-analysis}{%
\subsection{Champion-challenger analysis}\label{champion-challenger-analysis}}

One of the most interesting uses of the explainers is comparison of CP profiles for two or more of models.

To illustrate this possibility, first, we have go to construct profiles for the models. In our illustration, for the sake of clarity, we limit ourselves just to two models: the logistic regression and random forest models for the Titanic data. Moreover, we only consider the \texttt{age} and \texttt{fare} variables. We use \texttt{henry} as the instance, for which predictions are of interest.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cp_titanic_rf <-}\StringTok{ }\KeywordTok{ceteris_paribus}\NormalTok{(explain_rf_v6, henry)}
\NormalTok{cp_titanic_lmr <-}\StringTok{ }\KeywordTok{ceteris_paribus}\NormalTok{(explain_lmr_v6, henry)}
\end{Highlighting}
\end{Shaded}

Subsequently, we construct the plot. The result is shown in Figure \ref{fig:titanicCeterisProfile01E}. Predictions for \texttt{henry} are slightly different, logistic regression returns in this case higher predictions then random forest. For \texttt{age} variable profiles of both models are similar, in both models we see decreasing dependency. While for \texttt{fare} the logistic regression model is slightly positive while random forest is negative. The larger the \texttt{fare} the larger is difference between these models. Such analysis helps us to which degree different models agree on what if scenarios.

Note that every \texttt{plot} and \texttt{show\_*} function can take a collection of explainers as arguments. Profiles for different models are included in a single plot. In the presented R snippet, models are color-coded with the help of the argument \texttt{color\ =\ "\_label\_"}, where \texttt{\_label\_} refers to the name of the column in the CP explainer that contains the model label.



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(cp_titanic_rf, cp_titanic_lmr, }\DataTypeTok{color =} \StringTok{"_label_"}\NormalTok{, }
     \DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"fare"}\NormalTok{)) }\OperatorTok{+}
\StringTok{     }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus Profiles for Henry"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicCeterisProfile01E-1} 

}

\caption{Champion-challenger comparison of the \texttt{titanic\_lmr\_v6} and \texttt{titanic\_rf\_v6} models. Profiles for different models are color-coded.}\label{fig:titanicCeterisProfile01E}
\end{figure}

\hypertarget{ceterisParibusOscillations}{%
\chapter{Ceteris-paribus Oscillations}\label{ceterisParibusOscillations}}

\hypertarget{CPOscIntro}{%
\section{Introduction}\label{CPOscIntro}}

Visual examination of Ceteris-paribus (CP) profiles is insightful, but for a model with a large number of explanatory variables we may end up with a large number of plots which may be overwhelming. To prioritize between the profiles we need a measure that would summarize the impact of a selected variable on model's predictions. In this chapter we describe a solution closely linked with CP profiles. An alternative instance-level variable importance is discussed in the Chapters \ref{breakDown} (Break Down), \ref{shapley} (SHAP) and \ref{LIME} (LIME).

\hypertarget{CPOscIntuition}{%
\section{Intuition}\label{CPOscIntuition}}

To assign importance to CP profiles, we can use the concept of profile oscillations. In particular, the larger influence of an explanatory variable on prediction at a particular instance, the larger the fluctuations along the corresponding CP profile. For a variable that exercises little or no influence on model prediction, the profile will be flat or will barely change. In other words, the values of the CP profile should be close to the value of the model prediction for the particular instance. Consequently, the sum of differences between the profile and the value of the prediction, take across all possible values of the explanatory variable, should be close to zero. The sum can be graphically depicted by the area between the profile and the horizontal line representing the instance prediction. On the other hand, for an explanatory variable with a large influence on the prediction, the area should be large. Figure \ref{fig:CPVIPprofiles} illustrates the concept. Panel A of the Figure corresponds to the CP profiles presented in Figure \ref{fig:profileV4Rf}. The larger the highlighted area in Figure \ref{fig:CPVIPprofiles}, the more important is the variable for the particular prediction.



\begin{figure}

{\centering \includegraphics[width=0.99\linewidth]{figure/profile_v4_rf2} 

}

\caption{The value of the colored area summarizes the Ceteris-paribus-profile oscillations and provides the mean of the absolute deviations between the CP profile and the instance prediction. Panel A shows plots for continuous explanatory variables, while panel B shows plots for categorical variables in the \texttt{titanic\_rf\_v6} model.}\label{fig:CPVIPprofiles}
\end{figure}

\hypertarget{CPOscMethod}{%
\section{Method}\label{CPOscMethod}}

Let us formalize this concept now. Denote by \(g^j(z)\) the probability density function of the distribution of the \(j\)-th explanatory variable. The summary measure of the variable's importance for model prediction at point \(x_*\), \(vip_{CP}^{j}(x_*)\), computed based on the variable's CP profile, is defined as follows:

\begin{equation}
vip_{CP}^j(x_*) = \int_{\mathcal R} |h^{j}_{x_*}(z) - f(x_*)| g^j(z)dz=E_{X^j}\left[|h^{j}_{x_*}(X^j) - f(x_*)|\right].
\label{eq:VIPCPdef}
\end{equation}

Thus, \(vip_{CP}^j(x_*)\) is the expected absolute deviation of the CP profile from the model prediction for \(x_*\) over the distribution \(g^j(z)\) for the \(j\)-th explanatory variable.

The true distribution of \(j\)-th explanatory variable is, in most cases, unknown. Thus, there are several options how to calculate Equation \eqref{eq:VIPCPdef}.

One is to calculate just the area under the CP curve, i.e., to assume that \(g^j(z)\) is a uniform distribution for the range of variable \(x^j\). It folows then that a straightforward estimator of \(vip_{CP}^{j,uni}(x_*)\) is

\begin{equation}
\widehat{vip}_{CP}^{j,uni}(x_*) = \frac 1k \sum_{l=1}^k |h^{j}_{x_*}(z_l) - f(x_*)|,
\label{eq:VIPCPuni}
\end{equation}

where \(z_l\) (\(l=1, \ldots, k\)) are the selected values of the \(j\)-th explanatory variable. For instance, one can select use all unique values of \(x^{j}\) in the considered dataset. Alternatively, for a continuous variable, one can use an equidistant grid of values.

Another approach is to use the empirical distribution for \(x^{j}\). This leads to the estimator of \(vip_{CP}^{j,emp}(x_*)\) defined as

\begin{equation}
\widehat{vip}_{CP}^{j,emp}(x_*) = \frac 1n \sum_{i=1}^n |h^{j}_{x_*}(x^{j}_i) - f(x_*)|,
\label{eq:VIPCPemp}
\end{equation}

where index \(i\) goes through all observations in a dataset.

The use of of \(\widehat{vip}_{CP}^{j,emp}(x_*)\) is preferred when there are enough data to accurately estimate the empirical distribution and when the distribution is not uniform. On the other hand, \(\widehat{vip}_{CP}^{j,uni}(x_*)\) is in most cases quicker to compute and, therefore, it is preferred if we look for fast approximations.

It is worth noting that the importance of an explanatory variable for instance prediction may be very different for different points \(x_*\). For example, consider model
\[
f(x_1, x_2) = x_1 * x_2,
\]
where \(x_1\) and \(x_2\) take values in \([0,1]\). Consider prediction for an observation described by vector \(x_* = (0,1)\). In that case, the importance of \(X_1\) is larger than \(X_2\). This is because the CP profile for the first variable, given by the values of function \(f(z,1)=z\), will have oscillations. On the other hand, the profile for the second variable will show no oscillations, because the profile is given by function \(f(0,z)=0\). Obviously, the situation is reversed for \(x_*=(1,0)\).

\hypertarget{CPOscExample}{%
\section{Example: Titanic}\label{CPOscExample}}

Figure \ref{fig:CPVIP1} provides a barplot of variable importance measures for different continuous explanatory variables for the random forest model \texttt{titanic\_rf\_v6} for \texttt{johny\_d}.

The longer the bar, the larger the CP-profile oscillations for a particular explanatory variable. Thus, Figure \ref{fig:CPVIP1} indicates that the most important variable for prediction for the selected observation are \texttt{gender} and \texttt{sibsp}, followed by \texttt{age}.

From the Ceteris Paribus one can read that if Henry were older, this would significantly lower the chance of survival. One the other hand, were Henry not travelling alone, this would increase the chance.

From the oscillation's plot one can only read which features are important but one cannot read how they influence the prediction. This is why profile oscillations shall be accompanied by Ceteris Paribus profiles.



\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{figure/oscillations_all_rf_plot} 

}

\caption{Variable-importance measures calculated for Ceteris-paribus oscillations for \texttt{johny\_d} based on the \texttt{titanic\_rf\_v6} model.}\label{fig:CPVIP1}
\end{figure}

\hypertarget{CPOscProsCons}{%
\section{Pros and cons}\label{CPOscProsCons}}

Oscillations of CP profiles are easy to interpret and understand. By using the average of oscillations, it is possible to select the most important variables for an instance prediction. This method can easily be extended to two or more variables. In such cases one needs to integrate the equation \eqref{eq:VIPCPuni} over larger number of variables.

There are several issues related to the use of the CP oscillations. For example, the oscillations may not be of help in situations when the use of CP profiles may itself be problematic (e.g., in the case of correlated explanatory variables or interactions - see Section \ref{CPProsCons}). An important issue is that the CP based local variable importance do not sum up to the instance prediction for which they are calculated, opposite to Break Down (Chapter \ref{breakDown}) and Shapley values (Chapter \ref{shapley}).

\hypertarget{CPOscR}{%
\section{Code snippets for R}\label{CPOscR}}

In this section, we present key features of R package \texttt{DALEX} which is a part of the \texttt{DrWhy.AI} universe and covers all methods presented in this chapter.

For illustration purposes we use the random forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf}). Recall that it is developed to predict the probability of survival from sinking of Titanic. Instance-level explanations are calculated for a single observation: \texttt{henry} - a 47-year-old passenger that travelled in the 1st class.

\texttt{DALEX} explainers for both models and the Henry data are retrieved via \texttt{archivist} hooks as listed in Section \ref{ListOfModelsTitanic}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}
\NormalTok{explain_rf_v6 <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/6ed54"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{henry <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/a6538"}\NormalTok{)}
\NormalTok{henry}
\end{Highlighting}
\end{Shaded}

\hypertarget{basic-use-of-the-variable_attribution-function-1}{%
\subsection{\texorpdfstring{Basic use of the \texttt{variable\_attribution} function}{Basic use of the variable\_attribution function}}\label{basic-use-of-the-variable_attribution-function-1}}

To calculate CP oscillations, we have got to calculate CP profiles for the selected observation. We use \texttt{henry} as the instance prediction of interest.

CP profiles are calculated by applying the \texttt{variable\_attribution()} function to the \texttt{explainer} object to calculate the oscillations and the estimated value of the variable-importance measure as in Equation \eqref{eq:VIPCPdef}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ingredients"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}

\NormalTok{(oscillations_titanic_rf <-}\StringTok{ }\KeywordTok{variable_attribution}\NormalTok{(explain_rf_v6, }
\NormalTok{                                henry, }\DataTypeTok{type =} \StringTok{"oscillations"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    _vname_ _ids_ oscillations
## 2   gender     1   0.33700000
## 4    sibsp     1   0.15500000
## 3      age     1   0.14700000
## 1    class     1   0.14257143
## 6     fare     1   0.05407273
## 7 embarked     1   0.02400000
## 5    parch     1   0.00800000
\end{verbatim}

Note that, by default, \texttt{variable\_attribution(type\ =\ "oscillations")} estimates \(vip_{CP}^j(x_*)\) by \(\widehat{vip}_{CP}^{j,uni}(x_*)\), given in \eqref{eq:VIPCPuni}, using all unique values of the explanatory variable as the grid points.

The\texttt{variable\_attribution(type\ =\ "oscillations")} function returns an object of class \texttt{ceteris\_paribus\_oscillations}, which has a form of a data frame, but has also an overloaded \texttt{plot()} function. We can use the latter function to plot the local variable-importance measures for the instance of interest.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oscillations_titanic_rf}\OperatorTok{$}\StringTok{`}\DataTypeTok{_ids_}\StringTok{`}\NormalTok{ <-}\StringTok{ "Henry"}
\KeywordTok{plot}\NormalTok{(oscillations_titanic_rf) }\OperatorTok{+}\StringTok{ }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus Oscillations"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicCeterisProfile02E-1} \end{center}

\hypertarget{advanced-use-of-the-variable_attribution-function-1}{%
\subsection{\texorpdfstring{Advanced use of the \texttt{variable\_attribution} function}{Advanced use of the variable\_attribution function}}\label{advanced-use-of-the-variable_attribution-function-1}}

As mentioned in the previous section, \texttt{variable\_attribution()} estimates \(vip_{CP}^j(x_*)\) by \(\widehat{vip}_{CP}^{j,uni}(x_*)\) using all unique values of the explanatory variable as the grid points. However, other approaches are also possible.

One is to use \(\widehat{vip}_{CP}^{j,uni}(x_*)\), but assuming an equi-distant grid of values for a continuous explanatory variable. Toward this aim, we have got to explicitly specify a dense uniform grid of values for such a variable. The \texttt{variable\_splits} argument can be used for this purpose.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oscillations_uniform <-}\StringTok{ }\KeywordTok{variable_attribution}\NormalTok{(explain_rf_v6, henry, }
              \DataTypeTok{variable_splits =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{age =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{65}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                     \DataTypeTok{fare =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{200}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                     \DataTypeTok{sibsp =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{8}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                     \DataTypeTok{parch =} \KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{8}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                     \DataTypeTok{gender =} \KeywordTok{unique}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{gender),}
                                     \DataTypeTok{embarked =} \KeywordTok{unique}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{embarked),}
                                     \DataTypeTok{class =} \KeywordTok{unique}\NormalTok{(titanic}\OperatorTok{$}\NormalTok{class)), }
              \DataTypeTok{type =} \StringTok{"oscillations"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Subsequently, we apply the \texttt{calculate\_oscillations()} function to compute the oscillations and the variable-importance measures.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oscillations_uniform}\OperatorTok{$}\StringTok{`}\DataTypeTok{_ids_}\StringTok{`}\NormalTok{ <-}\StringTok{ "Henry"}
\NormalTok{oscillations_uniform}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    _vname_ _ids_ oscillations
## 5   gender Henry    0.3370000
## 3    sibsp Henry    0.1677778
## 1      age Henry    0.1677235
## 7    class Henry    0.1425714
## 2     fare Henry    0.1040790
## 6 embarked Henry    0.0240000
## 4    parch Henry    0.0100000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(oscillations_uniform) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus Oscillations"}\NormalTok{, }
            \StringTok{"Expectation over uniform distribution"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicCeterisProfile02G-1} \end{center}

Another approach is to calculate the expectation \eqref{eq:VIPCPdef} over the empirical distribution of a variable, i..e, to use \(\widehat{vip}_{CP}^{j,emp}(x_*)\), given in \eqref{eq:VIPCPemp}. Toward this aim, we use the \texttt{variable\_splits} argument to explicitly specify the validation-data sample to define the grid of values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic <-}\StringTok{ }\KeywordTok{na.omit}\NormalTok{(titanic)}

\NormalTok{oscillations_empirical <-}\StringTok{ }\KeywordTok{variable_attribution}\NormalTok{(explain_rf_v6, henry, }
              \DataTypeTok{variable_splits =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{age =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{age,}
                                     \DataTypeTok{fare =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{fare,}
                                     \DataTypeTok{sibsp =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{sibsp,}
                                     \DataTypeTok{parch =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{parch,}
                                     \DataTypeTok{gender =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{gender,}
                                     \DataTypeTok{embarked =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{embarked,}
                                     \DataTypeTok{class =}\NormalTok{ titanic}\OperatorTok{$}\NormalTok{class),}
              \DataTypeTok{type =} \StringTok{"oscillations"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oscillations_empirical}\OperatorTok{$}\StringTok{`}\DataTypeTok{_ids_}\StringTok{`}\NormalTok{ <-}\StringTok{ "Henry"}
\NormalTok{oscillations_empirical}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    _vname_ _ids_ oscillations
## 1      age Henry  0.153323969
## 5   gender Henry  0.149336656
## 7    class Henry  0.133567739
## 2     fare Henry  0.056883552
## 3    sibsp Henry  0.035932034
## 6 embarked Henry  0.019818758
## 4    parch Henry  0.001623924
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(oscillations_empirical) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus Oscillations"}\NormalTok{, }
              \StringTok{"Expectation over empirical distribution"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicCeterisProfile02I-1} \end{center}

\hypertarget{localDiagnostics}{%
\chapter{Local Diagnostics Plots}\label{localDiagnostics}}

\hypertarget{cPLocDiagIntro}{%
\section{Introduction}\label{cPLocDiagIntro}}

It may happen that, while the global predictive performance of a model is good, the model predictions for some observations are very misfitted. We often say that the model does not cover well some areas of the input space.

For example, a model calibrated for typical patients in a certain hospital may not do well with exceptionally young patients. Or a model calibrated for the credit risk of spring holiday consumer loans may not work well on a group of autumn loans for Christmas holiday gifts.
For this reason, we should not be satisfied with global measures of model performance. For important decisions, it is good to check how the model behaves for observations similar to the instance of interest.

In this chapter, we present two local-diagnostics techniques that address this issue, namely, \emph{local fidelity plots} that show local performance around observation of interest and \emph{local stability plots} that show the local stability around observation of interest.

The general idea behind fidelity plots is to select a number of observations (``neighbors'') from the validation dataset that are closest to the instance (observation) of interest. Then, for the selected observations, we plot CP profiles and check how stable they are. Additionally, if we know true values of the dependent variable for the selected neighbors, we may add residuals to the plot to evaluate the local fit of the model.

\hypertarget{cPLocDiagIntuition}{%
\section{Intuition}\label{cPLocDiagIntuition}}

Assume that we have identified a set of observations from the training data similar in terms of dependent variables to the observation of interest.
The basic idea behind local fidelity plots is to compare distribution of residuals for these similar cases against distribution of all residuals.

Figure \ref{fig:profileBack2BackHist} presents histograms of residuals for the entire dataset and the selected neighbors for the random forest model for the Apartments dataset (Section \ref{model-Apartments-rf}). The distribution of residuals for the entire dataset is rather symmetric and centered around 0, suggesting a reasonable average performance of the model. On the other hand, the residuals for the selected neighbors are centered around the value of 500. This suggests that for the apartment of interest around this apartment the model is biased towards values smaller than observed (residuals are positive, so on average \(y\) is higher than \(\hat y\), see \eqref{eq:modelResiduals}).



\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{figure/bb_hist} 

}

\caption{Histograms of residuals for the \texttt{apartments\_rf\_v5} model for the Apartments dataset. Upper panel: residuals calculated for all observations from the dataset. Bottom panel: residuals calculated for 25 nearest neighbors of the instance of interest.}\label{fig:profileBack2BackHist}
\end{figure}

Another approach to local model diagnostics is to examine how stable is model behaviour around the observation of interest.
Figure \ref{fig:profileWith10NN} presents CP profiles for variable \texttt{age} for the instance of interest and its 10 nearest neighbors for the random forest model for the Titanic dataset (Section \ref{model-titanic-rf}). The profiles are almost parallel and very close to each other. This suggests that model predictions are stable around the instance of interest, because small changes in the explanatory variables (represented by the nearest neighbors) have not got much influence on the predictions.



\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{figure/example_cp} 

}

\caption{Ceteris-paribus profiles for a selected instance (dark violet line) and 10 nearest neighbors (light grey lines) for the \texttt{titanic\_rf\_b6} model. The profiles are almost parallel and close to each other what suggests the stability of the model.}\label{fig:profileWith10NN}
\end{figure}

Of course CP profiles for different variables may be very different so a natural question arises which variables shall we examine. The most natural choice is to explore the most important variables according to results from the Break Down, SHAP, LIME od CP Oscillations methods.

\hypertarget{cPLocDiagMethod}{%
\section{Method}\label{cPLocDiagMethod}}

The proposed method is based on three steps:

\begin{itemize}
\tightlist
\item
  first, we need to select observations nearest to the observation of interest,
\item
  for fidelity analysis we need to calculate and compare residuals for the neighbors.
\item
  for stability analysis we need to calculate and visualize CP profiles for the selected neighbors.
\end{itemize}

In what follows we discuss each of the elements in more detail.

\hypertarget{cPLocDiagNeighbors}{%
\subsection{Nearest neighbors}\label{cPLocDiagNeighbors}}

There are two important questions related to the selection of the neighbors ``nearest'' to the instance (observation) of interest:

\begin{itemize}
\tightlist
\item
  How many neighbors should we choose?
\item
  What metric should be used to measure the ``proximity'' of observations?
\end{itemize}

The answer to both questions is \emph{it depends}.

\begin{itemize}
\tightlist
\item
  The smaller the number of neighbors, the more local is the analysis. However, a very small number will lead to a larger variability of the results. In many cases we found that 20 neighbors works fine. However, one should always take into account computational time (smaller number of neighbors results in quicker calculations) and the size of the dataset (for a small dataset, smaller sets of neighbors may be preferred).
\item
  The metric is very important. The more explanatory variables, the more important is the choice. In particular, the metric should be capable of accommodating variables of different nature (categorical, continuous). Our default choice is the Gower similarity measure:
  \[
  d_{gower}(x_i, x_j) = \frac 1p \sum_{k=1}^p d^k(x_i^k, x_j^k),
  \]
  where \(x_i\) is a \(p\)-dimensional vector of explanatory covariates for the \(i\)-th observation and \(d^k(x_i^k,x_j^k)\) is the distance between values of the \(k\)-th variable for the \(i\)-th and \(j\)-th observations. Note that \(d^k()\) depends on the nature of the variable. For instance, for a continuous variable it is equal to \(|x_i^k-x_j^k|/\{max(x_1^k,\ldots,x_n^k)-min(x_1^k,\ldots,x_n^k)\}\), i.e., the absolute difference scaled by the observed range of the variable. On the other hand, for a categorical variable, it is simply \(I(x_i^k = x_j^k)\), where \(I()\) is the indicator function. Note that \(p\) may be equal to the number of all explanatory variables included in the model, or only a subset of them. An advantage of Gower similarity measure is that it ``deals'' with heterogeneous vectors with both categorical and continuous variables.
  The disadvantage of Gower similarity measure is that it does not take into account neither variable correlation nor variable importance. For high dimensional setting an interesting alternative would be the proximity measure in Random Forest \citep{randomForestBreiman}. It takes into account variable importance but requires a fitted Random Forest model.
\end{itemize}

Once we have decided on the number of neighbors, we can use the chosen metric to select the required number observations ``closest'' to the one of interest.

\hypertarget{cPLocDiagLFplot}{%
\subsection{Local-fidelity plot}\label{cPLocDiagLFplot}}

Figure \ref{fig:profileBack2BackHist} illustrates two distribution of residuals, for the whole dataset and for neighbours of the observation of interest.

For a typical observation these two distributions shall be similar. An alarming situation would be if the residuals for neighbours will be shifted towards the extremely positive of negative values.

Apart from visual examination we may also use some statistical tests that compares these two distributions. Since we cannot assume any distribution for residuals we can use a nonparametric test like Wilcoxon test or Kolmogorov-Smirnov test.

{[}TODO: maybe we need a better test for the stochastic dominance, or it is enough to have a test for location parameter?{]}

\hypertarget{cPLocDiagProfiles}{%
\subsection{Local-stability plot for neighbors}\label{cPLocDiagProfiles}}

Once nearest neighbors have been identified, we can graphically compare CP profiles for selected (or all) variables.

For a model with a large number of variables, we may end up with a large number of plots. In such a case a better strategy is to focus only on \(K\) most important variables, selected by using the variable-importance measure (see for example Chapter \ref{ceterisParibusOscillations}).

CP profiles are helpful to assess the model stability. In addition, we can enhance the plot by adding residuals to it to allow evaluation of the local model fit. For model \(f()\) and observation \(i\) described by the vector of explanatory variables \(x_i\), the residual is the difference between the observed and predicted value of the dependent variable \(Y_i\). Let us recall the definition \eqref{eq:modelResiduals}:

\[
r_i = y_i - f(x_i).
\]
Note that, for a binary variable, the residual is the difference between the value of 0 or 1, depending on how we code ``success,'' and the value of the predicted probability of ``success.'' This definition also applies to categorical responses, as it is common to define, in such case, a binary ``success'' indicator and compute the predicted probability of ``success'' for each category separately.

The plot that includes CP profiles for the nearest neighbors and the corresponding residuals is called a local-fidelity plot. See an example in Figure \ref{fig:profileWith10NN}.

\hypertarget{cPLocDiagExample}{%
\section{Example: Titanic}\label{cPLocDiagExample}}

As an example, we will use the predictions for the random forest model for the Titanic data (see Section \ref{model-titanic-rf}).

Figure \ref{fig:localFidelityPlots} presents a detailed explanation of the elements of a local-fidelity plot for \emph{age}, a continuous explanatory variable. The plot includes eight nearest neighbors of Henry (see Section \ref{predictions-titanic}). Profiles are quite apart from each other, which indicates potential instability of model predictions. However, the residuals included in the plots are positive and negative, indicating that, on average, the instance prediction should not be biased.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/localFidelityPlots} 

}

\caption{Elements of a local-stability plot for a continuous explanatory variable. The green line shows the Ceteris-paribus profile for the instance of interest. Profiles of the nearest neighbors are marked with grey lines. The vertical intervals correspond to residuals; the shorter the interval, the smaller the residual and the more accurate prediction of the model. Blue intervals correspond to positive residuals, red intervals to negative intervals. Stable model will have profiles close to each other; additive model will have parallel lines.}\label{fig:localFidelityPlots}
\end{figure}

Figure \ref{fig:localFidelityPlots2} presents a local-fidelity plot for the categorical explanatory variable \texttt{class}. Henry and his neighbors traveled in the \texttt{1st} class. In different panels we see how the predicted probability of survival changes if the \texttt{1st} class is replaced, for instance, by the \texttt{2nd} (in most cases, they probability will be reduced) or the \texttt{deck\ crew} (in most cases, the probability will increase). Such plots can help to detect interactions, as we see that the same change (let's say, from the \texttt{1st} to the \texttt{3rd} class) results in a different change of the model prediction.



\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/cp_fidelity_2} 

}

\caption{The local-stability plot for the categorical explanatory variable \texttt{class} in the random effects model for the Titanic data, \texttt{johny\_d}, and his 10 neighbors. Each panel indicates how the model prediction would change if the class changed from \texttt{1st} to another one. Dots indicate original model predictions for the neighbors; the end of the interval corresponds to model prediction after changing the class. The top-lef panel indicates that, for the majority of the neighbors, the change from the \texttt{1st} to the \texttt{2nd} class reduces the predicted value of the probability of survival. On the other hand, the top-right panel indicates that changing the lass to \texttt{deck\ crew} members increases the predicted probability.}\label{fig:localFidelityPlots2}
\end{figure}

\hypertarget{cPLocDiagProsCons}{%
\section{Pros and cons}\label{cPLocDiagProsCons}}

Local fidelity and stability plots may be very helpful to check if

\begin{itemize}
\tightlist
\item
  the model is locally additive, as for such models the CP profiles should be parallel;
\item
  the model is locally stable, as in that case the CP profiles should be close to each other;
\item
  the model fit for the instance of interest is good, as in that case the residuals should be small and their distribution should be balanced around 0.
\end{itemize}

The drawback is that such plots are quite complex and lack objective measures of the quality of the model fit. Thus, they are mainly suitable for an exploratory analysis.

\hypertarget{cPLocDiagR}{%
\section{Code snippets for R}\label{cPLocDiagR}}

In this section, we show how to use the R package \texttt{DALEX} \citep{DALEX} to construct local-fidelity plots.

We use the random forest model \texttt{titanic\_rf\_v6} developed for the Titanic dataset (see Section \ref{model-titanic-rf} ) as the example. Recall that we try to address a classification problem for a binary dependent variable - we want to predict the probability of survival for a selected passenger.

\texttt{DALEX} explainers for the model and the \texttt{henry} data frame are retrieved via \texttt{archivist} hooks, as listed in Section \ref{ListOfModelsTitanic}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{explain_rf_v6 <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/6ed54"}\NormalTok{)}
\NormalTok{henry <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/a6538"}\NormalTok{)}
\NormalTok{henry}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   class gender age sibsp parch fare  embarked
## 1   1st   male  47     0     0   25 Cherbourg
\end{verbatim}

We will show how to construct fidelity plot as in Figure \ref{fig:profileWith10NN}. Toward this aim we need some number of passengers most similar to \texttt{henry}.
Here we are using \texttt{individual\_diagnostics} function from the \texttt{DALEX} package. First argument is an explainer, second the instance of interest, optional arguments are \texttt{neighbours} (number of neighbours) and \texttt{distance} (by default, the Gower distance is used).

This function needs to calculate residuals, so explainer shall be created with the \texttt{y} argument and also the \texttt{residual\_function} argument.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{id_rf_v6 <-}\StringTok{ }\KeywordTok{individual_diagnostics}\NormalTok{(explain_rf_v6,}
\NormalTok{                          henry,}
                          \DataTypeTok{neighbours =} \DecValTok{100}\NormalTok{)}
\NormalTok{id_rf_v6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  residuals_all and residuals_sel
## D = 0.45973, p-value = 2.116e-09
## alternative hypothesis: two-sided
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(id_rf_v6)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/residualDistributionFidelityPlot-1} \end{center}

The function \texttt{individual\_diagnostics()} can be also used for a local stability plot as in Figure \ref{fig:localFidelityPlots} and \ref{fig:residualDistributionStabilityPlotClass}. To do this we need to also specify an \texttt{variables} argument.

Toward this aim, we use the \texttt{y} argument in the \texttt{individual\_profile()} function. The argument takes numerical values. Our binary dependent variable \texttt{survived} assumes values \texttt{yes/no}; to convert them to numerical values, we use the \texttt{survived\ ==\ "yes"} expression.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{id_rf_v6 <-}\StringTok{ }\KeywordTok{individual_diagnostics}\NormalTok{(explain_rf_v6,}
\NormalTok{                          henry, }
                       \DataTypeTok{neighbours =} \DecValTok{10}\NormalTok{,}
                       \DataTypeTok{variables =} \StringTok{"age"}\NormalTok{)}
\NormalTok{id_rf_v6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Top profiles    : 
##     class gender        age sibsp parch fare  embarked _yhat_ _vname_
## 1     1st   male  0.1666667     0     0   25 Cherbourg  0.574     age
## 1.1   1st   male  2.0000000     0     0   25 Cherbourg  0.596     age
## 1.2   1st   male  4.0000000     0     0   25 Cherbourg  0.596     age
## 1.3   1st   male  7.0000000     0     0   25 Cherbourg  0.550     age
## 1.4   1st   male  9.0000000     0     0   25 Cherbourg  0.544     age
## 1.5   1st   male 13.0000000     0     0   25 Cherbourg  0.492     age
##     _ids_       _label_
## 1       1 Random Forest
## 1.1     1 Random Forest
## 1.2     1 Random Forest
## 1.3     1 Random Forest
## 1.4     1 Random Forest
## 1.5     1 Random Forest
## 
## 
## Top observations:
##   class gender age sibsp parch fare  embarked _yhat_       _label_ _ids_
## 1   1st   male  47     0     0   25 Cherbourg  0.254 Random Forest     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(id_rf_v6)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/residualDistributionStabilityPlot-1} \end{center}

As we see the 10 passengers closest to \texttt{henry} are all from the \texttt{1st} class with age span between 20 and 60. Profiles for both \texttt{age} and \texttt{class} looks stable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{id_rf_v6 <-}\StringTok{ }\KeywordTok{individual_diagnostics}\NormalTok{(explain_rf_v6,}
\NormalTok{                          henry, }
                       \DataTypeTok{neighbours =} \DecValTok{10}\NormalTok{,}
                       \DataTypeTok{variables =} \StringTok{"class"}\NormalTok{)}
\NormalTok{id_rf_v6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Top profiles    : 
##                class gender age sibsp parch fare  embarked _yhat_ _vname_
## 1                1st   male  47     0     0   25 Cherbourg  0.254   class
## 1.1              2nd   male  47     0     0   25 Cherbourg  0.056   class
## 1.2              3rd   male  47     0     0   25 Cherbourg  0.096   class
## 1.3        deck crew   male  47     0     0   25 Cherbourg  0.482   class
## 1.4 engineering crew   male  47     0     0   25 Cherbourg  0.086   class
## 1.5 restaurant staff   male  47     0     0   25 Cherbourg  0.082   class
##     _ids_       _label_
## 1       1 Random Forest
## 1.1     1 Random Forest
## 1.2     1 Random Forest
## 1.3     1 Random Forest
## 1.4     1 Random Forest
## 1.5     1 Random Forest
## 
## 
## Top observations:
##   class gender age sibsp parch fare  embarked _yhat_       _label_ _ids_
## 1   1st   male  47     0     0   25 Cherbourg  0.254 Random Forest     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(id_rf_v6)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/residualDistributionStabilityPlotClass-1} \end{center}

\hypertarget{summaryInstanceLevel}{%
\chapter{Summary of Instance-level Explainers}\label{summaryInstanceLevel}}

In the first part of the book, we introduced a number of techniques for exploration and explanation of model predictions for individual instances.
In each chapter we introduced and presented a single technique.
But in practice these techniques rarely shall be used separately. It's more informative to combine different views offered by each technique into a more holistic overview.

See an example in Figure \ref{fig:instanceLevelExplainers}. Four different approaches to the explanation of the random forest model are used.
First row shows results from variable attribution methods like LIME, SHAP and Break Down. All these method agree that the most important variables for \texttt{johny\_d} are his \texttt{age}, \texttt{gender}, \texttt{class} and \texttt{fare.} Since \texttt{fare} and \texttt{class} are correlated and possibly \texttt{age} is in the interaction with \texttt{gender} then the additive decomposition is ambiguous.
Second row shows Ceteris Paribus profiles for these four most important variables. We see that higher age or being in the \texttt{2nd} class in he \texttt{restaurant\ staff} would decrease the model response while lower fare (which is counter intuitive), being a female or in the \texttt{deck\ crew} would increase the model response.
Third row show univariate distributions of particular variables. We see that \texttt{fare=72} is very high as for a ticket and that only small fraction of people on the titanic were children (no kids in the crew). Combination of different perspectives supplement each other.



\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figure/instance_level} 

}

\caption{Instance-level explanations of the fandom forest model for the titanic data and \texttt{johny\_d} an 8-years old boy that travels in the 1ts class.}\label{fig:instanceLevelExplainers}
\end{figure}

In the Chapter \ref{UseCaseFIFA} we show an example how instance level explanations may be combined with dataset level explanations on a new use-case related to FIFA 19 data.

On one hand it is good to supplement different techniques for explanation with each other, but on another hand these techniques are different and may be more or less suitable for some selected problems. Below we discuss some differences.

\hypertarget{number-of-explanatory-variables-in-the-model}{%
\section{Number of explanatory variables in the model}\label{number-of-explanatory-variables-in-the-model}}

One of the most important criteria for selection of model exploration and explanation methods is the number of explanatory variables in the model.

\hypertarget{low-to-medium-number-of-explanatory-variables}{%
\subsection{Low to medium number of explanatory variables}\label{low-to-medium-number-of-explanatory-variables}}

A low number of variables usually implies that the particular variables have a very concrete meaning and interpretation. An example are models for the Titanic data presented in Sections \ref{model-titanic-lmr}-\ref{model-titanic-gbm}.

In such a situation, the most detailed information about the influence of the variables on the model predictions is provided by the CP profiles. In particular, the variables that are most influential for model predictions are selected by considering CP-profile oscillations (see Chapter \ref{ceterisParibusOscillations}) and then illustrated graphically with the help of individual-variable CP profiles (see Chapter \ref{ceterisParibus}).

\hypertarget{medium-to-large-number-of-explanatory-variables}{%
\subsection{Medium to large number of explanatory variables}\label{medium-to-large-number-of-explanatory-variables}}

In models with a medium or large number of variables, it is still possible that most (or all) of them are interpretable. An example of such a model is a car-insurance pricing model in which we need to estimate the value of an insurance based on behavioral data that includes 100+ variables about characteristics of the driver and characteristics of the car.

When the number of explanatory variables increases, it becomes harder to show CP profile for each individual variable. In such situation, the most common approach is to use BD plots, presented in Chapter \ref{breakDown}, or plots of Shapley values, discussed in Chapter \ref{shapley}). They allow a quick evaluation whether a particular variable has got a positive or negative effect on model's prediction; we can also judge the size of the effect. If necessary, it is possible to limit the plots only to the variables with the largest effects.

\hypertarget{very-large-number-of-explanatory-variables}{%
\subsection{Very large number of explanatory variables}\label{very-large-number-of-explanatory-variables}}

When the number of explanatory variables is very large, it may be difficult to interpret the role of each single variable. An example of such situation are models for processing of images or texts. In that case, explanatory variables may be individual pixels in image processing or individual characters in text analysis. As such, their individual interpretation is limited. Due to additional issues with computational complexity, it is not feasible to use CP profiles, BD plots, nor Shapley values to evaluate influence of individual values on model's predictions. Instead, the most common approach is to use LIME, presented in Chapter \ref{LIME}, which works on context-relevant groups of variables.

\hypertarget{correlated-explanatory-variables}{%
\section{Correlated explanatory variables}\label{correlated-explanatory-variables}}

When we derived some properties for presented methods we assumed that explanatory variables are independent. Obviously, this is not always the case. For instance, in the case of the data on apartment prices (see Chapter \ref{ApartmentDataset}), the number of rooms and surface of an apartment will most likely be positively associated same is true for the class variable and fare for titanic data.

Of course all presented methods can be applied for correlated features, however sometimes it may be harder to analyze these features independently from each other.

To address the issue, the two most common approaches are:
* to create new features that are independent (sometimes it is possible due to domain knowledge; sometimes it can e achieve by using principal components analysis or a similar technique),
* construct two-dimensional extensions for CP plots (model response is plotted as a 2d surface) or permute variables in blocks to preserve the correlation structure of variables.

\hypertarget{models-with-interactions}{%
\section{Models with interactions}\label{models-with-interactions}}

In models with interactions, the effect of one explanatory variable may depend on values of other variables. For example, the probability of survival on Titanic may decrease with age, but the effect may be different for different classes of passengers.
In such a case, to explore and explain model's predictions, we have got to consider not individual variables, but sets of variables included in interactions. To identify interactions, we can use BD plots as described in Chapter \ref{iBreakDown}. To show effects of an interaction we may use a set of CP profiles. For the Titanic example we may use CP profiles for age with to instances that differ only in gender. The less parallel are such profiles the higher the effect of an interaction.

\hypertarget{sparse-explanations}{%
\section{Sparse explanations}\label{sparse-explanations}}

Predictive models may use hundreds of explanatory variables to yield a prediction for a particular instance. However, for a meaningful interpretation and illustration, most of human beings can handle only a very limited (say, less than 10) number of variables. Thus, sparse explanations are of interest. The most common method that is used to construct such explanations is LIME (Chapter \ref{LIME}). However, constructing a sparse explanation for a complex model is not trivial and may be misleading. Hence, care is needed when applying LIME to very complex models.

\hypertarget{additional-uses-of-model-exploration-and-explanation}{%
\section{Additional uses of model exploration and explanation}\label{additional-uses-of-model-exploration-and-explanation}}

In the previous chapters we focused on the application of the presented methods to exploration and explanation of predictive models. However, the methods can also be used to other aims:

\begin{itemize}
\item
  Model improvement. If a model prediction is particularly bad for a selected observation, then the investigation of the reasons for such a bad performance may provide some hints about how to improve the model. In case of instance predictions it is easier to note that a selected explanatory variable should have a different effect than the observed one.
\item
  Additional domain-specific validation. Understanding which factors are important for model predictions helps in evaluation of the plausibility of the model. If the effects of some variables on the predictions are inconsistent with the domain knowledge, then this may provide a ground for criticising the model and, eventually, replacing it by another one. On the other hand, if the influence of the variables on model predictions is consistent with prior expectations, the user may become more confident with the model. Such a confidence is fundamental when the model predictions are used as a support for taking decisions that may lead to serious consequences, like in the case of, for example, predictive models in medicine.
\item
  Model selection. In case of multiple candidate models, one may use results of the model explanation techniques to select one of the candidates. It is possible that, even if two models are similar in terms of a global model fit, the fit of one of them is locally much better. Consider the following, highly hypothetical example. Assume that a model is sought to predict whether it will rain on a particular day in a region where it rains on a half of the days. Two models are considered: one which simply predicts that it will rain every other day, and another that predicts that it will rain every day since October till March. Arguably, both models are rather unsophisticated (to say the least), but they both predict that, on average, half of the days will be rainy. However, investigation of the instance predictions (for individual days) may lead to a preference for one of them.
\end{itemize}

\hypertarget{champion-challenger-analysis-1}{%
\section{Champion Challenger analysis}\label{champion-challenger-analysis-1}}

The techniques for explaining and exploring models have many applications. One of them is the opportunity to compare models.

Why compare models?
One scenario is the Champion-Challenger analysis. Let's assume that some institution uses a predictive model but wants to know if they could get a better model using other modeling techniques. For example, the risk department in a bank uses logistical regression to assess credit risk. The model has some efficiency and is the so-called champion - the best model considered in the class of logistic regression models.
However, it is worth checking whether using more complex models, so called challengers, e.g.~boosting or random trees, will not be more effective. And if they are more effective, the question will arise as to how these challengers differ from the champion.

Another reason why we want to compare models is because of the iterativness of the modeling process itself (see \ref{MDPprocess}). During the modeling process many versions of the models are created, often with different structures, sometimes with very similar efficiency. Comparative analysis allows for better understanding how these models differ from each other.

Below is an example of champion-challenger analysis for Random Forest model \texttt{model\_titanic\_rf}, logistic regression model \texttt{model\_titanic\_lmr}, boosting model of \texttt{model\_titanic\_gbm} and support-vector machines (SVM) model of \texttt{model\_titanic\_svm}.

Each of these models has a different way of functioning. Random forest and boosting models are on trees, so the response curves will be stepped one. The logistic regression and booster models have continuous and smooth response curves.

Figure \ref{fig:championChallengerSHAP} shows the Shapley values for the four models built in chapter \ref{TitanicDataset} using the example of \texttt{john\_d}. For three models, namely random forest, boosting and logistic regression, similar variables are indicated as important: \texttt{class}, \texttt{age} and \texttt{gender}. For the SVM model the most important variable is \texttt{gender}, followed by \texttt{age} and \texttt{parch}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/championChallengerSHAP-1} 

}

\caption{SHAP plots for four different models for the Titanic data.}\label{fig:championChallengerSHAP}
\end{figure}

Shapley values show an additive distribution for model predictions. In the chapter \ref{iBreakDown} we discussed what to do if the add-on attribute may not reflect the exact behaviour of the model.
Figure \ref{fig:championChallengerBD} compares Break Down plots with interactions for the four models under consideration.

Each of these models obviously has a different estimate for the chances of survival for \texttt{johny\_d}. The highest estimate has the logistic regression model \(0.764\) while the lowest estimate has the random forest model \(0.441\). For the SVM model, the most important variable is \texttt{gender} and for the other models, \texttt{age} and \texttt{class}. The Random Forest model included interactions of \texttt{fare:class} and the SVM model included interactions of \texttt{fare:age}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/championChallengerBD-1} 

}

\caption{Break Down plots for four different models for the Titanic data.}\label{fig:championChallengerBD}
\end{figure}

Figure \ref{fig:championChallengerCP} shows Ceteris Paribus profiles for the four models considered for the \texttt{age} and \texttt{fare} variables.
The logistic regression and GBM models behave in a similar way. Random forest and SVM models are much less sensitive to the \texttt{age} variable.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/championChallengerCP-1} 

}

\caption{Ceteris Paribus profiles for four different models for the Titanic data.}\label{fig:championChallengerCP}
\end{figure}

Each of the four models under consideration has a different structure and each of them is for some reason a complex model. Random forest and boosting models are complex due to the large number of trees used for prediction. The SVM model is complex due to the non-linear function of the kernel and the logistic regression model due to spline transformations.

The compilation of the operating profile of the models side-by-side allows for a better understanding of the similarities and differences in the signals that these models have learned.

\hypertarget{dataset-level}{%
\chapter*{Dataset Level}\label{dataset-level}}
\addcontentsline{toc}{chapter}{Dataset Level}

\begin{center}\includegraphics[width=0.99\linewidth]{figure/UMEPpiramideDataset} \end{center}

\hypertarget{modelLevelExploration}{%
\chapter{Model-level exploration}\label{modelLevelExploration}}

In Part I, we focused on instance-level explainers, which help to understand how a model yields a prediction for a single observation (instance).

In Part II, we concentrate on model-level explainers, which help to understand how model's predictions perform overall, for a set of observations. Assuming that the observations form a representative sample from a general population, model-level explainers can provide an information about the quality of predictions for the population.

The following examples illustrate situations in which model-level explainers may be useful:

\begin{itemize}
\tightlist
\item
  We may want to learn which variables are `'important'' in the model. For instance, we may be interested in predicting the risk of heart attack by using explanatory variables that are obtained based on results of some medical examinations. If some of the variables do not influence model's predictions, we could simplify the model by removing the variables.
\item
  We may want to understand how a selected variable influences model's predictions. For instance, we may be interested in predicting prices of apartments. Apartment's location is an important factor, but we may want to know which locations lead to higher prices?
\item
  We may want to discover whether there are any observations, for which the model yields wrong predictions. For instance, for a model predicting the probability of survival after a risky treatment, we might know whether there are patients for whom the model predictions are extremely wrong. Identifying such a group of patients might point to, for instance, an incorrect form of a explanatory variable or even a missed variable.
\end{itemize}

Model-level explainers focus on four main aspects of a model:

\begin{itemize}
\tightlist
\item
  Variable's importance: which explanatory variables are `'important'', and which are not?
\item
  Variable's effect: how does a variable influence average model's predictions?
\item
  Model's performance: how `'good'' is the model? Is one model `'better'' than another?
\item
  Model's fit: which observations are misfitted by the model, where residual are the largest?
\end{itemize}

In all cases, measures capturing a particular aspect of the model have to be defined. We will discuss them in subsequent chapters. In particular, in Chapter \ref{modelPerformance}, we discuss measures that are useful for the evaluation of the overall predictive model performance. In Chapter \ref{featureImportance}, we focus on methods that allow evaluation of a variable's effect on model's predictions. Chapter \ref{partialDependenceProfiles} and Chapter \ref{accumulatedLocalProfiles} focus on exploration of the effect of selected variables on model response. Chapter \ref{residualDiagnostic} presents an overview of the classical residual-diagnostics tools. Finally, in Chapter \ref{UseCaseFIFA}, we present an example of an analysis that illustrates the use of the model-level explainers introduced in the previous chapters.

\hypertarget{modelPerformance}{%
\chapter{Model Performance Measures}\label{modelPerformance}}

\hypertarget{modelPerformanceIntro}{%
\section{Introduction}\label{modelPerformanceIntro}}

In this chapter, we present measures that are useful for the evaluation of the overall performance of a predictive model. They may be applied for several purposes:

\begin{itemize}
\tightlist
\item
  model evaluation: we may want to know how good is the model, i.e., how reliable are the model predictions (how frequent and how large errors we may expect);
\item
  model comparison: we may want to compare two or more models in order to choose between them;
\item
  out-of-sample and out-of-time comparisons: we may want to check model's performance when applied to new data to evaluate if the performance has not worsened.
\end{itemize}

Depending of the nature of the dependent variable (continuous, binary, categorical, count, etc.), different model performance measures may be used. Moreover, the list of useful measures is growing as new applications emerge. In this chapter, we focus on a selected set of measures that are used in model-level exploration techniques that are introduced in subsequent chapters.

\hypertarget{modelPerformanceIntuition}{%
\section{Intuition}\label{modelPerformanceIntuition}}

Most model performance measures are based on comparison of the model predictions with the (known) values of the dependent variable in a dataset. For an ideal model, the predictions and the dependent-variable values should be equal. In practice, it is never the case, and we want to quantify the disagreement.

In applications, we can weigh differently the situation when the prediction is, for instance, larger than the true value, as compared to the case when it is smaller. Depending on the decision how to weigh different types of disagreement, we may need different performance measures.

When assessing model's overall performance, it is important to take into account the risk of overestimation of the quality of the performance when considering the data that were used for developing of the model. To mitigate the risk, various assessment strategies, such as cross-validation, have been proposed (see \citep{AppliedPredictiveModeling2013}). In what follows, we consider the simple train-test-split strategy, i.e., we assume that the available data are split into a training set and a testing set. Model is created on the training set, and the testing set is used to assess the model's performance.

In the best possible scenario we can specify a single model performance measure before the model is created and then we optimize model for this measure. But in practice the more common scenario is to have few performance measures that are often selected after the model is created.

\hypertarget{modelPerformanceMethod}{%
\section{Method}\label{modelPerformanceMethod}}

Assume that we have got a testing dataset with \(n\) observations on \(p\) explanatory variables and on a dependent variable \(Y\). Let \(x_i\) denote the (column) vector of values of the explanatory variables for the \(i\)-th observation, and \(y_i\) the corresponding value of the dependent variable. Denote by \(\widehat{y}_i=f(x_i)\) model's \(f()\) prediction corresponding to \(y_i\). Let \(X=(x'_1,\ldots,x'_n)\) denote the matrix of explanatory variables for all \(n\) observations, and \(y=(y_1,\ldots,y_n)'\) denote the (column) vector of the values of the dependent variable.

\hypertarget{modelPerformanceMethodCont}{%
\subsection{Continuous dependent variable}\label{modelPerformanceMethodCont}}

The most popular model performance measure for models for a continuous dependent variable is the mean squared-error, defined as

\begin{equation}
MSE(f,X,y) = \frac{1}{n} \sum_{i}^{n} (f(x_i) - y_i)^2 = \frac{1}{n} \sum_{i}^{n} r_i^2,
\label{eq:MSE}
\end{equation}

where \(r_i=f(x_i) - y_i\) is the residual for the \(i\)-th observation. Thus, MSE can be seen as a sum of squared residuals. MSE is a convex differentiable function, which is important from an optimization point of view. As the measure weighs all differences equally, large residuals have got a high impact on MSE. Thus, the measure is sensitive to outliers. For a `'perfect'' predictive model, which predicts all \(y_i\) exactly, \(MSE = 0\).

Note that MSE is constructed on a different scale than the dependent variable. Thus, a more interpretable variant of this measure is the root-mean-squared-error (RMSE), defined as

\begin{equation}
RMSE(f, X, y) = \sqrt{MSE(f, X, y)}.
\label{eq:RMSE}
\end{equation}

A popular variant of RMSE is its normalized version, \(R^2\), defined as

\begin{equation}
R^2(f, X, y) = 1 - \frac{MSE(f, X, y)}{MSE(f_0, X,y)}.
\label{eq:R2}
\end{equation}

In \eqref{eq:R2}, \(f_0()\) denotes a `'baseline'' model. For instance, in the case of the classical linear regression, \(f_0()\) is the model that includes only the intercept, which implies the use of the average value of \(Y\) as a prediction for all observations. \(R^2\) is normalized in the sense that the `'perfect'' predictive model leads to \(R^2 = 1\), while \(R^2 = 0\) means that we are not doing better than the baseline model. In the context of the classical linear regression, \(R^2\) is the familiar coefficient of determination and can be interpreted as the fraction of the total variance of \(Y\) explained by model \(f()\).

Given sensitivity of MSE to outliers, sometimes the median absolute-deviation (MAD) is considered as a model performance measure:

\begin{equation}
MAD(f, X ,y) = median( |r_1|, ..., |r_n| ).
\label{eq:MAD}
\end{equation}

MAD is more robust to outliers than MSE. A disadvantage of MAD are its less favorable mathematical properties.

\hypertarget{modelPerformanceMethodBin}{%
\subsection{Binary dependent variable}\label{modelPerformanceMethodBin}}

To introduce model performance measures, we, somewhat arbitrarily, label the two possible values of the dependent variable as `'success'' and `'failure'`. (Of course, in a particular application, the meaning of the'`success'' outcome does not have to be positive nor optimistic; in diagnostic tests `'success'' often means detection of a diseases.) We also assume that model prediction \(f(x_i)\) takes the form of the predicted probability of success.

If, additionally, we assign the value of 1 to success and 0 to failure, it is possible to use MSE, RMSE, and MAE, as defined in \eqref{eq:MSE}, \eqref{eq:RMSE}, \eqref{eq:MAD}, respectively, as a model performance measure. In practice, however, those summary measures are not often used. One of the main reasons is that they penalize too mildly for wrong predictions. In fact, the maximum penalty for an individual prediction is equal to 1 (if, for instance, the model yields zero probability for an actual success).

To address this issue, the log-likelihood function based on the Bernoulli distribution can be used:

\begin{equation}
l(f, X ,y) =  -\sum_{i=1}^{n} [y_i \ln\{f(x_i)\}+ (1-y_i) \ln\{1-f(x_i)\}].
\label{eq:bernoulli}
\end{equation}

Note that, in the machine-learning world, often \(l(f, X ,y)/n\) is considered (sometimes also with \(\ln\) replaced by \(\log_2\)) and termed `'logloss'' or `'cross-entropy'`. The log-likelihood heavily'`penalizes'' the cases when the model-predicted probability of success \(f(x_i)\) is high for an actual failure (\(y_i=0\)) and low for an actual success (\(y_i=1\)).

In many situations, however, a consequence of a prediction error depends on the form of the error. For this reason, performance measures based on the (estimated values of) probability of correct/wrong prediction are more often used. To introduce some of those measures, we assume that, for each observation from the testing dataset, the predicted probability of success \(f(x_i)\) is compared to a fixed cut-off threshold, \(C\) say. If the probability is larger than \(C\), then we assume that the model predicts success; otherwise, we assume that it predicts failure. As a result of such a procedure, the comparison of the observed and predicted values of the dependent variable for the \(n\) observations in the testing dataset can be summarized in the following table:

\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.24\columnwidth}\raggedright
True value: \texttt{success}\strut
\end{minipage} & \begin{minipage}[b]{0.32\columnwidth}\raggedright
True value: \texttt{failure}\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\raggedright
Total\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\(f(x) > C\), predicted: \texttt{success}\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
True Positive: \(TP_C\)\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright
False Positive (type I error): \(FP_C\)\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
\(P_C\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\(f(x) \leq C\), predicted: \texttt{failure}\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
False Negative (type II error): \(FN_C\)\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright
True Negative: \(TN_C\)\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
\(N_C\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Total\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright
S\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright
F\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
\(n\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

In machine-learning world, the table is often referred to as the `'confusion table'' or `'confusion matrix'`. In statistics, it is often called the'`decision table''. The counts \(TP_C\) and \(TN_C\) on the diagonal of the table correspond to the cases when the predicted and observed value of the dependent variable \(Y\) coincide. \(FP_C\) is the number of cases in which failure is predicted as success. These are false-positive, or type I error, cases. On the other hand, \(FN_C\) is the count of false-negative, or type II error, cases, in which success is predicted as failure. Marginally, there are \(P_C\) predicted successes and \(N_C\) predicted failures, with \(P_C+N_C=n\). In the testing dataset, there are \(S\) observed successes and \(F\) observed failures, with \(S+N=n\).

The simplest measure of model performance is \textbf{Accuracy}, defined as

\[
ACC_C = \frac{TP_C+TN_C}{n}.
\]
It is the fraction of correct predictions in the entire testing dataset. Accuracy is of interest if true positives and true negatives are more important than their false counterparts. However, accuracy may not be very informative when one of the binary categories is much more prevalent. For example, if the testing data contain 90\% of successes, a model that would always predict a success would reach accuracy of 0.9, although one could argue that this is not a very useful model.

There may be situations when false positives and/or false negatives may be of more concern. In that case, one might want to keep their number low. Hence, other measures, focused on the false results, might be of interest.

In the machine-learning world, two other measures are often considered: \textbf{Precision} and \textbf{Recall}. Precision is defined as

\[
Precision_C = \frac{TP_C}{TP_C+FP_C} = \frac{TP_C}{P_C}.
\]
Precision is also referred to as the positive predictive value. It is the fraction of correct predictions among the predicted successes. Precision is high if the number of false positives is low. Thus, it is a useful measure when the penalty for committing the type I error (false positive) is high. For instance, consider the use of a genetic test in cancer diagnostics, with a positive result of the test taken as an indication of an increased risk of developing a cancer. A false positive result of a genetic test might mean that a person would have to unnecessarily cope with emotions and, possibly, medical procedures, related to the fact of being evaluated as having a high risk of developing a cancer. We might want to avoid this situation more than the false negative case. The latter would mean that the genetic test gives a negative result for a person that, actually, might be at an increased risk of developing a cancer. However, an increased risk does not mean that the person will develop cancer. And even so, we could hope that we could detect it in due time.

Recall is defined as

\[
Recall_C = \frac{TP_C}{TP_C+FN_C} = \frac{TP_C}{S_C}.
\]
Recall is also referred to as sensitivity or true positive rate. It is the fraction of correct predictions among the true successes. Recall is high if the number of false negatives is low. Thus, it is a useful measure when the penalty for committing the type II error (false negative) is high. For instance, consider the use of an algorithm that predicts whether a bank transaction is fraudulent. A false negative result means that the algorithm accepts a fraudulent transaction as a legitimate one. Such a decision may have immediate and unpleasant consequences for the bank, because it may imply a non-recoverable loss of money. On the other hand, a false positive result means that a legitimate transaction is considered as fraudulent one and is blocked. However, upon further checking, the legitimate nature of the transaction can be confirmed with, perhaps, annoyed client as the only consequence for the bank.

The harmonic mean of these two measures defines the \textbf{F1 score}:

\[
F1\ score_C = \frac{2}{\frac{1}{Precision_C} + \frac{1}{Recall_C}} = 2\cdot\frac{Precision_C \cdot Recall_C}{Precision_C + Recall_C}.
\]
F1 score tends to give a low value if either precision or recall is low, and a high value if both precision and recall are high. For instance, if precision is 0, F1 score will also be 0 irrespectively of the value of recall. Thus, it is a useful measure if we have got to seek a balance between precision and recall.

In statistics, and especially in applications in medicine, the popular measures are \textbf{Sensitivity} and \textbf{Specificity}. Sensitivity is simply another name for recall. Specificity is defined as

\[
Specificity_C = \frac{TN_C}{TN_C + FP_C} = \frac{TN_C}{F_C}.
\]
Specificity is also referred to as true negative rate. It is the fraction of correct predictions among the true failures. Specificity is high if the number of false positives is low. Thus, as precision, it is a useful measure when the penalty for committing the type I error (false positive) is high.

The reason why sensitivity and specificity may be more often used outside the machine-learning world is related to the fact that their values do not depend on the proportion \(S/n\) (sometimes termed `'prevalence'') of true successes. This means that, once estimated in a sample obtained from a population, they may be applied to other populations, in which the prevalence may be different. This is not true for precision, because one can write

\[
Precision_C = \frac{Sensitivity_C \cdot \frac{S}{n}}{Sensitivity_C \cdot \frac{S}{n}+Specificity_C \cdot \left(1-\frac{S}{n}\right)}.
\]

All the measures depend on the choice of cut-off \(C\). To assess the form and the strength of dependence, a common approach is to construct the Receiver Operating Characteristic (ROC) curve. The curve plots the \(Sensitivity_C\) in function of \(1-Specificity_C\) for all possible, ordered values of \(C\). Figure \ref{fig:exampleROC} presents the ROC curve for the random-forest model for the Titanic dataset (see Section \ref{model-titanic-rf}). Note that the curve indicates an inverse relationship between sensitivity and specificity: by increasing one measure, the other is decreased.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure/ROCcurve} 

}

\caption{ROC curve for the random-forest model for the Titanic dataset. The Gini coefficient can be calculated as 2 x area between the ROC curve and the diagonal (this area is highlighted).}\label{fig:exampleROC}
\end{figure}

The ROC curve is very informative. For a model that predicts successes and failures at random, the corresponding ROC curve will be equal to the diagonal line. On the other hand, for a model that yields perfect predictions, the ROC curve reduces to a two intervals that connect points (0,0), (0,1), and (1,1).

Often, there is a need to summarize the ROC curve and, hence, model's performance. A popular measure that is used toward this aim is the area under the curve (AUC). For a model that predicts successes and failures at random, AUC is the area under the diagonal line, i.e., it is equal to 0.5. For a model that yields perfect predictions, AUC is equal to 1.

Another ROC-curve-based measure that is often used is the Gini coefficient \(G\). It is closely related to AUC; in fact, it can be calculated a \(G = 2 \times AUC - 1\). For a model that predicts successes and failures at random, \(G=0\); for a perfect-prediction model, \(G = 1\).

The value of Gini's coefficient or, equivalently, of \(AUC-0.5\) allow a comparison of the model-based predictions with random guessing. A measure that explicitly compares a prediction model with a baseline (or null) model is the \textbf{Lift}. Commonly, random guessing is considered as the baseline model. In that case,

\[
Lift_C  = \frac{\frac{TP_C}{P_C}}{\frac{S}{n}} = \frac{n Precision_C}{S}.
\]
Note that \(S/n\) can be seen as the estimated probability of a correct prediction of a success for random guessing. On the other hand, \(TP_C/P_C\) is the estimated probability of a correct prediction a success given that the model predicts a success. Hence, informally speaking, the lift indicates how many more (or less) times the model does better in predicting success than random guessing. As other measures, the lift depends on the choice of cut-off \(C\). The plot of the lift as a function of \(P_C\) is called the lift chart.

There are many more measures aimed at measuring performance of a predictive model for a linearly dependent variable. An overview can be found in, e.g., (Berrar D. Performance Measures for Binary Classification. Encyclopedia of Bioinformatics and Computational Biology Volume 1, 2019, Pages 546-560). {[}TOMASZ: INCLUDE IN THE REFERENCE LIST.{]}

\hypertarget{modelPerformanceMethodCateg}{%
\subsection{Categorical dependent variable}\label{modelPerformanceMethodCateg}}

To introduce model performance measures for a categorical dependent variable, we assume that \(y_i\) is now a vector of \(K\) elements. Each element \(y_{ik}\) (\(k=1,\ldots,K\)) is a binary variable indicating whether the \(k\)-th category was observed for the \(i\)-th observation. We assume that for each observation only one category can be observed. Thus, all elements of \(y_i\) are equal to 0 except of one that is equal to 1. Furthermore, We assume that model prediction \(f(x_i)\) takes the form of a vector of the predicted probabilities for each of the \(K\) categories. The predicted category is the one with the highest predicted probability.

The log-likelihood function \eqref{eq:bernoulli} can be adapted to the categorical dependent variable case as follows:

\begin{equation}
l(f, X ,y) =  -\sum_{i=1}^{n}\sum_{k=1}^{K} y_{ik} \ln\{f(x_i)_k\}.
\label{eq:multinom}
\end{equation}

It is essentially the log-likelihood function based on a multinomial distribution.

It is also possible to extend the performance measures like accuracy, precision, etc., introduced in Section \ref{modelPerformanceMethodBin}. Toward this end, first, a confusion table is created for each category \(k\), treating the category as `'success'' and all other categories as `'failure''. Let us denote the counts in the table by \(TP_k\), \(FP_k\), \(TN_k\), and \(FN_k\). Based on the counts, we can compute the average accuracy across all classes as follows:

\begin{equation}
\overline{ACC_C} = \frac{1}{K}\sum_{k=1}^K\frac{TP_{C,k}+TN_{C,k}}{n}.
\label{eq:accmacro}
\end{equation}

Similarly, one could compute the average precision, average sensitivity, etc. In machine-learning world, this approach is often termed `'macro-averaging''. The averages computed in that way treat all classes equally.

An alternative approach is to sum the appropriate counts from the confusion tables for all classes, and then form a measure based on the so-computed cumulative counts. For instance, for precision, this would lead to

\begin{equation}
\overline{Precision_C}_{\mu} = \frac{\sum_{k=1}^K TP_{C,k}}{\sum_{k=1}^K (TP_{C,k}+FP_{C,k})}.
\label{eq:precmicro}
\end{equation}

In machine-learning world, this approach is often termed `'micro-averaging'' (hence subscript \(\mu\) for `'micro'' in Equation \(Precision_{\mu}\) in \eqref{eq:precmicro}). Note that, for accuracy, this computation still leads to Equation \eqref{eq:accmacro}. The measures computed in that way favor classes with larger numbers of observations.

\hypertarget{modelPerformanceMethodCount}{%
\subsection{Count dependent variable}\label{modelPerformanceMethodCount}}

In case of counts, one could consider using any of the measures for a continuous dependent variable mentioned in Section \ref{modelPerformanceMethodCont}. However, a particular feature of a count dependent variable is that, often, its variance depends on the mean value. Consequently, weighing all contributions to MSE equally, as in Equation \eqref{eq:MSE}, is not appropriate, because the same residual value \(r_i\) indicates a larger discrepancy for a smaller count \(y_i\) than for a larger one. Therefore, a popular measure is of performance of a predictive model for counts is Pearson's statistic:

\begin{equation}
\chi^2(f,X,y) = \sum_{i}^{n} \left\{\frac{f(x_i) - y_i}{\sqrt{f(x_i)}}\right\}^2 = \sum_{i}^{n} \left\{\frac{r_i}{\sqrt{f(x_i)}}\right\}^2.
\label{eq:Pearson}
\end{equation}

From Equation \eqref{eq:Pearson} it is clear that, if the same residual value is obtained for two different observed counts, it is assigned a larger weight for the count for which the predicted value is smaller.

\hypertarget{example}{%
\section{Example}\label{example}}

\hypertarget{modelPerformanceApartments}{%
\subsection{Apartment prices}\label{modelPerformanceApartments}}

Let us consider the linear regression model \texttt{apartments\_lm\_v5} (see Section \ref{model-Apartments-lr}) and the random-forest model \texttt{apartments\_rf\_v5} (see Section \ref{model-Apartments-rf}) for the data on the apartment prices (see Section \ref{ApartmentDataset}). Recall that, for these data, the dependent variable, the price, is continuous. Hence, we can use the performance measures presented in Section \ref{modelPerformanceMethodCont}. In particular, we consider MSE and RMSE The values of the two measures for the two models are presented below.

\begin{verbatim}
## Model label:  Linear Regression v5 
##          score name
## mse  80137.98   mse
## rmse 283.0865  rmse

## Model label:  Random Forest v5 
##          score name
## mse  80061.77   mse
## rmse   282.952 rmse
\end{verbatim}

Both MSE and MAE indicate that, overall, the random-forest model performs better than the linear regression model.

\hypertarget{modelPerformanceTitanic}{%
\subsection{Titanic data}\label{modelPerformanceTitanic}}

Let us consider the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf} and the logistic regression model \texttt{titanic\_lmr\_v6} (see Section \ref{model-titanic-lmr}) for the Titanic data (see Section \ref{TitanicDataset}). Recall that, for these data, the dependent variable is binary, with success defined as survival of the passenger.

First, we will take a look at the accuracy, F1 score, and AUC for the models.

\begin{verbatim}
## Model label:  Logistic Regression v6 
##         score name
## auc 0.8196991  auc
## f1  0.6589018   f1
## acc 0.8046689  acc

## Model label:  Random Forest v6 
##         score name
## auc 0.8566304  auc
## f1  0.7289880   f1
## acc 0.8494521  acc
\end{verbatim}

Overall, the random-forest model is performing better, as indicated by the larger values of all the measures.

Figure \ref{fig:titanicROC} presents ROC curves for both models. The curve for the random-forest model lies above the one for the logistic regression model for the majority of the cut-offs \(C\), except for the very high values.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicROC-1} 

}

\caption{ROC curves for the  random-forest model and the logistic regression model for the Titanic dataset.}\label{fig:titanicROC}
\end{figure}

Figure \ref{fig:titanicLift} presents lift curves for both models. Also in this case the curve for the random-forest suggests a better performance than for the logistic regression model, except for the very high values of cut-off \(C\).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicLift-1} 

}

\caption{Lift curves for the Random forest model and the logistic regression model for the Titanic dataset.}\label{fig:titanicLift}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{ema_files/figure-latex/titanicGain-1} 

}

\caption{Cumulative gain chart for the Random forest model and the logistic regression model for the Titanic dataset.}\label{fig:titanicGain}
\end{figure}

\hypertarget{modelPerformanceProsCons}{%
\section{Pros and cons}\label{modelPerformanceProsCons}}

All model performance measures presented in this chapter face some limitations. For that reason, many measures are available, as the limitations of a particular measure were addressed by developing an alternative. For instance, RMSE is frequently used and reported for linear regression models. However, as it is sensitive to outliers, MAE was proposed. In case of predictive models for a binary dependent variable, the measures like accuracy, F1 score, sensitivity, and specificity, are often considered depending on the consequences of correct/incorrect predictions in a particular application. However, the value of those measures depends on the cut-off value used for creating the predictions. For this reason, ROC curve and AUC have been developed and have become very popular. They are not easily extended to the case of a categorical dependent variable, though.

Given the advantages and disadvantages of various measures, and the fact that each may reflect a different aspect of the predictive performance of a model, it is customary to report and compare several of them when evaluating a model's performance.

\hypertarget{modelPerformanceR}{%
\section{Code snippets for R}\label{modelPerformanceR}}

In this section, we present the key features of the \texttt{DALEX} R package which is a part of the \href{http://DrWhy.AI}{DrWhy.AI} universe. The package covers all methods presented in this chapter. Please note that more advanced measures of performance are available in the \texttt{auditor} R package \citep{R-auditor}.
Note that there are also other R packages that offer similar functionality. These include, for instance, packages \texttt{mlr} \citep{mlr}, \texttt{caret} \citep{caret}, \texttt{tidymodels} \citep{tidymodels}, and \texttt{ROCR} \citep{ROCR}.

For illustration purposes, we use the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf} and the logistic regression model \texttt{titanic\_lmr\_v6} (see Section \ref{model-titanic-lmr}) and the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf}) for the Titanic data (see Section \ref{TitanicDataset}). Consequently, the functions from the \texttt{DALEX} package are applied in the context of a binary classification problem. However, the same functions can be used for, e.g., linear regression problems.

To illustrate the use of the functions, we first load explainers for both models.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}

\NormalTok{explainer_titanic_rf <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\StringTok{ }\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/6ed54"}\NormalTok{)}
\NormalTok{explain_titanic_lmr <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\StringTok{ }\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/ff1cd"}\NormalTok{)}

\NormalTok{DALEX}\OperatorTok{::}\KeywordTok{model_performance}\NormalTok{(explainer_titanic_rf)}
\NormalTok{DALEX}\OperatorTok{::}\KeywordTok{model_performance}\NormalTok{(explain_titanic_lmr)}
\end{Highlighting}
\end{Shaded}

Function \texttt{DALEX::model\_performance()} calculates selected model performance measures. By default a set of selected performance measures are calculated. The argument \texttt{type} in the \texttt{explain()} function is used to determine if we deal with classification or regression model.
The \texttt{data} argument serves for specification of the test dataset, for which the selected measures are to be computed. Note that, by default, the data are extracted from the explainer object. Finally, it is possible to use the \texttt{cutoff} argument to specify the cut-off value to obtained cut-off-dependent measures like F1 score or accuracy.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{model_performance}\NormalTok{(explain_titanic_rf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Measures for:  classification
## recall   : 0.6385373 
## precision: 0.8832685 
## f1       : 0.7412245 
## accuracy : 0.8563661 
## auc      : 0.8595467
## 
## Residuals:
##      0%     10%     20%     30%     40%     50%     60%     70%     80% 
## -0.8920 -0.1140 -0.0240 -0.0080 -0.0040  0.0000  0.0000  0.0100  0.1400 
##     90%    100% 
##  0.5892  1.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{model_performance}\NormalTok{(explain_titanic_lmr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Measures for:  regression
## mse      : 0.1459437 
## rmse     : 0.3820258 
## r2       : 0.3316733 
## mad      : 0.2119129
## 
## Residuals:
##          0%         10%         20%         30%         40%         50% 
## -0.98457244 -0.31904861 -0.23408037 -0.20311483 -0.15200813 -0.10318060 
##         60%         70%         80%         90%        100% 
## -0.06933478  0.05858024  0.29306442  0.73666519  0.97151255
\end{verbatim}

ROC or lift curves can be constructed with the \texttt{plot()} function. The argument \texttt{geom} specifies what type of visual model performance summary shall be plotted. Use \texttt{geom\ =\ "lift"} for lift charts, \texttt{geom\ =\ "roc"} for ROC charts, \texttt{geom\ =\ "histogram"} for historam of residuals.
In all cases the plot functions return \texttt{ggplot2} objects and can take one or more explainer objects as arguments. In the latter case, the profiles for each explainer are superimposed on one plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eva_rf <-}\StringTok{ }\NormalTok{DALEX}\OperatorTok{::}\KeywordTok{model_performance}\NormalTok{(explain_titanic_rf)}
\NormalTok{eva_lr <-}\StringTok{ }\NormalTok{DALEX}\OperatorTok{::}\KeywordTok{model_performance}\NormalTok{(explain_titanic_lmr)}

\NormalTok{p1 <-}\StringTok{ }\KeywordTok{plot}\NormalTok{(eva_rf, eva_lr, }\DataTypeTok{geom =} \StringTok{"roc"}\NormalTok{)}
\NormalTok{p2 <-}\StringTok{ }\KeywordTok{plot}\NormalTok{(eva_rf, eva_lr, }\DataTypeTok{geom =} \StringTok{"lift"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(}\StringTok{"patchwork"}\NormalTok{)}
\NormalTok{p1 }\OperatorTok{+}\StringTok{ }\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ema_files/figure-latex/titanicMEexamples-1} \end{center}

The resulting plots are shown in Figures \ref{fig:titanicROC} and \ref{fig:titanicLift}. Both plots can be supplemented with boxplots for residuals. Toward this end, the residuals have got to be computed and added to the explainer object with the help of the \texttt{model\_performance()} function. Subsequently, the \texttt{plot()} can be applied to the resulting object.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(eva_rf, eva_lr, }\DataTypeTok{geom =} \StringTok{"boxplot"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{ema_files/figure-latex/titanicBoxplots-1} 

}

\caption{Boxplots for residuals for two models on Titanic dataset.}\label{fig:titanicBoxplots}
\end{figure}

\hypertarget{featureImportance}{%
\chapter{Variable's Importance}\label{featureImportance}}

\hypertarget{featureImportanceIntro}{%
\section{Introduction}\label{featureImportanceIntro}}

In this chapter, we present methods that are useful for the evaluation of an explanatory variable importance. The methods may be applied for several purposes.

\begin{itemize}
\tightlist
\item
  Model simplification: variables that do not influence model's predictions may be excluded from the model.
\item
  Model exploration: comparison of a variable's importance in different models may help in discovering interrelations between the variables.Also, ordering of variables in function of their importance is helpful in deciding in what order should we perform further model exploration.
\item
  Domain-knowledge-based model validation: identification of the most important variables may be helpful in assessing the validity of the model based on the domain knowledge.
\item
  Knowledge generation: identification of the most important variables may lead to discovery of new factors involved in a particular mechanism.
\end{itemize}

The methods for assessment of variable importance can be divided, in general, into two groups: model-specific and model-agnostic.

For models like linear models, random forest, and many others, there are methods of assessing of variable importance that exploit particular elements of the structure of the model. These are model-specific methods. For instance, for linear models, one can use the value of the normalized regression coefficient or its corresponding p-value as the variable-importance measure. For tree-based ensembles, such a measure may be based on the use of a particular variable in particular trees (see, e.g., \texttt{XgboostExplainer} \citep{xgboostExplainer} for gradient boosting and \texttt{RandomForestExplainer} \citep{randomForestExplainer} for random forest).

In this book we focus on model-agnostic methods. These methods do not assume anything about the model structure. Therefore, they can be applied to any predictive model or ensemble of models. Moreover, and perhaps even more importantly, they allow comparing variable importance between models with different structures.

\hypertarget{featureImportanceIntuition}{%
\section{Intuition}\label{featureImportanceIntuition}}

We focus on the method described in more detail in \citep{variableImportancePermutations}. The main idea is to measure how much the model fit decreases if the effect of a selected explanatory variable or of a group of variables is removed. The effect is removed by means of perturbations like resampling from an empirical distribution of just permutation of the values of the variable.

The idea is in some sense borrowed from variable important measure proposed by @ref\{randomForestBreiman\} for random forest. If a variable is important, then after permutation of this variable we expect that the model performance will be lower. The larger drop in the performance, the more important is the variable.

Despite the simplicity of definition, the permutation variable importance is a very powerful model agnostic tool for model exploration. Values of permutation variable importance may be compared between different structures of models. This property is discussed in detail in the section \emph{Pros and Cons}.

\hypertarget{featureImportanceMethod}{%
\section{Method}\label{featureImportanceMethod}}

Consider a set of \(n\) observations for a set of \(p\) explanatory variables. Denote by \(\widetilde{y}=(f(x_1),\ldots,f(x_n))\) the vector of predictions for model \(f()\) for all the observations. Let \(y\) denote the vector of observed values of the dependent variable \(Y\).

Let \(\mathcal L(\widetilde{y}, y)\) be a loss function that quantifies goodness of fit of model \(f()\) based on \(\widetilde{y}\) and \(y\). For instance, \(\mathcal L\) may be the value of likelihood. Consider the following algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute \(L = \mathcal L(\widetilde{y}, y)\), i.e., the value of the loss function for the original data.
\item
  For each explanatory variable \(X^j\) included in the model, do steps 3-6.
\item
  Replace vector \(x^j\) of observed values of \(X^j\) by vector \(x^{*j}\) of resampled or permuted values.
\item
  Calculate model predictions \(\widetilde{y}^{*j}\) for the modified data, \(\widetilde{y}^{*j} = f(x^{*j})\).
\item
  Calculate the value of the model performance for the modified data:
  \[
  L^{*j} = \mathcal L(\widetilde{y}^{*j}, y)
  \]
\item
  Quantify the importance of explanatory variable \(x^j\) by calculating \(vip_{Diff}(x^j) = L^{*j} - L\) or \(vip_{Ratio}(x^j) = L^{*j} / L\), where \(L\) is the value of the loss function for the original data.
\end{enumerate}

Note that the use of resampling or permuting data in Step 3 involves randomness. Thus, the results of the procedure may depend on the actual configuration of resampled/permuted values. Hence, it is advisable to repeat the procedure several times. In this way, the uncertainty related to the calculated variable-importance values can be assessed.

The calculations in Step 6 ``normalize'' the value of the variable importance measure with respect to \(L\). However, given that \(L\) is a constant, the normalization has no effect on the ranking of variables according to \(vip_{Diff}(x^j)\) or \(vip_{Ratio}(x^j)\). Thus, in practice, often the values of \(L^{*j}\) are simply used to quantify variable's importance.

\hypertarget{featureImportanceTitanic}{%
\section{Example: Titanic data}\label{featureImportanceTitanic}}

In this section, we illustrate the use of the permutation-based variable-importance method by applying it to the random forest model for the Titanic data (see Section \ref{model-titanic-rf}). Recall that the goal is to predict survival probability of passengers based on their sex, age, cityplace of embarkment, class in which they travelled, fare, and the number of persons they travelled with.

Figure \ref{fig:TitanicRFFeatImp} shows the values of loss function measured as \(1-AUC^{*j}\) after permuting, in turn, each of the variables included in the model. Additionally, the plot indicates the value of \(L\) by the vertical dashed line at the left-hand-side of the plot. Length of the bar span between \(L\) and \(L^{*j}=1-AUC^{*j}\) and correspond to the variable importance.

\begin{figure}
\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/TitanicRFFeatImp-1} \caption{Each interval presents the difference between the loss function for the original data (vertical dashed line at the left) and for the data with permuted observation for a particular variable.}\label{fig:TitanicRFFeatImp}
\end{figure}

The plot in Figure \ref{fig:TitanicRFFeatImp} suggests that the most important variable in the model is gender. This agrees with the conclusions drawn in the exploratory analysis presented in Section \ref{exploration-titanic}. The next three important variables are class of the travel (first-class patients had a higher chance of survival), age (children had a higher chance of survival), and fare (owners of more expensive tickets had a higher chance of survival).

To take into account the uncertainty related to the use of permutations, we can consider computing the average values of \(L^{*j}\) over a set of, say, 10 permutations. The plot in Figure \ref{fig:TitanicRFFeatImp10} presents the average values. The only remarkable difference, as compared to Figure \ref{fig:TitanicRFFeatImp}, is the change in the ordering of the \texttt{sibsp} and \texttt{parch} variables.

\begin{figure}
\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/TitanicRFFeatImp10-1} \caption{Average variable importance based on 10 permutations.}\label{fig:TitanicRFFeatImp10}
\end{figure}

The plots similar to those presented in Figures \ref{fig:TitanicRFFeatImp} and \ref{fig:TitanicRFFeatImp10} are useful for comparisons of variable importance for different models.
Figure \ref{fig:TitanicFeatImp} presents the single-permutation results for the random forest, gradient boosting (see Section \ref{model-titanic-gbm}), and logistic regression (see Section \ref{model-titanic-lmr}) models. The best result, in terms of the smallest value of the goodness-of-fit function \(L\), are obtained for the random forest model. Note, however, that this model includes more variables than the other two. For instance, variable \texttt{fare}, which is highly correlated with the travel class, is not important neither in the gradient boosting nor in the logistic regression model, but is important in the random forest model.

The plots in Figure \ref{fig:TitanicFeatImp} indicate that \texttt{gender} is the most important variable in all three models, followed by \texttt{class}.

\begin{figure}
\includegraphics[width=0.7\linewidth]{ema_files/figure-latex/TitanicFeatImp-1} \caption{Variable importance for the random forest, gradient boosting, and logistic regression models for the Titanic data.}\label{fig:TitanicFeatImp}
\end{figure}

\hypertarget{featureImportanceProsCons}{%
\section{Pros and cons}\label{featureImportanceProsCons}}

Permutation variable importance offer a model-agnostic approach to assessment of the influence of each variable on model performance. The approach offers several advantages. The plots are easy to understand. They are compact, all most important variables are presented in a single plot.

Permutation variable importance is expressed in a terms of model performance and can be compared between models. In different models the same variable may have different importance scores and comparison of such scores may lead to interesting insights. For example if variables are correlated then models like random forest are expected to spread importance across every variable while in regularized regression models coefficients for one correlated variable may dominate over coefficients for other variables.

The same approach can be used to measure importance of a single explanatory variable or a group of variables. The latter is useful for aspects - groups of variables that are complementary or are related to a similar concept. For example in the Titanic example the \texttt{fare} and \texttt{class} variables are linked with wealth of a passenger. Instead of calculation of effects of each variable independently we may calculate effect of both variables by permutation of both.

The disadvantage of this measure comes from the randomness behind permutations. For different permutations we may get different results. Also different choices of model performance measure, like Precision, Accuracy, AUC, lead to different numeric values of variable importance. And last disadvantage is related with the data used for assessment of model performance. Different importance values may be obtained on training and testing data.

\hypertarget{featureImportanceR}{%
\section{Code snippets for R}\label{featureImportanceR}}

For illustration, We will use the random forest model for the apartment prices data (see Section \ref{model-Apartments-rf}).

Let's recover a regression model for prediction of apartment prices.

A popular loss function for regression model is the root mean square loss.

\[
  L(y, \tilde y) = \sqrt{\frac1n \sum_{i=1}^n (y_i - \tilde y_i)^2}
\]

It is implemented in the \texttt{DALEX} package in the function \texttt{loss\_root\_mean\_square}. The initial loss function \(L\) for this model is

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{loss_root_mean_square}\NormalTok{(}
  \KeywordTok{predict}\NormalTok{(model_rf, apartmentsTest), }
\NormalTok{  apartmentsTest}\OperatorTok{$}\NormalTok{m2.price}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 792.8346
\end{verbatim}

Let's calculate variable importance for root mean square loss with the \texttt{model\_parts} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vip <-}\StringTok{ }\KeywordTok{model_parts}\NormalTok{(explainer_rf, }
            \DataTypeTok{loss_function =}\NormalTok{ loss_root_mean_square)}
\NormalTok{vip}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            variable mean_dropout_loss        label
## 1      _full_model_          796.0100 randomForest
## 2          no.rooms          828.4179 randomForest
## 3 construction.year          842.2287 randomForest
## 4          district          850.4096 randomForest
## 5             floor          858.8663 randomForest
## 6           surface          875.2063 randomForest
## 7        _baseline_         1118.4724 randomForest
\end{verbatim}

On a diagnostic plot is useful to present variable importance with boxplots that show results for different permutations.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(vip) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Permutation variable importance"}\NormalTok{, }\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{ema_files/figure-latex/featureImportanceUnoPlot-1.pdf}
\caption{\label{fig:featureImportanceUnoPlot}Permutation variable importance calculated as root mean square loss for random forest model for apartments data.}
\end{figure}

\hypertarget{models-comparison}{%
\subsection{Models comparison}\label{models-comparison}}

Variable importance plots are very useful tool for model comparison. In the section \ref{ApartmentDataset} we have trained three models on \texttt{apartments} dataset.
These were models with different structures to make the comparison more interesting.
Random Forest model \citep{R-randomForest} (elastic but biased), Support Vector Machines model \citep{R-e1071} (large variance on boundaries) and Linear Model (stable but not very elastic).

Let's calculate permutation variable importance with root mean square error for these three models.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vip_lm <-}\StringTok{ }\KeywordTok{variable_importance}\NormalTok{(explainer_lm, }
            \DataTypeTok{loss_function =}\NormalTok{ loss_root_mean_square)}
\NormalTok{vip_lm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            variable mean_dropout_loss label
## 1      _full_model_          281.8345    lm
## 2 construction.year          281.7864    lm
## 3          no.rooms          293.7945    lm
## 4             floor          486.0535    lm
## 5           surface          614.4047    lm
## 6          district         1018.8827    lm
## 7        _baseline_         1262.6592    lm
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vip_rf <-}\StringTok{ }\KeywordTok{variable_importance}\NormalTok{(explainer_rf, }
            \DataTypeTok{loss_function =}\NormalTok{ loss_root_mean_square)}
\NormalTok{vip_rf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            variable mean_dropout_loss        label
## 1      _full_model_          802.9422 randomForest
## 2          no.rooms          834.9660 randomForest
## 3 construction.year          851.9975 randomForest
## 4          district          852.5380 randomForest
## 5             floor          874.3987 randomForest
## 6           surface          880.9620 randomForest
## 7        _baseline_         1110.6190 randomForest
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vip_svm <-}\StringTok{ }\KeywordTok{variable_importance}\NormalTok{(explainer_svm, }
            \DataTypeTok{loss_function =}\NormalTok{ loss_root_mean_square)}
\NormalTok{vip_svm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            variable mean_dropout_loss label
## 1      _full_model_          984.9034   svm
## 2          district          950.4622   svm
## 3          no.rooms          980.3698   svm
## 4 construction.year         1041.9925   svm
## 5             floor         1072.9481   svm
## 6           surface         1096.7851   svm
## 7        _baseline_         1237.6861   svm
\end{verbatim}

Now we can plot variable importance for all three models on a single plot.
Intervals start in a different values, thus we can read that loss for SVM model is the lowest.

When we compare other variables it looks like in all models the \texttt{district} is the most important feature followed by \texttt{surface} and \texttt{floor}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(vip_rf, vip_svm, vip_lm) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Permutation variable importance"}\NormalTok{, }\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{ema_files/figure-latex/featureImportanceTriPlot-1.pdf}
\caption{\label{fig:featureImportanceTriPlot}Permutation variable importance on apartments data for Random forest, Support vector model and Linear model.}
\end{figure}

There is interesting difference between linear model and others in the way how important is the \texttt{construction.year}. For linear model this variable is not importance, while for remaining two models there is some importance.

In the next chapter we will see how this is possible.

\hypertarget{partialDependenceProfiles}{%
\chapter{Partial dependence profiles}\label{partialDependenceProfiles}}

\hypertarget{PDPIntro}{%
\section{Introduction}\label{PDPIntro}}

In this chapter we focus on partial dependence (PD) plots, sometimes also called PD profiles. They were introduced by Friedman in a paper devoted to Gradient Boosting Machines (GBM) \citep{Friedman00greedyfunction}. For many years PD profiles went unnoticed in the shadow of GBM. However, in recent years, the profiles have become very popular and are available in many data-science-oriented software packages like \texttt{DALEX}, \texttt{iml} \citep{imlRPackage}, \texttt{pdp} \citep{pdpRPackage}.

The general idea underlying the construction of PD profiles is to show how the expected value of model prediction behaves as a function of a selected explanatory variable. For a single model, one can construct an overall PD profile by using all observations from a dataset, or several profiles for sub-groups of the observations. Comparison of sub-group-specific PD profiles may provide important insight into, for instance, stability of the model predictions.\\
PD profiles are also useful for comparisons of different models:

\begin{itemize}
\tightlist
\item
  \emph{Agreement between profiles for different models is reassuring.} Some models are more flexible than others. If PD profiles for models from the two classes are similar, we can treat it as a evidence that the more flexible model is not over-fitting.
\item
  \emph{Disagreement between profiles may suggest a way to improve a model.} If a PD profile of a simpler, more interpretable model disagrees with a profile of a flexible model, this may suggest a variable transformation that can be used to improve the interpretable model. For example, if a random-forest model indicates a non-linear relationship between the dependent variable and an explanatory variable, then a suitable transformation of the explanatory variable may improve the fit or performance of a linear regression model.
\item
  \emph{Evaluation of model performance at boundaries.} Models are known to have a different behavior at the boundaries of dependent variables, i.e., for the largest or the lowest values. For instance, random-forest models are known to shrink predictions towards the average, whereas support-vector machines are known to have larger variance at edges. Comparison of PD profiles may help to understand the differences in models' behavior at boundaries.
\end{itemize}

\hypertarget{PDPIntuition}{%
\section{Intuition}\label{PDPIntuition}}

The general idea underlying the construction of PD profiles is to show how the expected value of model prediction behaves as a function of a selected explanatory variable. Toward this aim, the average of a set of individual Ceteris-paribus (CP) profiles is used. Recall that a CP profile (see Chapter \ref{ceterisParibus}) shows the dependence of an instance-level prediction for an explanatory variable. A PD profile is estimated by the average of the CP profiles for all instances (observations) from a dataset.

Note that, for additive models, CP profiles are parallel. In particular, they have got the same shape. Consequently, the average retains the shape, while offering a more precise estimate. However, for models that, for instance, include interactions, CP profiles may not be parallel. In that case, the average may not necessarily correspond to the shape of any particular profile. Nevertheless, it can still offer a summary of how (in general) the model predictions depend on changes in a given explanatory variable.

The left-hand-side panel of Figure \ref{fig:pdpIntuition} presents CP profiles for the explanatory variable age for the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{sec:model-titanic-rf}) for 25 randomly selected instances (observations) from the Titanic dataset (see Section \ref{sec:TitanicDataset}). Note that the profiles are not parallel, indicating non-additive effects of explanatory variables. The right-hand-side panel show the average of the CP profiles, which offers an estimate of the PD profile. Clearly, the shape of the PD profile does not capture, for instance, the shape of the three CP profiles shown at the top of the panel. Nevertheless, it does seem to reflect the fact that the majority of CP profiles suggest a substantial drop in the predicted probability of survival for the ages between 2 and 18.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/pdpIntuition-1} 

}

\caption{Ceteris-paribus and partial-dependence profiles for the random-forest model for 25 randomly selected observations from the Titanic dataset. Left: CP profiles for age; blue dots indicate the age and corresponding prediction for the selected observations. Right: CP profiles (grey lines) and the corresponding partial-dependence profile (blue line)}\label{fig:pdpIntuition}
\end{figure}

\hypertarget{PDPMethod}{%
\section{Method}\label{PDPMethod}}

\hypertarget{PDPs}{%
\subsection{Partial dependence profiles}\label{PDPs}}

The value of a PD profile for model \(f()\) and explanatory variable \(X^j\) at \(z\) is defined as follows:

\begin{equation}
g_{PD}^{f, j}(z) = E_{X^{-j}}[f(X^{j|=z})].
\label{eq:PDPdef0}
\end{equation}

Thus, it is the expected value of the model predictions when \(X^j\) is fixed at \(z\) over the (marginal) distribution of \(X^{-j}\), i.e., over the joint distribution of all explanatory variables other than \(X^j\). Or, in other words, it is the expected value of the CP profile ntoduced in Equation \eqref{eq:CPPdef} for \(X^j\) over the (marginal) distribution of \(X^{-j}\).

Usually, we do not know the true distribution of \(X^{-j}\). We can estimate it, however, by the empirical distribution of \(N\), say, observations available in a training dataset. This leads to the use of the average of CP profiles for \(X^j\) as an estimator of the PD profile:

\begin{equation}
\hat g_{PD}^{f, j}(z) =  \frac{1}{N} \sum_{i=1}^{N} f(x_i^{j|=z}).
\label{eq:PDPest}
\end{equation}

\hypertarget{clusteredPDPs}{%
\subsection{Clustered partial dependence profiles}\label{clusteredPDPs}}

As it has been already mentioned, the average of CP profiles is a good summary if the profiles are parallel. If they are not parallel, the average may not adequately represent the shape of a subset of profiles. To deal with this issue, one can consider clustering the profiles and calculate the average separately for each cluster. To cluster the CP profiles, one may use standard methods like K-means or hierarchical clustering. The similarities between observations can be calculated based on the Euclidean distance between CP profiles.

Figure \ref{fig:pdpPart4} illustrates an application of that approach to the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf}) for 100 randomly selected instances (observations) from the Titanic dataset. The CP profiles for age are marked in grey. It can be noted that they could be split into three clusters based on the \texttt{hclust} method: one for a group of passengers with a substantial drop in the predicted survival probability for ages below 18 (with the average represented by the red line), one with an almost linear decrease of the probability over the age (with the average represented by the green line), and one with almost constant predicted probability (with the average represented by the blue line). The plot itself does not allow to identify the variables that may be linked with these clusters, but additional exploratory analysis could be performed for this purpose.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{ema_files/figure-latex/pdpPart4-1} 

}

\caption{Clustered partial-dependence profiles for the random-forest model for 100 randomly selected observations from the Titanic dataset. Grey lines indicate Ceteris-paribus profiles that are clustered into 3 groups with the average profiles indicated by the blue, green, and red lines.}\label{fig:pdpPart4}
\end{figure}

\hypertarget{groupedPDPs}{%
\subsection{Grouped partial dependence profiles}\label{groupedPDPs}}

It may happen that we can identify an explanatory variable that can influence the shape of CP profiles for the explanatory variable of interest. The most obvious situation is when a model includes an interaction between the variable of interest and another one. In that case, a natural approach is to investigate the PD profiles for the variable of interest corresponding to the groups of observations defined by the variable involved in the interaction.
Figure \ref{fig:pdpPart5} illustrates an application of the approach to the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-titanic-rf}) for 100 randomly selected instances (observations) from the Titanic dataset. The CP profiles for age are marked in grey. The red and blue lines present the PD profiles for females and males, respectively. The latter have different shapes: the predicted survival probability for females is more stable across different ages, as compared to males. Thus, the PD profiles clearly indicate an interaction between age and gender.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{ema_files/figure-latex/pdpPart5-1} 

}

\caption{Partial-dependence profiles for two genders for the random-forest model for 100 randomly selected observations from the Titanic dataset. Grey lines indicate ceteris-paribus profiles for age.}\label{fig:pdpPart5}
\end{figure}

\hypertarget{contrastivePDPs}{%
\subsection{Contrastive partial dependence profiles}\label{contrastivePDPs}}

Comparison of clustered or grouped PD profiles for a single model may provide important insight into, for instance, stability of the model predictions. PD profiles can also be compared between different models.

Figure \ref{fig:pdpPart7} presents PD profiles for age for the random-forest model and the logistic regression model with splines for the Titanic data (see Section \ref{model-titanic-rf}). The profiles are similar with respect to a general relation between age and the predicted probability of survival (the younger the passenger, the better chance of survival). However, the profile for the random-forest model is flatter. The difference between both models is the largest at the edges of the age scale. This pattern can be treated as expected, because random-forest models, in general, shrink predictions towards the average and they are not very good for extrapolation outside the range of values observed in the training dataset.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{ema_files/figure-latex/pdpPart7-1} 

}

\caption{Partial-dependence profiles for age for the random-forest (green line) and logistic-regression (blue line) models for the Titanic dataset.}\label{fig:pdpPart7}
\end{figure}

\hypertarget{PDPExample}{%
\section{Example: Apartments data}\label{PDPExample}}

In this section, we use PD profiles to evaluate performance of the random-forest model \texttt{apartments\_rf\_v5} (see Section \ref{model-Apartments-rf}) for the Apartments dataset (see Section @ref()). Recall that the goal is to predict the price per square-meter of an apartment. In our illustration we focus on two explanatory variables, surface and construction year.

\hypertarget{partial-dependence-profiles}{%
\subsection{Partial dependence profiles}\label{partial-dependence-profiles}}

Figure \ref{fig:pdpApartment1} presents CP profiles (green lines) for 25 randomly-selected apartments together with the estimated PD profile (blue line) for surface and construction year.

PD profile for surface suggest an approximately linear relationship between the explanatory variable and the predicted price. On the other hand, PD profile for construction year is U-shaped: the predicted price is the highest for the very new and very old apartments. While the data were simulated, they were generated to reflect the effect of a lower quality of building materials used in housing construction after the II World War.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{ema_files/figure-latex/pdpApartment1-1} 

}

\caption{Ceteris-paribus and partial-dependence profiles for 100 randomly-selected apartments for the Random forest model for the Apartments dataset.}\label{fig:pdpApartment1}
\end{figure}

\hypertarget{clustered-partial-dependence-profiles}{%
\subsection{Clustered partial dependence profiles}\label{clustered-partial-dependence-profiles}}

All CP profiles for construction year, presented in Figure \ref{fig:pdpApartment1}, seem to be U-shaped. The same shape is observed for the PD profile. One might want to confirm that the shape is, indeed, common for all the observations. The left-hand-side panel of Figure \ref{fig:pdpApartment1clustered} presents clustered PD profiles for construction year for three clusters derived from the CP profiles presented in Figure \ref{fig:pdpApartment1}. The three PD profiles differ slightly in the size of the oscillations at the edges, but they all are U-shaped. Thus, we could conclude that the overall PD profile adequately captures the shape of the CP profiles. Or, put differently, there is little evidence that there might be any strong interaction between construction year and any other variable in the model. Similar conclusions can be drawn for the CP and PD profiles for surface, presented in the right-hand-side panel of Figure \ref{fig:pdpApartment1clustered}.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{ema_files/figure-latex/pdpApartment1clustered-1} 

}

\caption{Ceteris-paribus (grey lines) and partial-dependence profiles (red, green and blue lines) for three clusters for 100 randomly-selected apartments for the random-forest model for the Apartments dataset. Left: profiles for construction year. Right: profiles for surface.}\label{fig:pdpApartment1clustered}
\end{figure}

\hypertarget{grouped-partial-dependence-profiles}{%
\subsection{Grouped partial dependence profiles}\label{grouped-partial-dependence-profiles}}

One of the categorical explanatory variables in the Apartments dataset is district. We may want to investigate whether the relationship between the model predictions and construction year and surface is similar for all districts. Toward this aim, we can use grouped PD profiles, for groups of apartments defined by districts.

Figure \ref{fig:pdpApartment2} shows PD profiles for construction year (left-hand-side panel) and surface (right-hand-side panel) for each district. Several observations are worth making. First, profiles for apartments in `'Srodmiescie'' (Downtown) are clearly much higher than for other districts. Second, the profiles are roughly parallel, indicating that the effects of construction year and surface are similar in each district. Third, the profiles appear to form three clusters, i.e., `'Srodmiescie'' (Downtown), three districts close to `'Srodmiescie'' (namely `'Mokotow'`,'`Ochota'`, and'`Ursynow''), and the six remaining districts.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{ema_files/figure-latex/pdpApartment2-1} 

}

\caption{Partial-dependence profiles for separate districts for the random-forest model for the Apartments dataset. Left: profiles for construction year. Right: profiles for surface.}\label{fig:pdpApartment2}
\end{figure}

\hypertarget{contrastive-partial-dependence-profiles}{%
\subsection{Contrastive partial dependence profiles}\label{contrastive-partial-dependence-profiles}}

One of the main challenges in predictive modelling is to avoid over-fitting. The issue is particularly important for flexible models, such as random-forest models.

Figure \ref{fig:pdpApartment3} presents PD profiles for construction year (left-hand-side panel) and surface (right-hand-side panel) for the linear regression model (see Section @ref()) and the random-forest model. Several observations are worth making. The linear model cannot, of course, accommodate the non-monotonic relationship between the construction year and the price per square-meter. However, for surface, both models support a linear relationship, though the slope of the line resulting from the linear regression is steeper. This may be seen as an expected difference, given that random-forest models yield predictions that are shrunk towards the mean.

Thus, the profiles in Figure \ref{fig:pdpApartment3} suggest that both models miss some aspects of the data. In particular, the linear regression model does not capture the U-shaped relationship between the construction year and the apartment price. On the other hand, the effect of the surface on the apartment price seems to be underestimated by the random-forest model. Hence, one could conclude that, by addressing the issues, one could improve either of the models, possibly with an improvement in predictive performance.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{ema_files/figure-latex/pdpApartment3-1} 

}

\caption{Partial-dependence profiles for the linear regression and random-forest models for the Apartments dataset. Left: profiles for construction year. Right: profiles for surface.}\label{fig:pdpApartment3}
\end{figure}

\hypertarget{PDPProsCons}{%
\section{Pros and cons}\label{PDPProsCons}}

PD profiles, presented in this chapter, offer a simple way to summarize the effect of a particular explanatory variable on the dependent variable. They are easy to explain and intuitive. They can be obtained for sub-groups of observations and compared across different models. For these reasons, they have gained in popularity and have been implemented in various software packages, including R and Python.

Given that the PD profiles are averages of CP profiles, they inherit the limitations of the latter. In particular, as CP profiles are problematic for correlated features, PD profiles are also not suitable for that case. (An approach to deal with this issue will be discussed in the next chapter.) For models including interactions, the averages of CP profiles may offer a crude and potentially misleading summarization.

\hypertarget{PDPR}{%
\section{Code snippets for R}\label{PDPR}}

Here we show partial dependence profiles calculated with \texttt{DALEX} package which wrap functions from \texttt{ingredients} package \citep{ingredientsRPackage}. You will also find similar functions in the \texttt{pdp} package \citep{pdpRPackage}, \texttt{ALEPlots} package \citep{ALEPlotRPackage} or \texttt{iml} \citep{imlRPackage} package.

The easiest way to calculate PD profiles is to use the function \texttt{DALEX::model\_profile}.
The only required argument is the explainer and by default PD profiles are calculated for all variables. The only required argument is the model explainer. By default, PD profiles are calculated for all explanatory variables. In the code below we use the \texttt{variables} argument to limit the list of variables for which PD profiles are calculated. We store the computed PD profile in object \texttt{pdp\_rf}. Subsequently, we apply the \texttt{plot()} function to the object to generate the plot of the PD profile.

For illustration purposes, we use the random-forest model \texttt{titanic\_rf\_v6} (see Section \ref{model-HR-rf}) for the Titanic data. Recall that it is developed to predict the probability of survival from sinking of Titanic.
Below we use \texttt{variables} argument to limit list of variables for which PD profiles are calculated. Here we need profiles only for the \texttt{age} variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdp_rf <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(explain_titanic_rf, }\DataTypeTok{variables =} \StringTok{"age"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(pdp_rf) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Partial dependence profile for age"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/pdpExample1-1} 

}

\caption{Partial dependence profile for age.}\label{fig:pdpExample1}
\end{figure}

PD profiles can be plotted on top of CP profiles. This is a very useful feature if we want to learn how similar are the CP profiles to the average. Toward this aim, we first have got to compute and store the CP profiles with the help of the \texttt{model\_profile()} function. The argument \texttt{N} set the number of randomly-selected instances used for calculation of partial dependence. By default its 100.

The argument \texttt{geom\ =\ "profiles"} in the \texttt{plot()} function results in Partial dependence profile plotted on top of Ceteris paribus profiles. In the example below we only select the profiles for age.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdp_rf <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(explain_titanic_rf, }\DataTypeTok{variables =} \StringTok{"age"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(pdp_rf, }\DataTypeTok{geom =} \StringTok{"profiles"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Ceteris Paribus and Partial dependence profiles for age"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/pdpExample2-1} 

}

\caption{Ceteris-paribus and partial-dependence profiles for age.}\label{fig:pdpExample2}
\end{figure}

\hypertarget{clustered-partial-dependence-profiles-1}{%
\subsection{Clustered partial dependence profiles}\label{clustered-partial-dependence-profiles-1}}

To calculate clustered PD profiles, first we have to calculate and store the CP profiles and the use the \texttt{hclust} clustering to the profiles.
This can be done with the \texttt{model\_profile()} function. The number of clusters is specified with the help of argument \texttt{k}. Additional arguments of the function include \texttt{center} (a logical argument indicating if the profiles should be centered before calculation of distances between them) and \texttt{variables} (a list with the names of the explanatory variables for which the profiles are to be clustered, with the default value \texttt{NULL} indicating all the available variables).

The clustered PD profiles can be plotted on top of the CP profiles by setting the \texttt{geom\ =\ "profiles"} argument to the \texttt{plot()} function. Note that in the R code below we perform the calculations only for a randomly-selected set of 100 observations from the \texttt{titanic} data frame. Also, we only select the plots for the profiles for \texttt{age}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdp_rf <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(explain_titanic_rf, }\DataTypeTok{variables =} \StringTok{"age"}\NormalTok{, }\DataTypeTok{k =} \DecValTok{3}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(pdp_rf, }\DataTypeTok{geom =} \StringTok{"profiles"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Clustered Partial dependence profiles"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/pdpExample3-1} 

}

\caption{Clustered Partial dependence profiles.}\label{fig:pdpExample3}
\end{figure}

\hypertarget{grouped-partial-dependence-profiles-1}{%
\subsection{Grouped partial dependence profiles}\label{grouped-partial-dependence-profiles-1}}

The \texttt{model\_profile()} function admits the \texttt{groups} argument. If the argument is set to the name of a categorical explanatory variable, PD profiles are constructed for the groups of observations defined by the levels of the variable. In the example below, the argument is applied to obtain PD profiles for \texttt{age} grouped by \texttt{gender}. Subsequently, the profiles are plotted on top of the CP profiles for 100 randomly-selected observations from the \texttt{titanic} data frame (stored in object \texttt{pdp\_sex\_rf}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdp_sex_rf <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(explain_titanic_rf, }\DataTypeTok{variables =} \StringTok{"age"}\NormalTok{, }\DataTypeTok{groups =} \StringTok{"gender"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(pdp_sex_rf, }\DataTypeTok{geom =} \StringTok{"profiles"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Grouped Partial dependence profiles"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/pdpExample4-1} 

}

\caption{Grouped Partial dependence profiles.}\label{fig:pdpExample4}
\end{figure}

\hypertarget{contrastive-partial-dependence-profiles-1}{%
\subsection{Contrastive partial dependence profiles}\label{contrastive-partial-dependence-profiles-1}}

To overlay PD profiles for two or more models in a single plot, one can use the generic \texttt{plot()} function. In the code below, we create PD profiles for \texttt{age} for the random-forest (see Section \ref{sec:}) and logistic regression (see Section \ref{sec:}) models, stored in the explainer-objects \texttt{explain\_titanic\_rf} and \texttt{explain\_titanic\_lmr}, respectively. Subsequently, we apply the \texttt{plot()} function to plot the two PD profiles together in a single plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdp_rf <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(explain_titanic_rf, }\DataTypeTok{variables =} \StringTok{"age"}\NormalTok{)}
\NormalTok{pdp_lmr <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(explain_titanic_lmr, }\DataTypeTok{variables =} \StringTok{"age"}\NormalTok{)}

\KeywordTok{plot}\NormalTok{(pdp_rf}\OperatorTok{$}\NormalTok{agr_profiles, pdp_lmr}\OperatorTok{$}\NormalTok{agr_profiles) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Contrastive Partial dependence profiles"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/pdpExample5-1} 

}

\caption{Contrastive Partial dependence profiles.}\label{fig:pdpExample5}
\end{figure}

\hypertarget{accumulatedLocalProfiles}{%
\chapter{Local-dependence and Accumulated Local Profiles}\label{accumulatedLocalProfiles}}

\hypertarget{ALPIntro}{%
\section{Introduction}\label{ALPIntro}}

Partial-dependence (PD) profiles, introduced in the previous chapter, are easy to explain and interpret, especially given their estimation as an average of Ceteris-paribus (CP) profiles. However, as it was mentioned in Section \ref{PDPProsCons}, the profiles may be misleading if the explanatory variables are correlated. In many applications, this is the case. For example, in the Apartments dataset (see Section \ref{ApartmentDataset}), one can expect that variables `'surface'' and `'number of rooms'' may be positively correlated, because apartments with larger number of rooms usually also have a larger surface. Thus, it is not realistic to consider, for instance, an apartment with 5 rooms and 20 square meters. Similarly, in the Titanic dataset, a positive correlation can be expected for the values of variables `'fare'' and `'passenger class'', as tickets in the higher classes are more expensive than in the lower classes.

In this chapter, we present accumulated local (AL) profiles that address this issue. As they are related to local-dependence (LD) profiles, we introduce the latter first. Both approaches were proposed in ,,ALEPlot: Accumulated Local Effects (ALE) Plots and Partial Dependence (PD) Plots'' \citep{ALEPlotRPackage}.

\hypertarget{ALPIntuition}{%
\section{Intuition}\label{ALPIntuition}}

Let us consider the following, simple nonlinear model with for two explanatory variables:

\begin{equation}
f(x_1, x_2) = (x_1 + 1)\cdot x_2.
\label{eq:trickyModel}
\end{equation}

Moreover, assume that explanatory variables \(X^1\) and \(X^2\) are uniformly distributed over the interval \([-1,1]\) and perfectly correlated, i.e., \(X^2 = X^1\). Suppose that we have got the following dataset with 8 observations:

\begin{longtable}[]{@{}lllllllll@{}}
\toprule
i & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\tabularnewline
\midrule
\endhead
\(X^1\) & -1 & -0.71 & -0.43 & -0.14 & 0.14 & 0.43 & 0.71 & 1\tabularnewline
\(X^2\) & -1 & -0.71 & -0.43 & -0.14 & 0.14 & 0.43 & 0.71 & 1\tabularnewline
\(y\) & 0 & -0.2059 & -0.2451 & -0.1204 & 0.1596 & 0.6149 & 1.2141 & 2\tabularnewline
\bottomrule
\end{longtable}

Note that, for both \(X^1\) and \(X^2\), the sum of all observed values is equal to 0.

The top part of Panel A of Figure \ref{fig:accumulatedLocalEffects} shows CP profiles for \(X^1\) for model \eqref{eq:trickyModel} calculated for the eight observations. The bottom part of the panel presents the corresponding estimate of the PD profile for \(X^1\), i.e., the average of the CP profiles. The profile suggests no effect of variable \(X^1\), which is clearly a misleading conclusion.

To understand the reason, let us explicitly express the CP profile for \(X^1\) for model \eqref{eq:trickyModel}:

\begin{equation}
h^{(x_1 + 1) \cdot x_2 , 1}_{x_1,x_2}(z) = f(z,x_2) = (z+1)\cdot x_2.
\label{eq:CPtrickyModel}
\end{equation}

By allowing \(z\) to take any value in the interval \([-1,1]\), we get the CP profiles as straight lines with the slope equal to the value of variable \(X^2\). Hence, for instance, the CP profile for observation \((-1,-1)\) is a straight line with the slope equal to -1.

Recall that the PD profile for \(X^j\), defined in equation \eqref{eq:PDPdef0}, is the expected value, over the joint distribution of all explanatory variables other than \(X^j\), of the model predictions when \(X^j\) is set to \(z\). This leads to the estimation of the profile by taking the average of CP profiles for \(X^j\) (see equation \eqref{eq:PDPest}).

In our case, this implies that the PD profile for \(X^1\) is the expected value of the model predictions over the distribution of \(X^2\), i.e., over the uniform distribution on the interval \([-1,1]\). Thus, the PD profile is estimated by taking the average of the CP profiles (see \eqref{eq:CPtrickyModel}) at each value of \(z\) in \([-1,1]\):

\begin{equation}
\hat g_{PD}^{(x_1 + 1)\cdot x_2, 1}(z) =  \frac{1}{8} \sum_{i=1}^{8} (z+1)\cdot x_{2,i} = \frac{z+1}{8}  \sum_{i=1}^{8} x_{2,i} = 0.
\label{eq:PDtrickyModel}
\end{equation}

As a result, the PD profile for \(X^1\) is estimated as a horizontal line at 0, as seen in the bottom part of Panel A of Figure \ref{fig:accumulatedLocalEffects}.

The calculations in equation \eqref{eq:PDtrickyModel} ignore the fact that, given our assumptions, one cannot change \(z\) \emph{freely} for a particular value of \(X^2\), because \(X^1\) and \(X^2\) are assumed to be perfectly correlated. In fact, in this case, the CP profile for the \(i\)-th observation should actually be undefined for any values of \(z\) different from \(x^2_i\). As a consequence, the sum used in the calculation of the PD profile in equation \eqref{eq:PDtrickyModel} would involve undefined terms for any \(z\).

Thus, the issue is related to the fact of using the marginal distribution of \(X^2\), which disregards the value of \(X^1\), in the definition of the PD profile. This observation suggests a modification: instead of the marginal distribution, one might consider the conditional distribution of \(X^2 | X^1\). The modification leads to the definition of the LD profile.

For in our example, the conditional distribution of \(X^2\), given \(X^1=z\), is just a probability mass of 1 at \(z\). Consequently, the Local-dependence (LD) profile, for any \(z \in [-1,1]\), is given by
\begin{equation}
g_{LD}^{(x_1 + 1)\cdot x_2, 1}(z) =  z \cdot (z+1).
\label{eq:LDtrickyModel}
\end{equation}

It turns out, however, that the modification does not fully address the issue of correlated explanatory variables.

Looking at equation \eqref{eq:trickyModel} one can see that from the perspective of \(X^1\) the effect of the variable \(x_1\) is similar to the function \(f(x_1) = -x_1 -1\) for values close to \((x_1, x_2) = (-1,-1)\) and similar to the function \(f(x_1) = x_1 +1\) for values close to \((x_1, x_2) = (1,1)\). So first it decreases at the same rate as it increases later. The function in equation \eqref{eq:LDtrickyModel} does not show this.

In the \citep{ALEPlotRPackage}, author proposed Accumulated Local Effects (AL) profiles, where the effect of the \(X^1\) variable is defined as the cumulative sum of local derivatives due to the \(X^1\) variable

\begin{equation}
g_{AL}^{(x_1 + 1)\cdot x_2, 1}(z) = 
\int_{-1}^z E \left[\frac{\partial f(x_1, x_2)}{\partial x_1} | X^1 = v \right] dv = 
\int_{-1}^z E \left[X^2 | X^1 = v \right] dv = 
\int_{-1}^z v dv =
(z^2 - 1)/2.
\label{eq:ALtrickyModel}
\end{equation}

This formula better reflects the behavior of function \(f(x_1,x_2)\) due to \(X^1\) removing the effect of changes in variable \(X^2\).

\hypertarget{ALPMethod}{%
\section{Method}\label{ALPMethod}}

\hypertarget{local-dependence-profile}{%
\subsection{Local-dependence profile}\label{local-dependence-profile}}

LD profile for model \(f(x)\) and variable \(X^j\) is defined as follows:

\begin{equation}
g_{LD}^{f, j}(z) = E_{X^{-j}|X^j=z}\left[f\left(X^{j|=z}\right)\right].
\label{eq:LDPdef}
\end{equation}

Thus, it is the expected value of the model predictions over the conditional distribution of \(X^{-j}\) given \(X^j=z\), i.e., over the joint distribution of all explanatory variables other than \(X^j\) conditional on the value of the latter variable set to \(z\). Or, in other words, it is the expected value of the CP profiles in equation \eqref{eq:CPPdef} for \(X^j\) over the conditional distribution of \(X^{-j} | X^j\).

For example, consider \(X=(X^1,X^2)\) with \(X^1\) uniformly distributed over \([-1,1]\) and \(X^2=X^1\). Then the conditional distribution of \(X^{-1} \equiv X^2\), given \(X^1=z\), is the point mass of 1 at \(z\). Consequently, for model \eqref{eq:trickyModel} and variable \(X^1\), we get

\[
g_{LD}^{(x_1+1)\cdot x_2,1}(z) = E_{X^2|X^1=z}[f(z,X^2)] = E_{X^2|X^1=z}[(z+1)\cdot X^2] = (z+1)\cdot E_{X^2|X^1=z}(X^2) = (z+1)\cdot z,
\]
as given in Equation \eqref{eq:LDtrickyModel}.

As proposed in ,,ALEPlot: Accumulated Local Effects Plots and Partial Dependence Plots'' \citep{ALEPlotRPackage}, LD profile can be estimated as follows:

\begin{equation}
\hat g_{LD}^{f,j}(z) = \frac{1}{|N_j|} \sum_{k\in N_j} f\left(x_k^{j| = z}\right), 
\label{eq:LDPest}
\end{equation}

where \(N_j\) is the set of observations with the value of \(X^j\) `'close'' to \(z\) that is used to estimate the conditional distribution of \(X^{-j}|X^j=z\).

Note that, in general, the estimator given in formula \eqref{eq:LDPest} is neither smooth nor continuous at boundaries between subsets \(N_i\). A smooth estimator for \(g_{LD}^{f,j}(z)\) can be defined as follows:

\begin{equation}
\tilde g_{LD}^{f,j}(z) = \frac{1}{\sum_k w_{k}(z)} \sum_{i = 1}^N w_i(z) f(x_i^{j| = z}), 
\label{eq:LDPest2}
\end{equation}

where weights \(w_i(z)\) capture the distance between \(z\) and \(x_i^j\). In particular, for a categorical variable, we may just use the indicator function \(w_i(z) = 1_{z = x^j_i}\), while for a continuous variable we may use the Gaussian kernel:

\begin{equation}
w_i(z) = \phi(z - x_i^j, 0, s),
\label{eq:Gkernel}
\end{equation}

where \(\phi(y,0,s)\) is the density of a normal distribution with mean 0 and standard deviation \(s\). Note that \(s\) plays the role of a smoothing factor.

As argued in ,,Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models'' \citep{ALEPlot2}, if an explanatory variable is correlated with some other variables, the LD profile for the variable will capture the effect of all of the variables. This is because the profile is obtained by marginalizing (in fact, ignoring) over the remaining variables in the model. Thus, in this respect, LD profiles share the same limitation as PD profiles. To address the limitation, AD profiles can be used. We present them in the next section.

\hypertarget{accumulated-local-profile}{%
\subsection{Accumulated local profile}\label{accumulated-local-profile}}

Consider model \(f(x)\) and define

\[
h^j(u)=\left[ \frac{\partial f(x)}{\partial x^j} \right]_{x=u}.
\]
The AL profile for model \(f(x)\) and variable \(X^j\) is defined as follows:

\begin{equation}
g_{AL}^{f, j}(z) = \int_{z_0}^z \left\{E_{X^{-j}|X^j=u}\left[ h^j(X^{j|=u}) \right]\right\} du + c,
\label{eq:ALPdef}
\end{equation}

where \(z_0\) is a value close to the lower bound of the effective support of the distribution of \(X^j\) and \(c\) is a constant, usually selected so that \(E_{X^j}\left[g_{AL}^{f,j}(X^j)\right] = E_X f(x)\).

To interpret equation \eqref{eq:ALPdef} note that \(h^j(u)\) describes the local effect (change) of the model due to \(X^j\). Or, to put it in other words, \(h^j(u)\) describes how much the CP profile for \(X^j\) changes at \(u\). This effect (change) is averaged over the `'relevant'' (according to the conditional distribution of \(X^{-j}|X^j\)) values of \(X^{-j}\) and, subsequently, accumulated (integrated) over values of \(u\) up to \(z\). As argued by \citep{ALEPlot2}, the averaging of the local effects allows avoiding the issue, present in the PD and LD profiles, of capturing the effect of other variables in the profile for a particular variable. To see this, one can consider the approximation

\[
f(u^{j|=u+du})-f(u^{j|=u})  \approx h^j(u)du,
\]
and note that the difference \(f(u^{j|=u+du})-f(u^{j|=u})\), for a model without interaction, effectively removes the effect of all variables other than \(X^j\). For example, consider model \(f(x_1, x_2) = x_1 + x_2\), with \(f_1(x_1,x_2)=1\). Then

\[
f(u+du,x_2)-f(u,x_2)  = (u + du + x_2) - (u + x_2) = du = f_1(u,x_2) du.
\]
As another example, consider model \eqref{eq:trickyModel}. In this case, \(f_1(x_1,x_2)=x_2\) and the effect of variable \(X^2\) will still be present in the AL profile for \(X^1\).

Continuing with model in formula \eqref{eq:trickyModel}, assume that \(X=(X^1,X^2)\) with \(X^1\) uniformly distributed over \([-1,1]\) and \(X^2=X^1\). In this case, the conditional distribution of \(X^2 | X^1=z\) is the point mass of 1 at \(z\). Then

\begin{equation}
g_{AL}^{(x_1+1)\cdot x_2,1}(z) = \int_{-1}^z \left[E_{X^2|X^1=u}\left( X^2 \right)\right] du + c = \int_{-1}^z u du + c = \frac{z^2-1}{2}+c.
\label{eq:ALtrickyModel}
\end{equation}

Since \(E_{X^1}\left[(X^1)^2\right] = 1/3\), then, upon taking \(c=-1/3\), we get \(E_{X^1}\left[g_{AL}^{(x_1+1) \cdot x_2,1}(X^1)\right] = 0\).

To estimate AL profile, one replaces the integral in equation \eqref{eq:ALPdef} by a summation and the derivative with a finite difference \citep{ALEPlotRPackage}. In particular, consider a partition of the range of observed values \(x_{i}^j\) of variable \(X^j\) into \(K\) intervals \(N_j(k)=(z_{k-1}^j,z_k^j]\) (\(k=1,\ldots,K\)). Note that \(z_0^j\) can be chosen just below \(\min(x_1^j,\ldots,x_N^j)\) and \(z_K^j=\max(x_1^j,\ldots,x_N^j)\). Let \(n_j(k)\) denote the number of observations \(x_i^j\) falling into \(N_j(k)\), with \(\sum_{k=1}^K n_j(k)=N\). An estimator of AL profile for variable \(X^j\) can then be constructed as follows:

\begin{equation}
\widehat{g}_{AL}^{f,j}(z) = \sum_{k=1}^{k_j(z)} \frac{1}{n_j(k)} \sum_{i: x_i^j \in N_j(k)} \left[ f(x_i^{j| = z_k^j}) - f(x_i^{j| = z_{k-1}^j}) \right] - \hat{c},
\label{eq:ALPest}
\end{equation}

where \(k_j(z)\) is the index of interval \(N_j(k)\) in which \(z\) falls, i.e., \(z \in N_j[k_j(z)]\), and \(\hat{c}\) is selected so that \(\sum_{i=1}^n \widehat{g}_{AL}^{f,j}(x_i^j)=0\). To interpret formula \eqref{eq:ALPest} note that difference \(f\left(x_i^{j| = z_k^j}\right) - f\left(x_i^{j| = z_{k-1}^j}\right)\) corresponds to the difference of the CP profile for the \(i\)-th observation at the limits of interval \(N_j(k)\). This differences for are then averaged across all observations falling into the interval and accumulated.

Note that, in general, \(\widehat{g}_{AL}^{f,j}(z)\) is not smooth at the boundaries of intervals \(N_j(k)\). A smooth estimate can obtained as follows:

\begin{equation}
\widetilde{g}_{AL}^{f,j}(z) = \sum_{k=1}^K \frac{1}{\sum_{l} w_l(z_k)} \sum_{i=1}^N w_{i}(z_k) \left[f(x_i^{j| = z_k}) - f(x_i^{j| = z_k - \Delta})\right] - c,
\label{eq:ALPest2}
\end{equation}

where points \(z_k\) (\(k=0, \ldots, K\)) form a uniform grid covering the interval \((z_0,z)\) with step \(\Delta = (z-z_0)/K\), and weight \(w_i(z_k)\) captures the distance between point \(z_k\) and observation \(x_i^j\). In particular, we may use similar weights as in case of equation \eqref{eq:LDPest2}.

\hypertarget{summaryFeatureEffects}{%
\subsection{An illustrative example}\label{summaryFeatureEffects}}

Let us consider model \eqref{eq:trickyModel} and explanatory-variable vector \(X=(X^1,X^2)\) with \(X^1\) uniformly distributed over \([-1,1]\) and \(X^2=X^1\). Hence, \(X^2\) is perfectly correlated with \(X^1\). Moreover, consider the eight observations for \(X\) from Section \ref{ALPIntuition}.

The top part of Panel A of Figure \ref{fig:accumulatedLocalEffects} shows CP profiles for \(X^1\) for the eight observations, as computed in formula \eqref{eq:CPtrickyModel}. The bottom part of the panel shows the estimated PD profile obtained by using the average of the CP profiles. As indicated by formula \eqref{eq:PDtrickyModel}, the PD profile is estimated at 0. The estimate is correct, as

\[
g_{PD}^{(x_1+1)\cdot x_2,1}(z) = E_{X^2}[(z+ 1)\cdot X^2] = (z+1)\cdot E_{X^2}(X^2) = 0,
\]
given that \(X^2\) is uniformly-distributed over \([-1,1]\). It is, however, misleading, as there clearly is an effect of \(X^1\).

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{figure/CP_ALL} 

}

\caption{Partial-dependence, local-dependence, and accumulated local profiles. Panel A: Ceteris-paribus profiles (top plot) and the corresponding partial-dependence profile. Panel B: local-dependence profile. Panel C: accumulated local profile.}\label{fig:accumulatedLocalEffects}
\end{figure}

The LD profile for model \eqref{eq:trickyModel}, as computed in \eqref{eq:LDtrickyModel}, is

\[
g_{LD}^{(x_1+1)\cdot x_2,1}(z) =  (z+1)\cdot z.
\]
By using estimator \eqref{eq:LDPest}, with the data split into four intervals each containing two observations, we obtain the estimated LD profile shown at the bottom of Panel B of Figure \ref{fig:accumulatedLocalEffects}.

As shown in \eqref{eq:ALtrickyModel}, the AL profile for model presented in formula \eqref{eq:trickyModel} is up to the constant equal
\[
g_{AL}^{(x_1+1)\cdot x_2,1}(z) =  \frac{z^2-1}{2} + c.
\]

By using estimator \eqref{eq:ALPest}, with the data split into four intervals each containing two observations, we obtain the estimated AL profile shown at the bottom of Panel C of Figure \ref{fig:accumulatedLocalEffects}.

\hypertarget{CDPExample}{%
\section{Example: Apartments data}\label{CDPExample}}

In this section, we use PD, LD, and AL profiles to evaluate performance of the random-forest model \texttt{apartments\_rf\_v5} (see Section \ref{model-Apartments-rf}) for the Apartments dataset (see Section \ref{ApartmentDataset}). Recall that the goal is to predict the price per square-meter of an apartment. In our illustration we focus on two explanatory variables, surface and the number of rooms, as they are correlated (see Figure \ref{fig:appartmentsSurfaceNorooms}).

Figure \ref{fig:featureEffectsApartment} shows the three types of profiles for both variables estimated according to formulas \eqref{eq:PDPest}, \eqref{eq:LDPest2} and \eqref{eq:ALPest2}.

Number of rooms and surface are two correlated variables, moreover both have some effect on the price per square meter. As we see profiles calculated with different methods are different.

The green curve corresponds to the PD profile, which is the ordinary average of CP profiles. The red curve corresponds to the LD profile. It is steeper because the effect of the \texttt{surface} variable is additionally overlapped by the effects of variables correlated with \texttt{surface}, e.g.~number of rooms.
The blue curve corresponds to the AL profile. The estimator for AL profiles eliminates the effect of correlated variables. Since the AL and PD profiles are parallel to each other, it suggests that the model is additive for these two variables. In other words the effect of the \texttt{surface} variable in the model does not depend on the value of other variables.

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{ema_files/figure-latex/featureEffectsApartment-1} 

}

\caption{Partial dependence, local dependence, and accumulated local profiles for the random forest model for the  Apartments dataset.}\label{fig:featureEffectsApartment}
\end{figure}

\hypertarget{ALPProsCons}{%
\section{Pros and cons}\label{ALPProsCons}}

In this chapter we introduced tools for exploration of the relation between model response and model inputs. These tools are useful to summarize how ,,in general'' model responds to the input of interest. All presented approaches are based on Ceteris-paribus profiles introduced in Chapter \ref{ceterisParibus} but they differ in a way how individual profiles are merged into a global model response.

When the variables in the data are independent and there are no interactions in the model, the Ceteris-paribus profiles are parallel and their average, i.e.~Partial Dependence, summarizes them all well.

When there are interactions in the model, the Ceteris-paribus profiles are not parallel. Additionally, if variables in the data are correlated, averaging entire Ceteris-paribus profiles may distort the relationship described by the model.

Comparison of PD, LD and AL profiles allows to identify if there are any interactions in the model and if data are significantly correlated. When there are interactions, it may be helpful to explore these relations with generalization of PD profiles for two or more dependent variables.

\hypertarget{ALPR}{%
\section{Code snippets for R}\label{ALPR}}

In this section, we present key features of R package \texttt{DALEX} which is a wrapper over package \texttt{ingredients} \citep{ingredientsRPackage}. Similar functionalities can be found in package \texttt{ALEPlots} \citep{ALEPlotRPackage} or \texttt{iml} \citep{imlRPackage}.

For illustration purposes, we use the random-forest model \texttt{apartments\_rf\_v5} (see Section \ref{model-Apartments-rf}) for the Apartments dataset (see Section @ref()). Recall that the goal is to predict the price per square-meter of an apartment. In our illustration we focus on two explanatory variables, surface and the number of rooms.

LD profiles are calculated by applying function \texttt{DALEX::variable\_profile} to the model-explainer object. By default, profiles are calculated for all explanatory variables. To limit the calculation to selected variables, one can pass the names of the variables to the \texttt{variables} argument. A plot of the calculated profiles can be obtained by applying the generic \texttt{plot()} function, as shown in the code below. The resulting profiles correspond to those shown in Figure \ref{fig:featureEffectsApartment}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explain_apartments_rf <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(model_apartments_rf, }
                                 \DataTypeTok{data =}\NormalTok{ apartments,}
                                 \DataTypeTok{verbose =} \OtherTok{FALSE}\NormalTok{)}

\NormalTok{pd_rf <-}\StringTok{ }\KeywordTok{variable_profile}\NormalTok{(explain_apartments_rf, }
                           \DataTypeTok{type =} \StringTok{"partial"}\NormalTok{,}
                          \DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"no.rooms"}\NormalTok{, }\StringTok{"surface"}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(pd_rf) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Partial dependence for surface and number of rooms"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/aleExample1-1} 

}

\caption{Partial Dependence profile for surface and number of rooms.}\label{fig:aleExample1}
\end{figure}

LD profiles are calculated by applying function \texttt{DALEX::variable\_profile} with additional argument \texttt{type\ =\ "conditional"}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cd_rf <-}\StringTok{ }\KeywordTok{variable_profile}\NormalTok{(explain_apartments_rf,}
                          \DataTypeTok{type =} \StringTok{"conditional"}\NormalTok{,}
                          \DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"no.rooms"}\NormalTok{, }\StringTok{"surface"}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(cd_rf) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Local dependence for surface and number of rooms"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/aleExample3-1} 

}

\caption{Local dependence profiles for the number of rooms and surface.}\label{fig:aleExample3}
\end{figure}

LD profiles are calculated by applying function \texttt{DALEX::variable\_profile} with additional argument \texttt{type\ =\ "accumulated"}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ac_rf <-}\StringTok{ }\KeywordTok{variable_profile}\NormalTok{(explain_apartments_rf,}
                          \DataTypeTok{type =} \StringTok{"accumulated"}\NormalTok{,}
                          \DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"no.rooms"}\NormalTok{, }\StringTok{"surface"}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(ac_rf) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Accumulated local profiles for surface and number of rooms"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/aleExample2-1} 

}

\caption{Accumulated local profiles for the number of rooms and surface.}\label{fig:aleExample2}
\end{figure}

One can also use the \texttt{plot()} function to juxtapose different types of profiles in a single plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd_rf}\OperatorTok{$}\NormalTok{agr_profiles}\OperatorTok{$}\StringTok{`}\DataTypeTok{_label_}\StringTok{`}\NormalTok{ =}\StringTok{ "Partial Dependence"}
\NormalTok{cd_rf}\OperatorTok{$}\NormalTok{agr_profiles}\OperatorTok{$}\StringTok{`}\DataTypeTok{_label_}\StringTok{`}\NormalTok{ =}\StringTok{ "Local Dependence"}
\NormalTok{ac_rf}\OperatorTok{$}\NormalTok{agr_profiles}\OperatorTok{$}\StringTok{`}\DataTypeTok{_label_}\StringTok{`}\NormalTok{ =}\StringTok{ "Accumulated Local"}
\KeywordTok{plot}\NormalTok{(pd_rf}\OperatorTok{$}\NormalTok{agr_profiles, cd_rf}\OperatorTok{$}\NormalTok{agr_profiles, ac_rf}\OperatorTok{$}\NormalTok{agr_profiles) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ema_files/figure-latex/aleExample5-1} 

}

\caption{Different types of profiles for the number of rooms and surface.}\label{fig:aleExample5}
\end{figure}

\hypertarget{residualDiagnostic}{%
\chapter{Residual Diagnostics}\label{residualDiagnostic}}

\hypertarget{IntroResidualDiagnostic}{%
\section{Introduction}\label{IntroResidualDiagnostic}}

In this chapter, we present methods that are useful for detailed examination of both overall and instance-specific model performance. In particular, we focus on graphical methods that use residuals. The methods may be used for several purposes:

\begin{itemize}
\item
  In the first part of the book, we discussed tools for single-instance examination. Residuals can be used to identify potentially problematic instances. The single-instance explainers can then be used in the problematic cases to understand, for instance, which factors contribute most to the errors in prediction.
\item
  For most models, residuals should express a random behavior with certain properties (like, e.g., being concentrated around 0). If we find any systematic deviations from the expected behavior, they may signal an issue with a model (like, e.g., an omitted explanatory variable or wrong functional form of a variable included in the model).
\item
  In Chapter \ref{modelPerformance} we discussed measures to evaluate the overall performance of a predictive model. Sometimes, however, we may be more interested in cases with the largest errors of prediction, which can be identified with the help of residuals.
\end{itemize}

Residual diagnostics is a classical topic related to statistical modeling. Literature on the topic is vast -- essentially every book on statistical modeling includes some discussion about residuals. Thus, in this chapter, we are not aiming at being exhaustive. Rather, our goal is to present selected concepts that underlie the use of residuals.

\hypertarget{IntuitionResidualDiagnostic}{%
\section{Intuition}\label{IntuitionResidualDiagnostic}}

As we mentioned in Section \ref{notationTraining}, we primarily focus on models describing the expected value of the dependent as a function of explanatory variables. In such case, for a perfect predictive model, the predicted value of the dependent variable should be exactly equal to the actual value of the variable for every observation. Perfect prediction is rarely, if ever, expected. In practice, we want the predictions to be reasonably close to the actual values. This suggests that we can use the difference between the predicted and the actual value of the dependent variable to quantify the quality of predictions obtained from a model. The difference is called a residual.

For a single observation, residual will almost always be different from zero. While a large (absolute) value of a residual may indicate a problem with a prediction for a particular observation, it does not mean that the quality of predictions obtained from a model is unsatisfactory in general. To evaluate the quality, we should investigate the `'behavior'' of residuals for a group of observations. In other words, we should look at the distribution of the values of residuals.

For a `'good'' model, residuals should deviate from zero randomly, i.e., not systematically. Thus, their distribution should be symmetric around zero, implying that their mean (or median) value should be zero. Also, residuals should be close to zero themselves, i.e., they should show low variability.

Usually, to verify these properties, graphical methods are used. For instance, a histogram of can be used to check the symmetry and location of the distribution of the residuals. For linear regression models, a plot of residuals against a continuous covariate can be checked for absence of any patterns that would suggest any systematic error in the predictions obtained for a specific range of the values of the covariate.

Note that a model may imply a concrete distribution for residuals. For instance, in the case of the classical linear regression model, standardized residuals should be normally distributed with mean zero and a constant variance. In such a case, a the distributional assumption can be verified by using a suitable graphical method like, for instance, a quantile-quantile plot. If the assumption is found to be violated, one might want to be careful regarding to predictions obtained from the model.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figure/residuals1234} 

}

\caption{Diagnostic plots for linear models. Consecutive panels present residuals as a function of fitted values, standardized residuals as a function of fitted values, leverage plot and qq-plot.}\label{fig:residuals1234}
\end{figure}

\hypertarget{MethodResidualDiagnostic}{%
\section{Method}\label{MethodResidualDiagnostic}}

As it was already mentioned in Chapter \ref{modelDevelopmentProcess}, for a continuous dependent variable (or a count), residual \(r_i\) for the \(i\)-th observation in a dataset is the difference between the model prediction and the corresponding value of the variable:

\begin{equation}
r_i = y_i - f(x_i).
\label{eq:resid}
\end{equation}

A histogram of the estimated residuals can be used to check the symmetry and location of their distribution. An index plot of residuals, i.e., the plot of residuals against the corresponding observation number, may be used to identify observations with large residuals.

For diagnostic purposes the \emph{standardized residuals} are defined as

\begin{equation}
\tilde{r}_i = \frac{r_i}{\sqrt{\mbox{Var}(r_i)}},
\label{eq:standresid}
\end{equation}

where \(\mbox{Var}(r_i)\) is the variance of the residual \(r_i\).
Of course, in practice, the variance of \(r_i\) is usually unknown. Hence, in Equation \eqref{eq:standresid}, the estimated value of the variance is used. Residuals defined in this way are often called the \emph{Pearson residuals}.

For a gaussian linear model the \(\mbox{Var}(r_i)\) can be estimated from design matrix and the distribution of \(\tilde{r}_i\) is approximately standard normal. In general case, for complicated models, it is hard to estimate the variance \(\mbox{Var}(r_i)\) for a single instance so it is often approximated by a constant.

Definition \eqref{eq:standresid} can also be applied to a binary dependent variable if the model prediction \(f(x_i)\) is the probability observing \(y_i\) and upon coding the two possible values of the variable as 0 and 1. However, in this case, the range of possible values of \(r_i\) is restricted to \((-1,1)\), which limits the usefulness of the residuals. For this reason, more often the Pearson residuals are used. Note that, if the values of the explanatory-variable vectors \(x_i\) lead to different predicted values \(f(x_i)\) for different observations in a dataset, the distribution of the Pearson residuals will not be approximated by the standard normal one. Nevertheless, the index plot may still be useful to detect observations with large residuals. The standard-normal approximation is more likely to apply in the situation when vectors \(x_i\) split data into (a few, perhaps) groups sharing the same predicted value \(f(x_i)\). In that case, one one can consider averaging residuals \(r_i\) per group and standardizing them by \(\sqrt{f(x_i)\{1-f(x_i)/k\}}\), where \(k\) is the number of observations in a particular group.

For categorical data, residuals can only be defined in terms of residuals of the binary variables indicating the category observed for the \(i\)-th observation.

\hypertarget{ExampleResidualDiagnostic}{%
\section{Example: Apartments data}\label{ExampleResidualDiagnostic}}

In this section, we use the linear-regression model \texttt{apartments\_lm\_v5} (Section \ref{model-Apartments-lr}) and the random-forest model \texttt{apartments\_rf\_v5} (Section \ref{model-Apartments-rf}) for the apartment-prices data (Section \ref{ApartmentDataset}). Recall that the dependent variable of interest, the price per square-meter, is continuous. Thus, we can use residuals \(r_i\), as defined in equation \eqref{eq:resid}. It is worth noting that, as it was mentioned in Section \ref{modelPerformanceApartments}, RMSE for both models is very similar. Thus, overall, the two models could be seen as performing similarly.

Figures \ref{fig:plotResidualDensity1} and \ref{fig:plotResidualBoxplot1} summarize the distribution of residuals for both models. In particular, Figure \ref{fig:plotResidualDensity1} presents histogram of residuals, while Figure \ref{fig:plotResidualBoxplot1} shows box-and-whisker plots for the absolute value of the residuals.



\begin{figure}

{\centering \includegraphics{ema_files/figure-latex/plotResidualDensity1-1} 

}

\caption{Histogram of residuals the linear-regression model \texttt{apartments\_lm\_v5} and the random-forest model \texttt{apartments\_rf\_v5} for the \texttt{apartments} data.}\label{fig:plotResidualDensity1}
\end{figure}



\begin{figure}

{\centering \includegraphics{ema_files/figure-latex/plotResidualBoxplot1-1} 

}

\caption{Box-and-whisker plots of the absolute values of the residuals of the linear-regression model \texttt{apartments\_lm\_v5} and the random-forest model \texttt{apartments\_rf\_v5} for the \texttt{apartments} data. The crosses indicate the average value that corresponds to RMSE.}\label{fig:plotResidualBoxplot1}
\end{figure}

Despite the similar value of RMSE, the distribution of residuals for both models is different. In particular, Figure \ref{fig:plotResidualDensity1} indicates that the distribution for the linear-regression model is, in fact, split into two separate, normal-like parts, which may suggest omission of a binary explanatory variable in the model. The two components are located around the values of about -200 and 400. As mentioned in the previous chapters, the reason for this behavior of the residuals is the fact that the model does not capture the non-linear relationship between the price and the year of construction.

As seen from Figure \ref{fig:plotResidualDensity1}, the distribution for the random-forest model is skewed to the right and multimodal. It seems to be centered at a value closer to zero than the distribution for the linear-regression model, but it shows a larger variation. These conclusions are confirmed by the box-and-whisker plots in Figure \ref{fig:plotResidualBoxplot1}.

The two plots suggest that the residuals for the random-forest model are more frequently smaller than the residuals for the linear-regression model. However, a fraction of the random-forest-model residuals are very large and these large residuals result in the RMSE being comparable for the two models.

In the remainder of the section, we focus on the random-forest model.

Figure \ref{fig:plotResidual1} shows a scatterplot of residuals (y-axis) in function of the observed (x-axis) values of the dependent variable. For a perfect predictive model, we would expect the horizontal line at zero. For a `'good'' model, we would like to see a symmetric scatter of points around the horizontal line at zero, indicating random deviations of predictions from the observed values. The plot in Figure \ref{fig:plotResidual1} shows that, for the large observed values of the dependent variable, the residuals are positive, while for small values they are negative. Thus, the plot suggests that the predictions are shifted (biased) towards the average.



\begin{figure}

{\centering \includegraphics{ema_files/figure-latex/plotResidual1-1} 

}

\caption{Residuals and observed values of the dependent variable for the random-forest model \texttt{apartments\_rf\_v5} for the \texttt{apartments} data.}\label{fig:plotResidual1}
\end{figure}

The shift towards the average can also be seen from Figure \ref{fig:plotPrediction1} that shows a scatterplot of the predicted (y-axis) and observed (x-axis) values of the dependent variable. For a perfect predictive model we would expect a diagonal line (marked in red). The plot shows that, for large observed values of the dependent variable, the predictions are smaller than the observed values, with an opposite trend for the small observed values of the dependent variable.



\begin{figure}

{\centering \includegraphics{ema_files/figure-latex/plotPrediction1-1} 

}

\caption{Predicted and observed values of the dependent variable for the random-forest model \texttt{apartments\_rf\_v5} for the \texttt{apartments} data. Red line is the diagonal.}\label{fig:plotPrediction1}
\end{figure}

Figure \ref{fig:plotResidual2} shows an index plot of residuals, i.e., their scatterplot in function of an (arbitrary) id-number of the observation (x-axis). The plot indicates an asymmetric distribution of residuals around zero, as there is an excess of large positive (larger than 500) residuals without a corresponding fraction of negative values. This can be linked to the right-skewed distribution seen in Figures \ref{fig:plotResidualDensity1} and \ref{fig:plotResidualBoxplot1} for the random-forest model.



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(md_rf, }\DataTypeTok{variable =} \StringTok{"ids"}\NormalTok{, }\DataTypeTok{yvariable =} \StringTok{"residuals"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{xlab}\NormalTok{(}\StringTok{"observation id"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{ylab}\NormalTok{(}\StringTok{"residuals"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{ema_files/figure-latex/plotResidual2-1} 

}

\caption{An index plot of residuals for the random-forest model \texttt{apartments\_rf\_v5} for the \texttt{apartments} data.}\label{fig:plotResidual2}
\end{figure}

Figure \ref{fig:plotResidual3} shows a scatterplot of residuals (y-axis) in function of the predicted (x-axis) value of the dependent variable. For a `'good'' model, we would like to see a symmetric scatter of points around the horizontal line at zero. The plot in Figure \ref{fig:plotResidual3}, as the one in Figure \ref{fig:plotResidual1}, the plot suggests that the predictions are shifted (biased) towards the average.



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(md_rf, }\DataTypeTok{variable =} \StringTok{"y_hat"}\NormalTok{, }\DataTypeTok{yvariable =} \StringTok{"residuals"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{xlab}\NormalTok{(}\StringTok{"predicted price"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{ema_files/figure-latex/plotResidual3-1} 

}

\caption{Residuals and predicted values of the dependent variable for the random-forest model \texttt{apartments\_rf\_v5} for the \texttt{apartments} data.}\label{fig:plotResidual3}
\end{figure}



The random-forest model, as the linear-regression model, assumes that residuals should be homoscedastic, i.e., that they should have a constant variance. Figure \ref{fig:plotScaleLocation1} presents the scale-location plot of residuals, i.e., a scatterplot of the absolute value of residuals in function of the predicted values of the dependent variable. The plot includes a smoothed line capturing the average trend. For homoscedastic residuals, we would expect a symmetric scatter around a horizontal line, for which the smoothed trend should be also horizontal. The plot in Figure \ref{fig:plotScaleLocation1} deviates from the expected pattern and indicates that the variability of the residuals depends on the (predicted) value of the dependent variable.



\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(md_rf, }\DataTypeTok{variable =} \StringTok{"y_hat"}\NormalTok{, }\DataTypeTok{yvariable =} \StringTok{"abs_residuals"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{xlab}\NormalTok{(}\StringTok{"predicted price"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{ylab}\NormalTok{(}\StringTok{"|residuals|"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{ema_files/figure-latex/plotScaleLocation1-1} 

}

\caption{The scale-location plot of residuals for the random-forest model \texttt{apartments\_rf\_v5} for the \texttt{apartments} data. The square-roots of the absolute values of standardized residuals (y-axis) are plotted in function of the predicted values of the dependent variable (x-axis).}\label{fig:plotScaleLocation1}
\end{figure}

\hypertarget{ProsConsResidualDiagnostic}{%
\section{Pros and cons}\label{ProsConsResidualDiagnostic}}

Diagnostics of the residuals is a very important stage of model exploration.
Properly performed diagnostics allows to identify many different types of problems such as:

\begin{itemize}
\tightlist
\item
  Bias in predictions for instances with extremely high values of the target variable.
\item
  The heterogeneous variance of the residuals, suggesting perhaps incorrect specification of the model.
\item
  High values of residual for some ranges of a variable suggesting an incorrect model specification for some subgroup of observations.
\end{itemize}

However, the problem with diagnostics is that there is lots of diagnostic charts to review. And without quantitative measures of meeting assumption, we can only rely on the organoleptic review of the graph after the graph.

\hypertarget{RcodeResidualDiagnostic}{%
\section{Code snippets for R}\label{RcodeResidualDiagnostic}}

In this section, we present the key features of the \texttt{DALEX} package which is a wrapper for functions from \texttt{auditor} package \citep{R-auditor}. This package covers all methods presented in this chapter.

First, we load explainers for the linear-regression model \texttt{apartments\_lm\_v5} and the random-forest model \texttt{apartments\_rf\_v5} created in Section \ref{ExplainersApartmentsRCode} for the \texttt{apartments} data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{"randomForest"}\NormalTok{)}

\NormalTok{explainer_apartments_lr <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\StringTok{ }\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/f49ea"}\NormalTok{)}
\NormalTok{explainer_apartments_rf <-}\StringTok{ }\NormalTok{archivist}\OperatorTok{::}\StringTok{ }\KeywordTok{aread}\NormalTok{(}\StringTok{"pbiecek/models/569b0"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

There are two functions that will be used for exploration of residuals.
The \texttt{DALEX::model\_performance()} function is useful for exploration of distribution of residuals while \texttt{DALEX::model\_diagnostics()} function is useful for looking for relation between residuals and other variables.

Let's start with distributions of residuals. This can be done with the \texttt{model\_performance()} function. The residuals are stored in separate objects that can be used for construction of various plots and summaries.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mr_lr <-}\StringTok{ }\NormalTok{DALEX}\OperatorTok{::}\KeywordTok{model_performance}\NormalTok{(explainer_apartments_lr)}
\NormalTok{mr_rf <-}\StringTok{ }\NormalTok{DALEX}\OperatorTok{::}\KeywordTok{model_performance}\NormalTok{(explainer_apartments_rf)}
\end{Highlighting}
\end{Shaded}

The generic \texttt{plot()} function shows different statistics based on specified \texttt{geom} argument. In particular, Figure \ref{fig:plotResidualDensity1} can be constructed by using the following simple code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(mr_lr, mr_rf, }\DataTypeTok{geom =} \StringTok{"histogram"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

Note that, by including the two objects containing residuals for the linear-regression model and the random-forest model in the function call, we automatically get an overlay of the plots of the histogram of residuals for the two models.

The box-and-whisker plots of the residuals for the two models, shown in Figure \ref{fig:plotResidualBoxplot1}, can be constructed by using the following simple call with \texttt{geom\ =\ "boxplot"}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(mr_lr, mr_rf, }\DataTypeTok{geom =} \StringTok{"boxplot"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Function \texttt{model\_diagnostics()} calculates residuals for various scatter plots of residuals against some other variables

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{md_lr <-}\StringTok{ }\KeywordTok{model_diagnostics}\NormalTok{(explainer_apartments_lr)}
\NormalTok{md_rf <-}\StringTok{ }\KeywordTok{model_diagnostics}\NormalTok{(explainer_apartments_rf)}
\end{Highlighting}
\end{Shaded}

The generic \texttt{plot()} function produces a scatterplot of residuals (y-axis) in function of the observed (x-axis) values of the dependent variable, as in Figure \ref{fig:plotResidual1}. By using arguments \texttt{variable} and \texttt{yvariable}, one specify which variables will be plotted on OX and OY axis. Apart of variables names, one can use following constants:

\begin{itemize}
\tightlist
\item
  \texttt{y} for true target values,
\item
  \texttt{y\_hat} for predicted target values,
\item
  \texttt{obs} for ids of an observation,
\item
  \texttt{residuals} for calculated residual,
\item
  \texttt{abs\_residuals} for absolute values of residual.
\end{itemize}

For example, to reproduce Figure \ref{fig:plotResidual1} one needs to plot target variable on the OX axis and residuals on OY.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(md_rf, }\DataTypeTok{variable =} \StringTok{"y"}\NormalTok{, }\DataTypeTok{yvariable =} \StringTok{"residuals"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

To produce Figure \ref{fig:plotPrediction1} we need to plot predicted target values on OY axis. This can be done with \texttt{yvariable\ =\ "y\_hat"} argument.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(md_rf, }\DataTypeTok{variable =} \StringTok{"y"}\NormalTok{, }\DataTypeTok{yvariable =} \StringTok{"y_hat"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

The Figure \ref{fig:plotResidual2} has indexes of observations on OX axis. This can be achieved with \texttt{variable\ =\ "ids"} argument.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(md_rf, }\DataTypeTok{variable =} \StringTok{"ids"}\NormalTok{, }\DataTypeTok{yvariable =} \StringTok{"residuals"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In the Figure \ref{fig:plotScaleLocation1} on OY scale we plotted absolute residuals. This can be done with \texttt{yvariable\ =\ "abs\_residuals"} argument.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(md_rf, }\DataTypeTok{variable =} \StringTok{"y_hat"}\NormalTok{, }\DataTypeTok{yvariable =} \StringTok{"abs_residuals"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{use-cases}{%
\chapter*{Use Cases}\label{use-cases}}
\addcontentsline{toc}{chapter}{Use Cases}

\hypertarget{UseCaseFIFA}{%
\chapter{FIFA 19}\label{UseCaseFIFA}}

In previous chapters we introduced a number of methods for instance level exploration of predictive models. In consecutive chapter we showed how to use Ceteris Paribus profiles, SHAP values, LIME or Break Down plots for models created on the dataset \texttt{titanic}. These examples we introduced and discussed separately as each of them was focused on a single method described in a given chapter.

In this chapter we present an example of full process for model development along the process introduces in Chapter \ref{modelDevelopmentProcess}. We will use a new dataset for FIFA 19 soccer game. Based on it we will tour through the process of data preparation, model assembly and model understanding. In each phase we show how to combine results from different methods of exploration.

The main goal of this chapter is to show how different techniques complement each other. Some phases, like data preparation, are simplified in order to leave space for the method for visual exploration and explanation of predictive models.

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

The story is following. The \texttt{https://sofifa.com/} portal is a reliable website for FIFA ratings of football players. Data from this website was scrapped and make available at the Kaggle webpage \texttt{https://www.kaggle.com/karangadiya/fifa19}.

We will use this data to build a predictive model for assessment of player value. Once the model will be created we will use methods for exploration and explanation to better understand how it is working and also to better understand which factors and how influence the player value.

\hypertarget{data-preparation}{%
\section{Data preparation}\label{data-preparation}}

The scraped data contains 89 columns, and various information about players along with photo, club, nationality and others.
Here we will focus on 40 players statistics and the way how they influence model predictions.

The data set contains statistics for 16924 players. First, let's see distribution of selected variables from this dataset.

Players values are heavily skewed. Half of players have estimated value between 0.3 and 2.2 millions of Euro. But few players have estimated values higher than 100 millions of Euro. Figure \ref{fig:distFIFA19Value} presents empirical cumulative distribution function and histogram with log transformation of the OX axis.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/distFIFA19Value-1} 

}

\caption{Empirical cumulative distribution function and histogram for values of players. The OX axis is in the log10 transformation.}\label{fig:distFIFA19Value}
\end{figure}

Due to a large number of player characteristics we are not going to explore all of them but rather we will focus on four that will be discussed later in this chapter, namely: \texttt{Age}, \texttt{Reactions}, \texttt{BallControl} and \texttt{ShortPassing.}

Figure \ref{fig:distFIFA19histograms} presents distributions for these variables. For \texttt{Age} we see that most players are between 20 and 30 years old. What is interesting in \texttt{BallControl} and \texttt{ShortPassing} is that they have bimodal distribution. The reason for that is that these characteristics are very low for goalkeepers but higher for other players. The variable \texttt{Reactions} has Gaussian shaped distribution with average 62 and standard deviation 9.



\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/distFIFA19histograms-1} 

}

\caption{Histograms for selected characteristics of players. Note that \texttt{BallControl} and \texttt{ShortPassing} have bimodal distributions.}\label{fig:distFIFA19histograms}
\end{figure}

\hypertarget{data-understanding}{%
\section{Data understanding}\label{data-understanding}}

Time to see how these variables are linked with player's value.
Figure \ref{fig:distFIFA19scatter} shows scatterplots for selected four characteristics. Because of the skewness of player's value the OY value is presented after log transformation.

For \texttt{Age} it looks like the relation is not monotonic, there is some optimal age in which players value is the highest, between 24 and 28 years. Value of youngest players are on average 10x lower. Same with olders players.

For variables \texttt{BallControl} and \texttt{ShortPassing} the relation is not monotonic. In general the larger value of these coefficients the higher value of a player and most expensive are players with top characteristics. But among players with very low scores in \texttt{BallControl} and \texttt{ShortPassing} some are very expensive too. As it was suggested earlier, these players are probably goalkeepers.

For variable \texttt{Reactions} the link with player's value is monotonic. As expected, the higher \texttt{Reactions} the higher player's value.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/distFIFA19scatter-1} 

}

\caption{Scatterplot for relation between selected four players characteristics and values of players.}\label{fig:distFIFA19scatter}
\end{figure}

Figure \ref{fig:distFIFA19scatter2} shows pairwise scatterplots for dependent variables. Three observations are clear from these scatterplots. One is that \texttt{Age} has positive correlation with other variables. On average older players have higher skills. Second is that skills are positively correlated, the correlation between \texttt{BallControl} and \texttt{ShortPassing} is higher than 0.9. Third is that goalkeepers' characteristics are different than rest of players.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/distFIFA19scatter2-1} 

}

\caption{Scatterplot for relation between selected four players characteristics and values of players.}\label{fig:distFIFA19scatter2}
\end{figure}

Let's compare results from this data exploration with exploration of predictive models that will be fitted on this data.

\hypertarget{model-assembly}{%
\section{Model assembly}\label{model-assembly}}

Time to build a predictive model for players' value based on selected characteristics. We will use a trained elastic model to explore the relation between players' characteristics and players' values.

Having clean data then model assembly is easy. For FIFA 19 data we will try four models with different structures that are able to catch different types of relations. One model would be enough, but we will try four different models to see if they catch similar relations.

Considered models are:

\begin{itemize}
\tightlist
\item
  boosting model with 250 trees 1 level depth as implemented in package \texttt{gbm} \citep{gbm},
\item
  boosting model with 250 trees 4 levels depth, this model shall be able to catch interactions between features,
\item
  linear model with spline transformation of dependent variables implemented in package \texttt{rms} \citep{rms},
\item
  random forest model with 250 trees as implemented in package \texttt{ranger} \citep{rangerRpackage}.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"gbm"}\NormalTok{)}
\NormalTok{fifa_gbm_shallow <-}\StringTok{ }\KeywordTok{gbm}\NormalTok{(LogValue}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ fifa19small, }\DataTypeTok{n.trees =} \DecValTok{250}\NormalTok{,}
        \DataTypeTok{interaction.depth =} \DecValTok{1}\NormalTok{, }\DataTypeTok{distribution =} \StringTok{"gaussian"}\NormalTok{)}

\NormalTok{fifa_gbm_deep <-}\StringTok{ }\KeywordTok{gbm}\NormalTok{(LogValue}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ fifa19small, }\DataTypeTok{n.trees =} \DecValTok{250}\NormalTok{,}
        \DataTypeTok{interaction.depth =} \DecValTok{4}\NormalTok{, }\DataTypeTok{distribution =} \StringTok{"gaussian"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(}\StringTok{"ranger"}\NormalTok{)}
\NormalTok{fifa_rf <-}\StringTok{ }\KeywordTok{ranger}\NormalTok{(LogValue}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ fifa19small, }\DataTypeTok{num.trees =} \DecValTok{250}\NormalTok{)}

\KeywordTok{library}\NormalTok{(}\StringTok{"rms"}\NormalTok{)}
\NormalTok{fifa_ols <-}\StringTok{ }\KeywordTok{ols}\NormalTok{(LogValue }\OperatorTok{~}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Age) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(International.Reputation) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(Skill.Moves) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Crossing) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Finishing) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(HeadingAccuracy) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(ShortPassing) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Volleys) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(Dribbling) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Curve) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(FKAccuracy) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(LongPassing) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(BallControl) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Acceleration) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(SprintSpeed) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Agility) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Reactions) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(Balance) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(ShotPower) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Jumping) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Stamina) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(Strength) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(LongShots) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Aggression) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(Interceptions) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Positioning) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Vision) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(Penalties) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Composure) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(Marking) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(StandingTackle) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(SlidingTackle) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(GKDiving) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(GKHandling) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(GKKicking) }\OperatorTok{+}\StringTok{ }\KeywordTok{rcs}\NormalTok{(GKPositioning) }\OperatorTok{+}
\StringTok{        }\KeywordTok{rcs}\NormalTok{(GKReflexes), }\DataTypeTok{data =}\NormalTok{ fifa19small)}
\end{Highlighting}
\end{Shaded}

Before we can explore model behavior we need to create explainers with the \texttt{DALEX::explain} function. These explainers will be later used to assess model performance.

Note that models are trained on logarithm of the value, but it will be much more natural to operate on values in Euro. This is why in explainers we specified a user defined predict function that transforms log value to the value in Euro.

Each explainer got also a unique \texttt{label} and corresponding \texttt{data} and \texttt{y} arguments.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{fifa_gbm_exp_deep <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(fifa_gbm_deep, }
        \DataTypeTok{data =}\NormalTok{ fifa19small, }\DataTypeTok{y =} \DecValTok{10}\OperatorTok{^}\NormalTok{fifa19small}\OperatorTok{$}\NormalTok{LogValue, }
        \DataTypeTok{predict_function =} \ControlFlowTok{function}\NormalTok{(m,x) }\DecValTok{10}\OperatorTok{^}\KeywordTok{predict}\NormalTok{(m, x, }\DataTypeTok{n.trees =} \DecValTok{250}\NormalTok{),}
        \DataTypeTok{label =} \StringTok{"GBM deep"}\NormalTok{)}

\NormalTok{fifa_gbm_exp_shallow <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(fifa_gbm_shallow, }
        \DataTypeTok{data =}\NormalTok{ fifa19small, }\DataTypeTok{y =} \DecValTok{10}\OperatorTok{^}\NormalTok{fifa19small}\OperatorTok{$}\NormalTok{LogValue, }
        \DataTypeTok{predict_function =} \ControlFlowTok{function}\NormalTok{(m,x) }\DecValTok{10}\OperatorTok{^}\KeywordTok{predict}\NormalTok{(m, x, }\DataTypeTok{n.trees =} \DecValTok{250}\NormalTok{),}
        \DataTypeTok{label =} \StringTok{"GBM shallow"}\NormalTok{)}

\NormalTok{fifa_rf_exp <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(fifa_rf, }
        \DataTypeTok{data =}\NormalTok{ fifa19small, }\DataTypeTok{y =} \DecValTok{10}\OperatorTok{^}\NormalTok{fifa19small}\OperatorTok{$}\NormalTok{LogValue, }
        \DataTypeTok{predict_function =} \ControlFlowTok{function}\NormalTok{(m,x) }\DecValTok{10}\OperatorTok{^}\KeywordTok{predict}\NormalTok{(m, x)}\OperatorTok{$}\NormalTok{predictions,}
        \DataTypeTok{label =} \StringTok{"RF"}\NormalTok{)}

\NormalTok{fifa_rms_exp <-}\StringTok{ }\KeywordTok{explain}\NormalTok{(fifa_ols, }
        \DataTypeTok{data =}\NormalTok{ fifa19small, }\DataTypeTok{y =} \DecValTok{10}\OperatorTok{^}\NormalTok{fifa19small}\OperatorTok{$}\NormalTok{LogValue, }
        \DataTypeTok{predict_function =} \ControlFlowTok{function}\NormalTok{(m,x) }\DecValTok{10}\OperatorTok{^}\KeywordTok{predict}\NormalTok{(m, x),}
        \DataTypeTok{label =} \StringTok{"RMS"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-audit}{%
\section{Model audit}\label{model-audit}}

We have created four models. Let's see which model is better. Figure \ref{fig:modelPerforamanceBoxplot} compares distributions of absolute model residuals. Crosses corresponds to average, which correspond to RMSE. On average, smallest residuals are for the Random Forest model.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"DALEX"}\NormalTok{)}
\NormalTok{(fifa_mr_gbm_shallow <-}\StringTok{ }\KeywordTok{model_performance}\NormalTok{(fifa_gbm_exp_shallow))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Measures for:  regression
## mse      : 8.793857e+12 
## rmse     : 2965444 
## r2       : 0.7359532 
## mad      : 184494.3
## 
## Residuals:
##            0%           10%           20%           30%           40% 
## -36235118.885   -551904.801   -190134.326    -91880.898    -41545.399 
##           50%           60%           70%           80%           90% 
##      7545.811     78107.824    179592.760    385908.869   1242757.255 
##          100% 
##  84138902.525
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(fifa_mr_gbm_deep <-}\StringTok{ }\KeywordTok{model_performance}\NormalTok{(fifa_gbm_exp_deep))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Measures for:  regression
## mse      : 2.258819e+12 
## rmse     : 1502937 
## r2       : 0.9321761 
## mad      : 118742.1
## 
## Residuals:
##           0%          10%          20%          30%          40% 
## -19116967.31   -436856.06   -148437.56    -57458.30    -18811.11 
##          50%          60%          70%          80%          90% 
##     10420.76     46392.59    100655.11    217644.71    714571.14 
##         100% 
##  41410615.28
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(fifa_mr_gbm_rf <-}\StringTok{ }\KeywordTok{model_performance}\NormalTok{(fifa_rf_exp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Measures for:  regression
## mse      : 1.127823e+12 
## rmse     : 1061990 
## r2       : 0.9661357 
## mad      : 51320.23
## 
## Residuals:
##           0%          10%          20%          30%          40% 
## -4610822.779   -97148.598   -41372.043   -20398.749    -6968.849 
##          50%          60%          70%          80%          90% 
##     5584.176    25714.410    65998.232   181294.901   589440.628 
##         100% 
## 29046254.806
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(fifa_mr_gbm_rms <-}\StringTok{ }\KeywordTok{model_performance}\NormalTok{(fifa_rms_exp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Measures for:  regression
## mse      : 2.191297e+13 
## rmse     : 4681129 
## r2       : 0.342035 
## mad      : 148187.1
## 
## Residuals:
##            0%           10%           20%           30%           40% 
## -2.722515e+08 -4.983836e+05 -1.746193e+05 -7.411303e+04 -2.777345e+04 
##           50%           60%           70%           80%           90% 
##  7.872114e+03  5.199682e+04  1.301219e+05  3.007244e+05  1.071466e+06 
##          100% 
##  6.091332e+07
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(fifa_mr_gbm_shallow, fifa_mr_gbm_deep, fifa_mr_gbm_rf, fifa_mr_gbm_rms, }\DataTypeTok{geom =} \StringTok{"boxplot"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\StringTok{"Absolute residuals in Euro"}\NormalTok{, }\DataTypeTok{trans =} \StringTok{"log10"}\NormalTok{, }\DataTypeTok{labels =} \KeywordTok{dollar_format}\NormalTok{(}\DataTypeTok{suffix =} \StringTok{"€"}\NormalTok{, }\DataTypeTok{prefix =} \StringTok{""}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Distributions of model absolute residuals"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/modelPerforamanceBoxplot-1} 

}

\caption{Distribution of absolute values of residuals. The smaller are values the better is the model. Dots stand for averages.}\label{fig:modelPerforamanceBoxplot}
\end{figure}

But performance is not everything. Figure \ref{fig:modelPerformanceScatterplot} show diagnostics plots for every model. Each scatterplot shows true target variable against model predictions. The random forest model has predictions closest to the true target values.

Extreme predictions (lowest and highest) are biased towards the mean, what is typical for such type of models. This means that Random Forest models learned factors that influence players' values, but for the most expensive players these values will be underestimated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fifa_md_gbm_shallow <-}\StringTok{ }\KeywordTok{model_diagnostics}\NormalTok{(fifa_gbm_exp_shallow)}
\NormalTok{fifa_md_gbm_deep <-}\StringTok{ }\KeywordTok{model_diagnostics}\NormalTok{(fifa_gbm_exp_deep)}
\NormalTok{fifa_md_gbm_rf <-}\StringTok{ }\KeywordTok{model_diagnostics}\NormalTok{(fifa_rf_exp)}
\NormalTok{fifa_md_gbm_rms <-}\StringTok{ }\KeywordTok{model_diagnostics}\NormalTok{(fifa_rms_exp)}

\KeywordTok{plot}\NormalTok{(fifa_md_gbm_shallow, fifa_md_gbm_deep, }
\NormalTok{                fifa_md_gbm_rf, fifa_md_gbm_rms, }
     \DataTypeTok{variable =} \StringTok{"y"}\NormalTok{, }\DataTypeTok{yvariable =} \StringTok{"y_hat"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\StringTok{"Value in Euro"}\NormalTok{, }\DataTypeTok{trans =} \StringTok{"log10"}\NormalTok{, }\DataTypeTok{labels =} \KeywordTok{dollar_format}\NormalTok{(}\DataTypeTok{suffix =} \StringTok{"€"}\NormalTok{, }\DataTypeTok{prefix =} \StringTok{""}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\StringTok{"Estimated value in Euro"}\NormalTok{, }\DataTypeTok{trans =} \StringTok{"log10"}\NormalTok{, }\DataTypeTok{labels =} \KeywordTok{dollar_format}\NormalTok{(}\DataTypeTok{suffix =} \StringTok{"€"}\NormalTok{, }\DataTypeTok{prefix =} \StringTok{""}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{label) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_abline}\NormalTok{(}\DataTypeTok{slope =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Diagnostics plot Predicted vs True target values"}\NormalTok{, }\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/modelPerformanceScatterplot-1} 

}

\caption{Diagnostics plots Predicted vs. True target values. Points correspond to particular players. The closer to the diagonal the better is the model.}\label{fig:modelPerformanceScatterplot}
\end{figure}

\hypertarget{model-understanding-1}{%
\section{Model understanding}\label{model-understanding-1}}

Figure \ref{fig:featureImportance} shows variable importance plots for four selected models. Only 12 most important variables in each model are presented.

Some variables are important for all models, like \texttt{Reactions} or \texttt{BallControl}. Importance of other variables may be very different. All models except random forest are using some characteristics of goalkeepers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fifa_mp_gbm_shallow <-}\StringTok{ }\KeywordTok{model_parts}\NormalTok{(fifa_gbm_exp_shallow)}
\NormalTok{fifa_mp_gbm_deep <-}\StringTok{ }\KeywordTok{model_parts}\NormalTok{(fifa_gbm_exp_deep)}
\NormalTok{fifa_mp_rf <-}\StringTok{ }\KeywordTok{model_parts}\NormalTok{(fifa_rf_exp)}
\NormalTok{fifa_mp_rms <-}\StringTok{ }\KeywordTok{model_parts}\NormalTok{(fifa_rms_exp)}

\KeywordTok{plot}\NormalTok{(fifa_mp_gbm_shallow, fifa_mp_gbm_deep, }
\NormalTok{     fifa_mp_rf, fifa_mp_rms,}
     \DataTypeTok{max_vars =} \DecValTok{20}\NormalTok{, }\DataTypeTok{bar_width =} \DecValTok{4}\NormalTok{, }\DataTypeTok{show_boxplots =} \OtherTok{FALSE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/featureImportance-1} 

}

\caption{Variable importance plots for four considered models. Each bar starts in a RMSE for the model and ends in a RMSE calculated for data with permuted single variable.}\label{fig:featureImportance}
\end{figure}

Figure \ref{fig:usecaseFIFApdp} shows Partial Dependence profiles for the most important variables. They show average relation between particular variable and players value.

The general direction of relation in all models is the same. The larger the player characteristic the higher is the price. With a single exception -- variable Age.

Random forest model has smallest range of average model responses. All tree-based models stabilize average predictions at the ends of variables ranges.

The most interesting difference between Exploratory Data Analysis presented in Figure \ref{fig:distFIFA19scatter} and Exploratory Model Analysis presented in Figure \ref{fig:usecaseFIFApdp} is related with variable \texttt{Age}. In Figure \ref{fig:distFIFA19scatter} the relation was non-monotonic while in Figure \ref{fig:usecaseFIFApdp} its monotonically decreasing.
How we can explain this difference?
One explanation is following: Youngest players have lower values not because of their age but because of lower skills that are correlated with Age. The EDA analysis cannot entangle these effects, thus for youngest players we see lover values also because their lower skills. But models learned that once we take skills into account, the effect of age is only decreasing.

This example also shows, that proper \emph{exploration of models may be more insightful than exploration of raw data}. Variable \texttt{Age} is correlated with other confounding variables. This entangle was visible in the EDA analysis. But models learned to disentangle these effects.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{selected_variables <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Age"}\NormalTok{, }\StringTok{"Reactions"}\NormalTok{,}\StringTok{"BallControl"}\NormalTok{, }\StringTok{"ShortPassing"}\NormalTok{)}

\NormalTok{fifa19_pd_shallow <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(fifa_gbm_exp_shallow, }\DataTypeTok{variables =}\NormalTok{ selected_variables)}\OperatorTok{$}\NormalTok{agr_profiles}
\NormalTok{fifa19_pd_deep <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(fifa_gbm_exp_deep, }\DataTypeTok{variables =}\NormalTok{ selected_variables)}\OperatorTok{$}\NormalTok{agr_profiles}
\NormalTok{fifa19_pd_rf <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(fifa_rf_exp, }\DataTypeTok{variables =}\NormalTok{ selected_variables)}\OperatorTok{$}\NormalTok{agr_profiles}
\NormalTok{fifa19_pd_rms <-}\StringTok{ }\KeywordTok{model_profile}\NormalTok{(fifa_rms_exp, }\DataTypeTok{variables =}\NormalTok{ selected_variables)}\OperatorTok{$}\NormalTok{agr_profiles}

\KeywordTok{plot}\NormalTok{(fifa19_pd_shallow, fifa19_pd_deep, fifa19_pd_rf, fifa19_pd_rms) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\StringTok{"Estimated value in Euro"}\NormalTok{, }\DataTypeTok{trans =} \StringTok{"log10"}\NormalTok{, }\DataTypeTok{labels =} \KeywordTok{dollar_format}\NormalTok{(}\DataTypeTok{suffix =} \StringTok{"€"}\NormalTok{, }\DataTypeTok{prefix =} \StringTok{""}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Partial Dependence profiles for selected variables"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/usecaseFIFApdp-1} 

}

\caption{Partial Dependence profiles for four selected variables and four considered models.}\label{fig:usecaseFIFApdp}
\end{figure}

\hypertarget{instance-understanding}{%
\section{Instance understanding}\label{instance-understanding}}

Time to see how the model behaves for a single observation / player
This can be done for any player, but for this example we will use \emph{Robert Lewandowski}, the most valuable polish football player.

Here are his characteristics in the FIFA 19 database.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fifa19small[}\StringTok{"R. Lewandowski"}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                Age Special Preferred.Foot International.Reputation
## R. Lewandowski  29    2152          Right                        4
##                Weak.Foot Skill.Moves Crossing Finishing HeadingAccuracy
## R. Lewandowski         4           4       62        91              85
##                ShortPassing Volleys Dribbling Curve FKAccuracy LongPassing
## R. Lewandowski           83      89        85    77         86          65
##                BallControl Acceleration SprintSpeed Agility Reactions
## R. Lewandowski          89           77          78      78        90
##                Balance ShotPower Jumping Stamina Strength LongShots
## R. Lewandowski      78        88      84      78       84        84
##                Aggression Interceptions Positioning Vision Penalties
## R. Lewandowski         80            39          91     77        88
##                Composure Marking StandingTackle SlidingTackle GKDiving
## R. Lewandowski        86      34             42            19       15
##                GKHandling GKKicking GKPositioning GKReflexes LogValue
## R. Lewandowski          6        12             8         10 7.886491
\end{verbatim}

In the chapter \ref{breakDown} we showed a Break Down plots for presentation of variable attributions. In the Figure \ref{fig:usecaseFIFAbreakDown} we show Break Down plots for Robert Lewandowski predictions.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/usecaseFIFAbreakDown-1} 

}

\caption{Break down plot for Robert Lewandowski. Results for GBM and RF model.}\label{fig:usecaseFIFAbreakDown}
\end{figure}

In the chapter \ref{shapley} we showed a SHAP values for presentation of variable attributions. In the Figure \ref{fig:usecaseFIFAshap} we show SHAP plots for Robert Lewandowski predictions. As it was expected, these explanations are consistent.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{ema_files/figure-latex/usecaseFIFAshap-1} 

}

\caption{SHAP values for GBM model.}\label{fig:usecaseFIFAshap}
\end{figure}

Robert Lewandowski is a striker. It makes sense that his most valuable characteristics are \texttt{Reactions} and \texttt{BallControl.}

How these plots will look like for goalkeepers? Figure \ref{fig:usecaseFIFAbreakDownWS} show Break Down plots for Wojciech Szczęsny - most valuable polish goalkeeper. As we see the most important coefficients make sense, most of them are linked with properties of goalkeepers.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/usecaseFIFAbreakDownWS-1} 

}

\caption{Break down plot for Wojciech Szczęsny. Results for GBM and RF model.}\label{fig:usecaseFIFAbreakDownWS}
\end{figure}

In Chapter \ref{ceterisParibus} we introduced Ceteris Paribus profiles. These are more details steps of the model exploration. Based on an example of Robert Lewandowski. Figure \ref{fig:usecaseFIFAceterisParibus} show how change in one characteristic affects model value.

Tree based models are flat on borders, and for them Robert value is the highest for variables \texttt{Reactions}, \texttt{BallControl} or \texttt{Dribling}. When it comes to Age we see that the predicted value is just before a larger drop in value prediction.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/usecaseFIFAceterisParibus-1} 

}

\caption{Ceteris Paribus profiles for Robert Lewandowski for four selected variables.}\label{fig:usecaseFIFAceterisParibus}
\end{figure}

Figure \ref{fig:usecaseFIFAceterisParibusNeighbours} shows residuals for all observations against residuals for 50 closest neighbours of Robert Lewandowski. Clearly, among neighbours he has the most expensive players and therefore their residuals are much higher than average residuals. This was also visible in the right top corner of each panel in Figure \ref{fig:modelPerformanceScatterplot}.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/usecaseFIFAceterisParibusNeighbours-1} 

}

\caption{Distribution of residuals for all players and neighbours of Robert Lewandowski.}\label{fig:usecaseFIFAceterisParibusNeighbours}
\end{figure}

Figure \ref{fig:usecaseFIFAceterisParibusNeighboursAgeGBM} shows local-fidelity plot for 15 neighbours of Robert Lewandowski. Model behaviour for these neighbours are similar. We also see that the most expensive players are undervalued by the model.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/usecaseFIFAceterisParibusNeighboursAgeGBM-1} 

}

\caption{Ceteris Paribus profiles for 15 neighbours of Robert Lewandowski.}\label{fig:usecaseFIFAceterisParibusNeighboursAgeGBM}
\end{figure}

\hypertarget{cr7}{%
\section{CR7}\label{cr7}}

In this section we present model explanations for Cristiano Ronaldo (CR7). Here are his characteristics in the FIFA 19 database.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fifa19small[}\StringTok{"Cristiano Ronaldo"}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                   Age Special Preferred.Foot International.Reputation
## Cristiano Ronaldo  33    2228          Right                        5
##                   Weak.Foot Skill.Moves Crossing Finishing HeadingAccuracy
## Cristiano Ronaldo         4           5       84        94              89
##                   ShortPassing Volleys Dribbling Curve FKAccuracy
## Cristiano Ronaldo           81      87        88    81         76
##                   LongPassing BallControl Acceleration SprintSpeed Agility
## Cristiano Ronaldo          77          94           89          91      87
##                   Reactions Balance ShotPower Jumping Stamina Strength
## Cristiano Ronaldo        96      70        95      95      88       79
##                   LongShots Aggression Interceptions Positioning Vision
## Cristiano Ronaldo        93         63            29          95     82
##                   Penalties Composure Marking StandingTackle SlidingTackle
## Cristiano Ronaldo        85        95      28             31            23
##                   GKDiving GKHandling GKKicking GKPositioning GKReflexes
## Cristiano Ronaldo        7         11        15            14         11
##                   LogValue
## Cristiano Ronaldo 7.886491
\end{verbatim}

Let's start with Break Down plots for variable attributions.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{ema_files/figure-latex/usecaseFIFAbreakDownCR7-1} 

}

\caption{Break down plot for Cristiano Ronaldo.}\label{fig:usecaseFIFAbreakDownCR7}
\end{figure}

Cristiano Ronaldo is a striker. It makes sense that his most valuable characteristics are \texttt{Reactions} and \texttt{BallControl.} Let's see Ceteris Paribus profiles for him.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{ema_files/figure-latex/usecaseFIFAceterisParibusCR7-1} 

}

\caption{Ceteris Paribus profiles for Cristiano Ronaldo for four selected variables.}\label{fig:usecaseFIFAceterisParibusCR7}
\end{figure}

\bibliography{book.bib,packages.bib}

\end{document}
