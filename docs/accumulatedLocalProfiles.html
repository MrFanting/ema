<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>19 Local-dependence and Accumulated Local Profiles | Explanatory Model Analysis</title>
  <meta name="description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="19 Local-dependence and Accumulated Local Profiles | Explanatory Model Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="github-repo" content="pbiecek/ema" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="19 Local-dependence and Accumulated Local Profiles | Explanatory Model Analysis" />
  
  <meta name="twitter:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2020-03-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="partialDependenceProfiles.html"/>
<link rel="next" href="residualDiagnostic.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/ema/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><span style="font-size: large">Explanatory Model Analysis</span><br/>Explore, Explain and Examine<br/>Predictive Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#notes-to-readers"><i class="fa fa-check"></i><b>1.1</b> Notes to readers</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.2</b> The aim of the book</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.3</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.4</b> The structure of this book</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i><b>1.5</b> Terminology</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#glass-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.6</b> Glass-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.7</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#what-is-in-this-book-and-what-is-not"><i class="fa fa-check"></i><b>1.8</b> What is in this book and what is not</a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.9</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>2</b> Model Development</a><ul>
<li class="chapter" data-level="2.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPprocess"><i class="fa fa-check"></i><b>2.2</b> The Process</a></li>
<li class="chapter" data-level="2.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notation"><i class="fa fa-check"></i><b>2.3</b> Notation</a></li>
<li class="chapter" data-level="2.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#data-exploration"><i class="fa fa-check"></i><b>2.4</b> Data exploration</a></li>
<li class="chapter" data-level="2.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notationTraining"><i class="fa fa-check"></i><b>2.5</b> Model training</a></li>
<li class="chapter" data-level="2.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#model-understanding"><i class="fa fa-check"></i><b>2.6</b> Model understanding</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself with R</a><ul>
<li class="chapter" data-level="3.1" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#what-to-install"><i class="fa fa-check"></i><b>3.1</b> What to install?</a></li>
<li class="chapter" data-level="3.2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-dalex"><i class="fa fa-check"></i><b>3.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="3.3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>3.3</b> How to work with <code>archivist</code>?</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html"><i class="fa fa-check"></i><b>4</b> Do-it-yourself with Python</a></li>
<li class="chapter" data-level="5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>5</b> Data sets and models</a><ul>
<li class="chapter" data-level="5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>5.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="5.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>5.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.1.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>5.1.2</b> Logistic regression model</a></li>
<li class="chapter" data-level="5.1.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>5.1.3</b> Random forest model</a></li>
<li class="chapter" data-level="5.1.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>5.1.4</b> Gradient boosting model</a></li>
<li class="chapter" data-level="5.1.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-svm"><i class="fa fa-check"></i><b>5.1.5</b> Support Vector Machine model</a></li>
<li class="chapter" data-level="5.1.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>5.1.6</b> Model predictions</a></li>
<li class="chapter" data-level="5.1.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>5.1.7</b> Model adapters</a></li>
<li class="chapter" data-level="5.1.8" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>5.1.8</b> List of objects for the <code>titanic</code> example</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>5.2</b> Apartment prices</a><ul>
<li class="chapter" data-level="5.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>5.2.1</b> Data exploration</a></li>
<li class="chapter" data-level="5.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>5.2.2</b> Linear regression model</a></li>
<li class="chapter" data-level="5.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>5.2.3</b> Random forest model</a></li>
<li class="chapter" data-level="5.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-svm"><i class="fa fa-check"></i><b>5.2.4</b> Support vector model</a></li>
<li class="chapter" data-level="5.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>5.2.5</b> Model predictions</a></li>
<li class="chapter" data-level="5.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>5.2.6</b> Model adapters</a></li>
<li class="chapter" data-level="5.2.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>5.2.7</b> List of objects for the <code>apartments</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="instance-level.html"><a href="instance-level.html"><i class="fa fa-check"></i>Instance Level</a></li>
<li class="chapter" data-level="6" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>6</b> Introduction to Instance Level Exploration</a></li>
<li class="chapter" data-level="7" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>7</b> Break-down Plots for Additive Attributions</a><ul>
<li class="chapter" data-level="7.1" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>7.2</b> Method</a><ul>
<li class="chapter" data-level="7.2.1" data-path="breakDown.html"><a href="breakDown.html#break-down-for-linear-models"><i class="fa fa-check"></i><b>7.2.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="7.2.2" data-path="breakDown.html"><a href="breakDown.html#break-down-for-a-general-case"><i class="fa fa-check"></i><b>7.2.2</b> Break-down for a general case</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>7.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.4" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.5.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-variable_attribution-function"><i class="fa fa-check"></i><b>7.5.1</b> Basic use of the <code>variable_attribution()</code> function</a></li>
<li class="chapter" data-level="7.5.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-variable_attribution-function"><i class="fa fa-check"></i><b>7.5.2</b> Advanced use of the <code>variable_attribution()</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>8</b> Break-down Plots for Interactions (iBreak-down Plots)</a><ul>
<li class="chapter" data-level="8.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>8.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>8.4</b> Pros and cons</a></li>
<li class="chapter" data-level="8.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>8.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9</b> Shapley Additive Explanations (SHAP) and Average Variable Attributions</a><ul>
<li class="chapter" data-level="9.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>9.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>10</b> Local Interpretable Model-agnostic Explanations (LIME)</a><ul>
<li class="chapter" data-level="10.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>10.2</b> Intuition</a></li>
<li class="chapter" data-level="10.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>10.3</b> Method</a><ul>
<li class="chapter" data-level="10.3.1" data-path="LIME.html"><a href="LIME.html#interpretable-data-representation"><i class="fa fa-check"></i><b>10.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="10.3.2" data-path="LIME.html"><a href="LIME.html#sampling-around-the-instance-of-interest"><i class="fa fa-check"></i><b>10.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="10.3.3" data-path="LIME.html"><a href="LIME.html#developing-the-glass-box-model"><i class="fa fa-check"></i><b>10.3.3</b> Developing the glass-box model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>10.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="10.6.1" data-path="LIME.html"><a href="LIME.html#the-lime-package"><i class="fa fa-check"></i><b>10.6.1</b> The lime package</a></li>
<li class="chapter" data-level="10.6.2" data-path="LIME.html"><a href="LIME.html#the-localmodel-package"><i class="fa fa-check"></i><b>10.6.2</b> The localModel package</a></li>
<li class="chapter" data-level="10.6.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>10.6.3</b> The iml package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>11</b> Ceteris-paribus Profiles</a><ul>
<li class="chapter" data-level="11.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>11.2</b> Intuition</a></li>
<li class="chapter" data-level="11.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>11.3</b> Method</a></li>
<li class="chapter" data-level="11.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>11.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="11.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>11.5</b> Pros and cons</a></li>
<li class="chapter" data-level="11.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>11.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="11.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-individual_profile-function"><i class="fa fa-check"></i><b>11.6.1</b> Basic use of the <code>individual_profile</code> function</a></li>
<li class="chapter" data-level="11.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-individual_profile-function"><i class="fa fa-check"></i><b>11.6.2</b> Advanced use of the <code>individual_profile</code> function</a></li>
<li class="chapter" data-level="11.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#champion-challenger-analysis"><i class="fa fa-check"></i><b>11.6.3</b> Champion-challenger analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>12</b> Ceteris-paribus Oscillations</a><ul>
<li class="chapter" data-level="12.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a></li>
<li class="chapter" data-level="12.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="12.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="12.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-variable_attribution-function-1"><i class="fa fa-check"></i><b>12.6.1</b> Basic use of the <code>variable_attribution</code> function</a></li>
<li class="chapter" data-level="12.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-variable_attribution-function-1"><i class="fa fa-check"></i><b>12.6.2</b> Advanced use of the <code>variable_attribution</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>13</b> Local Diagnostics Plots</a><ul>
<li class="chapter" data-level="13.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>13.2</b> Intuition</a></li>
<li class="chapter" data-level="13.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>13.3</b> Method</a><ul>
<li class="chapter" data-level="13.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagNeighbors"><i class="fa fa-check"></i><b>13.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="13.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>13.3.2</b> Local-fidelity plot</a></li>
<li class="chapter" data-level="13.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>13.3.3</b> Local-stability plot for neighbors</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>13.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="13.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>13.5</b> Pros and cons</a></li>
<li class="chapter" data-level="13.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>13.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>14</b> Summary of Instance-level Explainers</a><ul>
<li class="chapter" data-level="14.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>14.1</b> Number of explanatory variables in the model</a><ul>
<li class="chapter" data-level="14.1.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.2</b> Medium to large number of explanatory variables</a></li>
<li class="chapter" data-level="14.1.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.1.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>14.2</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="14.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>14.3</b> Models with interactions</a></li>
<li class="chapter" data-level="14.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>14.4</b> Sparse explanations</a></li>
<li class="chapter" data-level="14.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>14.5</b> Additional uses of model exploration and explanation</a></li>
<li class="chapter" data-level="14.6" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#champion-challenger-analysis-1"><i class="fa fa-check"></i><b>14.6</b> Champion Challenger analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dataset-level.html"><a href="dataset-level.html"><i class="fa fa-check"></i>Dataset Level</a></li>
<li class="chapter" data-level="15" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>15</b> Model-level exploration</a></li>
<li class="chapter" data-level="16" data-path="modelPerformance.html"><a href="modelPerformance.html"><i class="fa fa-check"></i><b>16</b> Model Performance Measures</a><ul>
<li class="chapter" data-level="16.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntuition"><i class="fa fa-check"></i><b>16.2</b> Intuition</a></li>
<li class="chapter" data-level="16.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethod"><i class="fa fa-check"></i><b>16.3</b> Method</a><ul>
<li class="chapter" data-level="16.3.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCont"><i class="fa fa-check"></i><b>16.3.1</b> Continuous dependent variable</a></li>
<li class="chapter" data-level="16.3.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodBin"><i class="fa fa-check"></i><b>16.3.2</b> Binary dependent variable</a></li>
<li class="chapter" data-level="16.3.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCateg"><i class="fa fa-check"></i><b>16.3.3</b> Categorical dependent variable</a></li>
<li class="chapter" data-level="16.3.4" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCount"><i class="fa fa-check"></i><b>16.3.4</b> Count dependent variable</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="modelPerformance.html"><a href="modelPerformance.html#example"><i class="fa fa-check"></i><b>16.4</b> Example</a><ul>
<li class="chapter" data-level="16.4.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceApartments"><i class="fa fa-check"></i><b>16.4.1</b> Apartment prices</a></li>
<li class="chapter" data-level="16.4.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceTitanic"><i class="fa fa-check"></i><b>16.4.2</b> Titanic data</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceProsCons"><i class="fa fa-check"></i><b>16.5</b> Pros and cons</a></li>
<li class="chapter" data-level="16.6" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceR"><i class="fa fa-check"></i><b>16.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>17</b> Variable’s Importance</a><ul>
<li class="chapter" data-level="17.1" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntuition"><i class="fa fa-check"></i><b>17.2</b> Intuition</a></li>
<li class="chapter" data-level="17.3" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceMethod"><i class="fa fa-check"></i><b>17.3</b> Method</a></li>
<li class="chapter" data-level="17.4" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceTitanic"><i class="fa fa-check"></i><b>17.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="17.5" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceProsCons"><i class="fa fa-check"></i><b>17.5</b> Pros and cons</a></li>
<li class="chapter" data-level="17.6" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceR"><i class="fa fa-check"></i><b>17.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="17.6.1" data-path="featureImportance.html"><a href="featureImportance.html#models-comparison"><i class="fa fa-check"></i><b>17.6.1</b> Models comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>18</b> Partial dependence profiles</a><ul>
<li class="chapter" data-level="18.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntuition"><i class="fa fa-check"></i><b>18.2</b> Intuition</a></li>
<li class="chapter" data-level="18.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPMethod"><i class="fa fa-check"></i><b>18.3</b> Method</a><ul>
<li class="chapter" data-level="18.3.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPs"><i class="fa fa-check"></i><b>18.3.1</b> Partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clusteredPDPs"><i class="fa fa-check"></i><b>18.3.2</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#groupedPDPs"><i class="fa fa-check"></i><b>18.3.3</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.3.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastivePDPs"><i class="fa fa-check"></i><b>18.3.4</b> Contrastive partial dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPExample"><i class="fa fa-check"></i><b>18.4</b> Example: Apartments data</a><ul>
<li class="chapter" data-level="18.4.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.1</b> Partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.2</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.3</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.4.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles"><i class="fa fa-check"></i><b>18.4.4</b> Contrastive partial dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPProsCons"><i class="fa fa-check"></i><b>18.5</b> Pros and cons</a></li>
<li class="chapter" data-level="18.6" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPR"><i class="fa fa-check"></i><b>18.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="18.6.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.1</b> Clustered partial dependence profiles</a></li>
<li class="chapter" data-level="18.6.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.2</b> Grouped partial dependence profiles</a></li>
<li class="chapter" data-level="18.6.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>18.6.3</b> Contrastive partial dependence profiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>19</b> Local-dependence and Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="19.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntro"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntuition"><i class="fa fa-check"></i><b>19.2</b> Intuition</a></li>
<li class="chapter" data-level="19.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPMethod"><i class="fa fa-check"></i><b>19.3</b> Method</a><ul>
<li class="chapter" data-level="19.3.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#local-dependence-profile"><i class="fa fa-check"></i><b>19.3.1</b> Local-dependence profile</a></li>
<li class="chapter" data-level="19.3.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#accumulated-local-profile"><i class="fa fa-check"></i><b>19.3.2</b> Accumulated local profile</a></li>
<li class="chapter" data-level="19.3.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#summaryFeatureEffects"><i class="fa fa-check"></i><b>19.3.3</b> An illustrative example</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#CDPExample"><i class="fa fa-check"></i><b>19.4</b> Example: Apartments data</a></li>
<li class="chapter" data-level="19.5" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPProsCons"><i class="fa fa-check"></i><b>19.5</b> Pros and cons</a></li>
<li class="chapter" data-level="19.6" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPR"><i class="fa fa-check"></i><b>19.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>20</b> Residual Diagnostics</a><ul>
<li class="chapter" data-level="20.1" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntroResidualDiagnostic"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntuitionResidualDiagnostic"><i class="fa fa-check"></i><b>20.2</b> Intuition</a></li>
<li class="chapter" data-level="20.3" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#MethodResidualDiagnostic"><i class="fa fa-check"></i><b>20.3</b> Method</a></li>
<li class="chapter" data-level="20.4" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ExampleResidualDiagnostic"><i class="fa fa-check"></i><b>20.4</b> Example: Apartments data</a></li>
<li class="chapter" data-level="20.5" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ProsConsResidualDiagnostic"><i class="fa fa-check"></i><b>20.5</b> Pros and cons</a></li>
<li class="chapter" data-level="20.6" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#RcodeResidualDiagnostic"><i class="fa fa-check"></i><b>20.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="use-cases.html"><a href="use-cases.html"><i class="fa fa-check"></i>Use Cases</a></li>
<li class="chapter" data-level="21" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html"><i class="fa fa-check"></i><b>21</b> FIFA 19</a><ul>
<li class="chapter" data-level="21.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#introduction-1"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-preparation"><i class="fa fa-check"></i><b>21.2</b> Data preparation</a></li>
<li class="chapter" data-level="21.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#data-understanding"><i class="fa fa-check"></i><b>21.3</b> Data understanding</a></li>
<li class="chapter" data-level="21.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-assembly"><i class="fa fa-check"></i><b>21.4</b> Model assembly</a></li>
<li class="chapter" data-level="21.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-audit"><i class="fa fa-check"></i><b>21.5</b> Model audit</a></li>
<li class="chapter" data-level="21.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#model-understanding-1"><i class="fa fa-check"></i><b>21.6</b> Model understanding</a></li>
<li class="chapter" data-level="21.7" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#instance-understanding"><i class="fa fa-check"></i><b>21.7</b> Instance understanding</a></li>
<li class="chapter" data-level="21.8" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#cr7"><i class="fa fa-check"></i><b>21.8</b> CR7</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/ModelOriented/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Explanatory Model Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="accumulatedLocalProfiles" class="section level1">
<h1><span class="header-section-number">19</span> Local-dependence and Accumulated Local Profiles</h1>
<div id="ALPIntro" class="section level2">
<h2><span class="header-section-number">19.1</span> Introduction</h2>
<p>Partial-dependence (PD) profiles, introduced in the previous chapter, are easy to explain and interpret, especially given their estimation as an average of Ceteris-paribus (CP) profiles. However, as it was mentioned in Section <a href="partialDependenceProfiles.html#PDPProsCons">18.5</a>, the profiles may be misleading if the explanatory variables are correlated. In many applications, this is the case. For example, in the Apartments dataset (see Section <a href="dataSetsIntro.html#ApartmentDataset">5.2</a>), one can expect that variables ‘’surface’’ and ‘’number of rooms’’ may be positively correlated, because apartments with larger number of rooms usually also have a larger surface. Thus, it is not realistic to consider, for instance, an apartment with 5 rooms and 20 square meters. Similarly, in the Titanic dataset, a positive correlation can be expected for the values of variables ‘’fare’’ and ‘’passenger class’’, as tickets in the higher classes are more expensive than in the lower classes.</p>
<p>In this chapter, we present accumulated local (AL) profiles that address this issue. As they are related to local-dependence (LD) profiles, we introduce the latter first. Both approaches were proposed in ,,ALEPlot: Accumulated Local Effects (ALE) Plots and Partial Dependence (PD) Plots’’ <span class="citation">(Apley <a href="#ref-ALEPlotRPackage">2018</a>)</span>.</p>
</div>
<div id="ALPIntuition" class="section level2">
<h2><span class="header-section-number">19.2</span> Intuition</h2>
<!--
The general idea behind LD profiles is to use the conditional distribution of the instead of marginal distribution to accommodate for the dependency between $x^j$ and $x^{-j}$.
The general idea behind Accumulated Local Profiles is to accumulate local changes in model response affected by single feature $x^j$.

Intuition behind Partial Dependency profiles and their extensions is presented in Figure \@ref(fig:accumulatedLocalEffects).
-->
<p>Let us consider the following, simple nonlinear model with for two explanatory variables:</p>
<p><span class="math display" id="eq:trickyModel">\[\begin{equation}
f(x_1, x_2) = (x_1 + 1)\cdot x_2.
\tag{19.1}
\end{equation}\]</span></p>
<p>Moreover, assume that explanatory variables <span class="math inline">\(X^1\)</span> and <span class="math inline">\(X^2\)</span> are uniformly distributed over the interval <span class="math inline">\([-1,1]\)</span> and perfectly correlated, i.e., <span class="math inline">\(X^2 = X^1\)</span>. Suppose that we have got the following dataset with 8 observations:</p>
<table>
<thead>
<tr class="header">
<th>i</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(X^1\)</span></td>
<td>-1</td>
<td>-0.71</td>
<td>-0.43</td>
<td>-0.14</td>
<td>0.14</td>
<td>0.43</td>
<td>0.71</td>
<td>1</td>
</tr>
<tr class="even">
<td><span class="math inline">\(X^2\)</span></td>
<td>-1</td>
<td>-0.71</td>
<td>-0.43</td>
<td>-0.14</td>
<td>0.14</td>
<td>0.43</td>
<td>0.71</td>
<td>1</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(y\)</span></td>
<td>0</td>
<td>-0.2059</td>
<td>-0.2451</td>
<td>-0.1204</td>
<td>0.1596</td>
<td>0.6149</td>
<td>1.2141</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>Note that, for both <span class="math inline">\(X^1\)</span> and <span class="math inline">\(X^2\)</span>, the sum of all observed values is equal to 0.</p>
<p>The top part of Panel A of Figure <a href="accumulatedLocalProfiles.html#fig:accumulatedLocalEffects">19.1</a> shows CP profiles for <span class="math inline">\(X^1\)</span> for model <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a> calculated for the eight observations. The bottom part of the panel presents the corresponding estimate of the PD profile for <span class="math inline">\(X^1\)</span>, i.e., the average of the CP profiles. The profile suggests no effect of variable <span class="math inline">\(X^1\)</span>, which is clearly a misleading conclusion.</p>
<p>To understand the reason, let us explicitly express the CP profile for <span class="math inline">\(X^1\)</span> for model <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a>:</p>
<p><span class="math display" id="eq:CPtrickyModel">\[\begin{equation}
h^{(x_1 + 1) \cdot x_2 , 1}_{x_1,x_2}(z) = f(z,x_2) = (z+1)\cdot x_2.
\tag{19.2}
\end{equation}\]</span></p>
<p>By allowing <span class="math inline">\(z\)</span> to take any value in the interval <span class="math inline">\([-1,1]\)</span>, we get the CP profiles as straight lines with the slope equal to the value of variable <span class="math inline">\(X^2\)</span>. Hence, for instance, the CP profile for observation <span class="math inline">\((-1,-1)\)</span> is a straight line with the slope equal to -1.</p>
<p>Recall that the PD profile for <span class="math inline">\(X^j\)</span>, defined in equation <a href="partialDependenceProfiles.html#eq:PDPdef0">(18.1)</a>, is the expected value, over the joint distribution of all explanatory variables other than <span class="math inline">\(X^j\)</span>, of the model predictions when <span class="math inline">\(X^j\)</span> is set to <span class="math inline">\(z\)</span>. This leads to the estimation of the profile by taking the average of CP profiles for <span class="math inline">\(X^j\)</span> (see equation <a href="partialDependenceProfiles.html#eq:PDPest">(18.2)</a>).</p>
<p>In our case, this implies that the PD profile for <span class="math inline">\(X^1\)</span> is the expected value of the model predictions over the distribution of <span class="math inline">\(X^2\)</span>, i.e., over the uniform distribution on the interval <span class="math inline">\([-1,1]\)</span>. Thus, the PD profile is estimated by taking the average of the CP profiles (see <a href="accumulatedLocalProfiles.html#eq:CPtrickyModel">(19.2)</a>) at each value of <span class="math inline">\(z\)</span> in <span class="math inline">\([-1,1]\)</span>:</p>
<p><span class="math display" id="eq:PDtrickyModel">\[\begin{equation}
\hat g_{PD}^{(x_1 + 1)\cdot x_2, 1}(z) =  \frac{1}{8} \sum_{i=1}^{8} (z+1)\cdot x_{2,i} = \frac{z+1}{8}  \sum_{i=1}^{8} x_{2,i} = 0.
\tag{19.3}
\end{equation}\]</span></p>
<p>As a result, the PD profile for <span class="math inline">\(X^1\)</span> is estimated as a horizontal line at 0, as seen in the bottom part of Panel A of Figure <a href="accumulatedLocalProfiles.html#fig:accumulatedLocalEffects">19.1</a>.</p>
<p>The calculations in equation <a href="accumulatedLocalProfiles.html#eq:PDtrickyModel">(19.3)</a> ignore the fact that, given our assumptions, one cannot change <span class="math inline">\(z\)</span> <em>freely</em> for a particular value of <span class="math inline">\(X^2\)</span>, because <span class="math inline">\(X^1\)</span> and <span class="math inline">\(X^2\)</span> are assumed to be perfectly correlated. In fact, in this case, the CP profile for the <span class="math inline">\(i\)</span>-th observation should actually be undefined for any values of <span class="math inline">\(z\)</span> different from <span class="math inline">\(x^2_i\)</span>. As a consequence, the sum used in the calculation of the PD profile in equation <a href="accumulatedLocalProfiles.html#eq:PDtrickyModel">(19.3)</a> would involve undefined terms for any <span class="math inline">\(z\)</span>.</p>
<p>Thus, the issue is related to the fact of using the marginal distribution of <span class="math inline">\(X^2\)</span>, which disregards the value of <span class="math inline">\(X^1\)</span>, in the definition of the PD profile. This observation suggests a modification: instead of the marginal distribution, one might consider the conditional distribution of <span class="math inline">\(X^2 | X^1\)</span>. The modification leads to the definition of the LD profile.</p>
<p>For in our example, the conditional distribution of <span class="math inline">\(X^2\)</span>, given <span class="math inline">\(X^1=z\)</span>, is just a probability mass of 1 at <span class="math inline">\(z\)</span>. Consequently, the Local-dependence (LD) profile, for any <span class="math inline">\(z \in [-1,1]\)</span>, is given by
<span class="math display" id="eq:LDtrickyModel">\[\begin{equation}
g_{LD}^{(x_1 + 1)\cdot x_2, 1}(z) =  z \cdot (z+1).
\tag{19.4}
\end{equation}\]</span></p>
<p>It turns out, however, that the modification does not fully address the issue of correlated explanatory variables.</p>
<!-- Profile LD  -->
<p>Looking at equation <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a> one can see that from the perspective of <span class="math inline">\(X^1\)</span> the effect of the variable <span class="math inline">\(x_1\)</span> is similar to the function <span class="math inline">\(f(x_1) = -x_1 -1\)</span> for values close to <span class="math inline">\((x_1, x_2) = (-1,-1)\)</span> and similar to the function <span class="math inline">\(f(x_1) = x_1 +1\)</span> for values close to <span class="math inline">\((x_1, x_2) = (1,1)\)</span>. So first it decreases at the same rate as it increases later. The function in equation <a href="accumulatedLocalProfiles.html#eq:LDtrickyModel">(19.4)</a> does not show this.</p>
<p>In the <span class="citation">(Apley <a href="#ref-ALEPlotRPackage">2018</a>)</span>, author proposed Accumulated Local Effects (AL) profiles, where the effect of the <span class="math inline">\(X^1\)</span> variable is defined as the cumulative sum of local derivatives due to the <span class="math inline">\(X^1\)</span> variable</p>
<p><span class="math display" id="eq:ALtrickyModel">\[\begin{equation}
g_{AL}^{(x_1 + 1)\cdot x_2, 1}(z) = 
\int_{-1}^z E \left[\frac{\partial f(x_1, x_2)}{\partial x_1} | X^1 = v \right] dv = 
\int_{-1}^z E \left[X^2 | X^1 = v \right] dv = 
\int_{-1}^z v dv =
(z^2 - 1)/2.
\tag{19.5}
\end{equation}\]</span></p>
<p>This formula better reflects the behavior of function <span class="math inline">\(f(x_1,x_2)\)</span> due to <span class="math inline">\(X^1\)</span> removing the effect of changes in variable <span class="math inline">\(X^2\)</span>.</p>
<!--
For example, for the `apartments` dataset one can expect that features like `surface` and `number.of.rooms` are correlated but we can also imagine that each of these variables affect the apartment price somehow. Partial Dependency Profiles show how the average price changes as a function of surface, keeping all other variables unchanged. Conditional Dependency Profiles show how the average price changes as a function of surface adjusting all other variables to the current value of the surface. Accumulated Local Profiles show how the average price changes as a function of surface adjusting all other variables to the current value of the surface but extracting changes caused by these other features. 
-->
</div>
<div id="ALPMethod" class="section level2">
<h2><span class="header-section-number">19.3</span> Method</h2>
<div id="local-dependence-profile" class="section level3">
<h3><span class="header-section-number">19.3.1</span> Local-dependence profile</h3>
<p>LD profile for model <span class="math inline">\(f(x)\)</span> and variable <span class="math inline">\(X^j\)</span> is defined as follows:</p>
<p><span class="math display" id="eq:LDPdef">\[\begin{equation}
g_{LD}^{f, j}(z) = E_{X^{-j}|X^j=z}\left[f\left(X^{j|=z}\right)\right].
\tag{19.6}
\end{equation}\]</span></p>
<p>Thus, it is the expected value of the model predictions over the conditional distribution of <span class="math inline">\(X^{-j}\)</span> given <span class="math inline">\(X^j=z\)</span>, i.e., over the joint distribution of all explanatory variables other than <span class="math inline">\(X^j\)</span> conditional on the value of the latter variable set to <span class="math inline">\(z\)</span>. Or, in other words, it is the expected value of the CP profiles in equation <a href="ceterisParibus.html#eq:CPPdef">(11.1)</a> for <span class="math inline">\(X^j\)</span> over the conditional distribution of <span class="math inline">\(X^{-j} | X^j\)</span>.</p>
<!--
For example, let $f(x_1, x_2) = x_1 + x_2$ and distribution of $(x_1, x_2)$ is given by $x_1 \sim U[0,1]$ and $x_2=x_1$. In this case $g^{CD}_{f, 1}(z) = 2*z$.
-->
<p>For example, consider <span class="math inline">\(X=(X^1,X^2)\)</span> with <span class="math inline">\(X^1\)</span> uniformly distributed over <span class="math inline">\([-1,1]\)</span> and <span class="math inline">\(X^2=X^1\)</span>. Then the conditional distribution of <span class="math inline">\(X^{-1} \equiv X^2\)</span>, given <span class="math inline">\(X^1=z\)</span>, is the point mass of 1 at <span class="math inline">\(z\)</span>. Consequently, for model <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a> and variable <span class="math inline">\(X^1\)</span>, we get</p>
<p><span class="math display">\[
g_{LD}^{(x_1+1)\cdot x_2,1}(z) = E_{X^2|X^1=z}[f(z,X^2)] = E_{X^2|X^1=z}[(z+1)\cdot X^2] = (z+1)\cdot E_{X^2|X^1=z}(X^2) = (z+1)\cdot z,
\]</span>
as given in Equation <a href="accumulatedLocalProfiles.html#eq:LDtrickyModel">(19.4)</a>.</p>
<p>As proposed in ,,ALEPlot: Accumulated Local Effects Plots and Partial Dependence Plots’’ <span class="citation">(Apley <a href="#ref-ALEPlotRPackage">2018</a>)</span>, LD profile can be estimated as follows:</p>
<p><span class="math display" id="eq:LDPest">\[\begin{equation}
\hat g_{LD}^{f,j}(z) = \frac{1}{|N_j|} \sum_{k\in N_j} f\left(x_k^{j| = z}\right), 
\tag{19.7}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(N_j\)</span> is the set of observations with the value of <span class="math inline">\(X^j\)</span> ‘’close’’ to <span class="math inline">\(z\)</span> that is used to estimate the conditional distribution of <span class="math inline">\(X^{-j}|X^j=z\)</span>.</p>
<!--
In Figure \@ref(fig:accumulatedLocalEffects) panel C the range of variable $x_i$ is divided into 4 separable intervals. The set $N_i$ contains all observations that fall into the same interval as observation $x_i$. The final CD profile is an average from closest pieces of CP profiles.
-->
<p>Note that, in general, the estimator given in formula <a href="accumulatedLocalProfiles.html#eq:LDPest">(19.7)</a> is neither smooth nor continuous at boundaries between subsets <span class="math inline">\(N_i\)</span>. A smooth estimator for <span class="math inline">\(g_{LD}^{f,j}(z)\)</span> can be defined as follows:</p>
<p><span class="math display" id="eq:LDPest2">\[\begin{equation}
\tilde g_{LD}^{f,j}(z) = \frac{1}{\sum_k w_{k}(z)} \sum_{i = 1}^N w_i(z) f(x_i^{j| = z}), 
\tag{19.8}
\end{equation}\]</span></p>
<p>where weights <span class="math inline">\(w_i(z)\)</span> capture the distance between <span class="math inline">\(z\)</span> and <span class="math inline">\(x_i^j\)</span>. In particular, for a categorical variable, we may just use the indicator function <span class="math inline">\(w_i(z) = 1_{z = x^j_i}\)</span>, while for a continuous variable we may use the Gaussian kernel:</p>
<p><span class="math display" id="eq:Gkernel">\[\begin{equation}
w_i(z) = \phi(z - x_i^j, 0, s),
\tag{19.9}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\phi(y,0,s)\)</span> is the density of a normal distribution with mean 0 and standard deviation <span class="math inline">\(s\)</span>. Note that <span class="math inline">\(s\)</span> plays the role of a smoothing factor.</p>
<p>As argued in ,,Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models’’ <span class="citation">(Apley and Zhu <a href="#ref-ALEPlot2">2019</a>)</span>, if an explanatory variable is correlated with some other variables, the LD profile for the variable will capture the effect of all of the variables. This is because the profile is obtained by marginalizing (in fact, ignoring) over the remaining variables in the model. Thus, in this respect, LD profiles share the same limitation as PD profiles. To address the limitation, AD profiles can be used. We present them in the next section.</p>
</div>
<div id="accumulated-local-profile" class="section level3">
<h3><span class="header-section-number">19.3.2</span> Accumulated local profile</h3>
<p>Consider model <span class="math inline">\(f(x)\)</span> and define</p>
<p><span class="math display">\[
h^j(u)=\left[ \frac{\partial f(x)}{\partial x^j} \right]_{x=u}.
\]</span>
The AL profile for model <span class="math inline">\(f(x)\)</span> and variable <span class="math inline">\(X^j\)</span> is defined as follows:</p>
<p><span class="math display" id="eq:ALPdef">\[\begin{equation}
g_{AL}^{f, j}(z) = \int_{z_0}^z \left\{E_{X^{-j}|X^j=u}\left[ h^j(X^{j|=u}) \right]\right\} du + c,
\tag{19.10}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(z_0\)</span> is a value close to the lower bound of the effective support of the distribution of <span class="math inline">\(X^j\)</span> and <span class="math inline">\(c\)</span> is a constant, usually selected so that <span class="math inline">\(E_{X^j}\left[g_{AL}^{f,j}(X^j)\right] = E_X f(x)\)</span>.</p>
<p>To interpret equation <a href="accumulatedLocalProfiles.html#eq:ALPdef">(19.10)</a> note that <span class="math inline">\(h^j(u)\)</span> describes the local effect (change) of the model due to <span class="math inline">\(X^j\)</span>. Or, to put it in other words, <span class="math inline">\(h^j(u)\)</span> describes how much the CP profile for <span class="math inline">\(X^j\)</span> changes at <span class="math inline">\(u\)</span>. This effect (change) is averaged over the ‘’relevant’’ (according to the conditional distribution of <span class="math inline">\(X^{-j}|X^j\)</span>) values of <span class="math inline">\(X^{-j}\)</span> and, subsequently, accumulated (integrated) over values of <span class="math inline">\(u\)</span> up to <span class="math inline">\(z\)</span>. As argued by <span class="citation">(Apley and Zhu <a href="#ref-ALEPlot2">2019</a>)</span>, the averaging of the local effects allows avoiding the issue, present in the PD and LD profiles, of capturing the effect of other variables in the profile for a particular variable. To see this, one can consider the approximation</p>
<p><span class="math display">\[
f(u^{j|=u+du})-f(u^{j|=u})  \approx h^j(u)du,
\]</span>
and note that the difference <span class="math inline">\(f(u^{j|=u+du})-f(u^{j|=u})\)</span>, for a model without interaction, effectively removes the effect of all variables other than <span class="math inline">\(X^j\)</span>. For example, consider model <span class="math inline">\(f(x_1, x_2) = x_1 + x_2\)</span>, with <span class="math inline">\(f_1(x_1,x_2)=1\)</span>. Then</p>
<p><span class="math display">\[
f(u+du,x_2)-f(u,x_2)  = (u + du + x_2) - (u + x_2) = du = f_1(u,x_2) du.
\]</span>
As another example, consider model <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a>. In this case, <span class="math inline">\(f_1(x_1,x_2)=x_2\)</span> and the effect of variable <span class="math inline">\(X^2\)</span> will still be present in the AL profile for <span class="math inline">\(X^1\)</span>.</p>
<p>Continuing with model in formula <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a>, assume that <span class="math inline">\(X=(X^1,X^2)\)</span> with <span class="math inline">\(X^1\)</span> uniformly distributed over <span class="math inline">\([-1,1]\)</span> and <span class="math inline">\(X^2=X^1\)</span>. In this case, the conditional distribution of <span class="math inline">\(X^2 | X^1=z\)</span> is the point mass of 1 at <span class="math inline">\(z\)</span>. Then</p>
<p><span class="math display" id="eq:ALtrickyModel">\[\begin{equation}
g_{AL}^{(x_1+1)\cdot x_2,1}(z) = \int_{-1}^z \left[E_{X^2|X^1=u}\left( X^2 \right)\right] du + c = \int_{-1}^z u du + c = \frac{z^2-1}{2}+c.
\tag{19.5}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(E_{X^1}\left[(X^1)^2\right] = 1/3\)</span>, then, upon taking <span class="math inline">\(c=-1/3\)</span>, we get <span class="math inline">\(E_{X^1}\left[g_{AL}^{(x_1+1) \cdot x_2,1}(X^1)\right] = 0\)</span>.</p>
<p>To estimate AL profile, one replaces the integral in equation <a href="accumulatedLocalProfiles.html#eq:ALPdef">(19.10)</a> by a summation and the derivative with a finite difference <span class="citation">(Apley <a href="#ref-ALEPlotRPackage">2018</a>)</span>. In particular, consider a partition of the range of observed values <span class="math inline">\(x_{i}^j\)</span> of variable <span class="math inline">\(X^j\)</span> into <span class="math inline">\(K\)</span> intervals <span class="math inline">\(N_j(k)=(z_{k-1}^j,z_k^j]\)</span> (<span class="math inline">\(k=1,\ldots,K\)</span>). Note that <span class="math inline">\(z_0^j\)</span> can be chosen just below <span class="math inline">\(\min(x_1^j,\ldots,x_N^j)\)</span> and <span class="math inline">\(z_K^j=\max(x_1^j,\ldots,x_N^j)\)</span>. Let <span class="math inline">\(n_j(k)\)</span> denote the number of observations <span class="math inline">\(x_i^j\)</span> falling into <span class="math inline">\(N_j(k)\)</span>, with <span class="math inline">\(\sum_{k=1}^K n_j(k)=N\)</span>. An estimator of AL profile for variable <span class="math inline">\(X^j\)</span> can then be constructed as follows:</p>
<p><span class="math display" id="eq:ALPest">\[\begin{equation}
\widehat{g}_{AL}^{f,j}(z) = \sum_{k=1}^{k_j(z)} \frac{1}{n_j(k)} \sum_{i: x_i^j \in N_j(k)} \left[ f(x_i^{j| = z_k^j}) - f(x_i^{j| = z_{k-1}^j}) \right] - \hat{c},
\tag{19.11}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(k_j(z)\)</span> is the index of interval <span class="math inline">\(N_j(k)\)</span> in which <span class="math inline">\(z\)</span> falls, i.e., <span class="math inline">\(z \in N_j[k_j(z)]\)</span>, and <span class="math inline">\(\hat{c}\)</span> is selected so that <span class="math inline">\(\sum_{i=1}^n \widehat{g}_{AL}^{f,j}(x_i^j)=0\)</span>. To interpret formula <a href="accumulatedLocalProfiles.html#eq:ALPest">(19.11)</a> note that difference <span class="math inline">\(f\left(x_i^{j| = z_k^j}\right) - f\left(x_i^{j| = z_{k-1}^j}\right)\)</span> corresponds to the difference of the CP profile for the <span class="math inline">\(i\)</span>-th observation at the limits of interval <span class="math inline">\(N_j(k)\)</span>. This differences for are then averaged across all observations falling into the interval and accumulated.</p>
<!--
In Figure \@ref(fig:accumulatedLocalEffects) panel D the range of variable $x_i$ is divided into 4 separable intervals. The set $N_i$ contains all observations that fall into the same interval as observation $x_i$. The final ALE profile is constructed from accumulated differences of local CP profiles.
-->
<p>Note that, in general, <span class="math inline">\(\widehat{g}_{AL}^{f,j}(z)\)</span> is not smooth at the boundaries of intervals <span class="math inline">\(N_j(k)\)</span>. A smooth estimate can obtained as follows:</p>
<p><span class="math display" id="eq:ALPest2">\[\begin{equation}
\widetilde{g}_{AL}^{f,j}(z) = \sum_{k=1}^K \frac{1}{\sum_{l} w_l(z_k)} \sum_{i=1}^N w_{i}(z_k) \left[f(x_i^{j| = z_k}) - f(x_i^{j| = z_k - \Delta})\right] - c,
\tag{19.12}
\end{equation}\]</span></p>
<p>where points <span class="math inline">\(z_k\)</span> (<span class="math inline">\(k=0, \ldots, K\)</span>) form a uniform grid covering the interval <span class="math inline">\((z_0,z)\)</span> with step <span class="math inline">\(\Delta = (z-z_0)/K\)</span>, and weight <span class="math inline">\(w_i(z_k)\)</span> captures the distance between point <span class="math inline">\(z_k\)</span> and observation <span class="math inline">\(x_i^j\)</span>. In particular, we may use similar weights as in case of equation <a href="accumulatedLocalProfiles.html#eq:LDPest2">(19.8)</a>.</p>
</div>
<div id="summaryFeatureEffects" class="section level3">
<h3><span class="header-section-number">19.3.3</span> An illustrative example</h3>
<p>Let us consider model <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a> and explanatory-variable vector <span class="math inline">\(X=(X^1,X^2)\)</span> with <span class="math inline">\(X^1\)</span> uniformly distributed over <span class="math inline">\([-1,1]\)</span> and <span class="math inline">\(X^2=X^1\)</span>. Hence, <span class="math inline">\(X^2\)</span> is perfectly correlated with <span class="math inline">\(X^1\)</span>. Moreover, consider the eight observations for <span class="math inline">\(X\)</span> from Section <a href="accumulatedLocalProfiles.html#ALPIntuition">19.2</a>.</p>
<p>The top part of Panel A of Figure <a href="accumulatedLocalProfiles.html#fig:accumulatedLocalEffects">19.1</a> shows CP profiles for <span class="math inline">\(X^1\)</span> for the eight observations, as computed in formula <a href="accumulatedLocalProfiles.html#eq:CPtrickyModel">(19.2)</a>. The bottom part of the panel shows the estimated PD profile obtained by using the average of the CP profiles. As indicated by formula <a href="accumulatedLocalProfiles.html#eq:PDtrickyModel">(19.3)</a>, the PD profile is estimated at 0. The estimate is correct, as</p>
<p><span class="math display">\[
g_{PD}^{(x_1+1)\cdot x_2,1}(z) = E_{X^2}[(z+ 1)\cdot X^2] = (z+1)\cdot E_{X^2}(X^2) = 0,
\]</span>
given that <span class="math inline">\(X^2\)</span> is uniformly-distributed over <span class="math inline">\([-1,1]\)</span>. It is, however, misleading, as there clearly is an effect of <span class="math inline">\(X^1\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:accumulatedLocalEffects"></span>
<img src="figure/CP_ALL.png" alt="Partial-dependence, local-dependence, and accumulated local profiles. Panel A: Ceteris-paribus profiles (top plot) and the corresponding partial-dependence profile. Panel B: local-dependence profile. Panel C: accumulated local profile." width="90%" />
<p class="caption">
Figure 19.1: Partial-dependence, local-dependence, and accumulated local profiles. Panel A: Ceteris-paribus profiles (top plot) and the corresponding partial-dependence profile. Panel B: local-dependence profile. Panel C: accumulated local profile.
</p>
</div>
<p>The LD profile for model <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a>, as computed in <a href="accumulatedLocalProfiles.html#eq:LDtrickyModel">(19.4)</a>, is</p>
<p><span class="math display">\[
g_{LD}^{(x_1+1)\cdot x_2,1}(z) =  (z+1)\cdot z.
\]</span>
By using estimator <a href="accumulatedLocalProfiles.html#eq:LDPest">(19.7)</a>, with the data split into four intervals each containing two observations, we obtain the estimated LD profile shown at the bottom of Panel B of Figure <a href="accumulatedLocalProfiles.html#fig:accumulatedLocalEffects">19.1</a>.</p>
<p>As shown in <a href="accumulatedLocalProfiles.html#eq:ALtrickyModel">(19.5)</a>, the AL profile for model presented in formula <a href="accumulatedLocalProfiles.html#eq:trickyModel">(19.1)</a> is up to the constant equal
<span class="math display">\[
g_{AL}^{(x_1+1)\cdot x_2,1}(z) =  \frac{z^2-1}{2} + c.
\]</span></p>
<p>By using estimator <a href="accumulatedLocalProfiles.html#eq:ALPest">(19.11)</a>, with the data split into four intervals each containing two observations, we obtain the estimated AL profile shown at the bottom of Panel C of Figure <a href="accumulatedLocalProfiles.html#fig:accumulatedLocalEffects">19.1</a>.</p>
</div>
</div>
<div id="CDPExample" class="section level2">
<h2><span class="header-section-number">19.4</span> Example: Apartments data</h2>
<p>In this section, we use PD, LD, and AL profiles to evaluate performance of the random-forest model <code>apartments_rf_v5</code> (see Section <a href="dataSetsIntro.html#model-Apartments-rf">5.2.3</a>) for the Apartments dataset (see Section <a href="dataSetsIntro.html#ApartmentDataset">5.2</a>). Recall that the goal is to predict the price per square-meter of an apartment. In our illustration we focus on two explanatory variables, surface and the number of rooms, as they are correlated (see Figure <a href="dataSetsIntro.html#fig:appartmentsSurfaceNorooms">5.9</a>).</p>
<p>Figure <a href="accumulatedLocalProfiles.html#fig:featureEffectsApartment">19.2</a> shows the three types of profiles for both variables estimated according to formulas <a href="partialDependenceProfiles.html#eq:PDPest">(18.2)</a>, <a href="accumulatedLocalProfiles.html#eq:LDPest2">(19.8)</a> and <a href="accumulatedLocalProfiles.html#eq:ALPest2">(19.12)</a>.</p>
<p>Number of rooms and surface are two correlated variables, moreover both have some effect on the price per square meter. As we see profiles calculated with different methods are different.</p>
<p>The green curve corresponds to the PD profile, which is the ordinary average of CP profiles. The red curve corresponds to the LD profile. It is steeper because the effect of the <code>surface</code> variable is additionally overlapped by the effects of variables correlated with <code>surface</code>, e.g. number of rooms.
The blue curve corresponds to the AL profile. The estimator for AL profiles eliminates the effect of correlated variables. Since the AL and PD profiles are parallel to each other, it suggests that the model is additive for these two variables. In other words the effect of the <code>surface</code> variable in the model does not depend on the value of other variables.</p>
<div class="figure" style="text-align: center"><span id="fig:featureEffectsApartment"></span>
<img src="ema_files/figure-html/featureEffectsApartment-1.png" alt="Partial dependence, local dependence, and accumulated local profiles for the random forest model for the  Apartments dataset." width="75%" />
<p class="caption">
Figure 19.2: Partial dependence, local dependence, and accumulated local profiles for the random forest model for the Apartments dataset.
</p>
</div>
</div>
<div id="ALPProsCons" class="section level2">
<h2><span class="header-section-number">19.5</span> Pros and cons</h2>
<p>In this chapter we introduced tools for exploration of the relation between model response and model inputs. These tools are useful to summarize how ,,in general’’ model responds to the input of interest. All presented approaches are based on Ceteris-paribus profiles introduced in Chapter <a href="ceterisParibus.html#ceterisParibus">11</a> but they differ in a way how individual profiles are merged into a global model response.</p>
<p>When the variables in the data are independent and there are no interactions in the model, the Ceteris-paribus profiles are parallel and their average, i.e. Partial Dependence, summarizes them all well.</p>
<p>When there are interactions in the model, the Ceteris-paribus profiles are not parallel. Additionally, if variables in the data are correlated, averaging entire Ceteris-paribus profiles may distort the relationship described by the model.</p>
<p>Comparison of PD, LD and AL profiles allows to identify if there are any interactions in the model and if data are significantly correlated. When there are interactions, it may be helpful to explore these relations with generalization of PD profiles for two or more dependent variables.</p>
</div>
<div id="ALPR" class="section level2">
<h2><span class="header-section-number">19.6</span> Code snippets for R</h2>
<p>In this section, we present key features of R package <code>DALEX</code> which is a wrapper over package <code>ingredients</code> <span class="citation">(Biecek et al. <a href="#ref-ingredientsRPackage">2019</a>)</span>. Similar functionalities can be found in package <code>ALEPlots</code> <span class="citation">(Apley <a href="#ref-ALEPlotRPackage">2018</a>)</span> or <code>iml</code> <span class="citation">(Molnar, Bischl, and Casalicchio <a href="#ref-imlRPackage">2018</a>)</span>.</p>
<p>For illustration purposes, we use the random-forest model <code>apartments_rf_v5</code> (see Section <a href="dataSetsIntro.html#model-Apartments-rf">5.2.3</a>) for the Apartments dataset (see Section @ref()). Recall that the goal is to predict the price per square-meter of an apartment. In our illustration we focus on two explanatory variables, surface and the number of rooms.</p>
<p>LD profiles are calculated by applying function <code>DALEX::variable_profile</code> to the model-explainer object. By default, profiles are calculated for all explanatory variables. To limit the calculation to selected variables, one can pass the names of the variables to the <code>variables</code> argument. A plot of the calculated profiles can be obtained by applying the generic <code>plot()</code> function, as shown in the code below. The resulting profiles correspond to those shown in Figure <a href="accumulatedLocalProfiles.html#fig:featureEffectsApartment">19.2</a>.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb143-1" data-line-number="1">explain_apartments_rf &lt;-<span class="st"> </span><span class="kw">explain</span>(model_apartments_rf, </a>
<a class="sourceLine" id="cb143-2" data-line-number="2">                                 <span class="dt">data =</span> apartments,</a>
<a class="sourceLine" id="cb143-3" data-line-number="3">                                 <span class="dt">verbose =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb143-4" data-line-number="4"></a>
<a class="sourceLine" id="cb143-5" data-line-number="5">pd_rf &lt;-<span class="st"> </span><span class="kw">variable_profile</span>(explain_apartments_rf, </a>
<a class="sourceLine" id="cb143-6" data-line-number="6">                           <span class="dt">type =</span> <span class="st">&quot;partial&quot;</span>,</a>
<a class="sourceLine" id="cb143-7" data-line-number="7">                          <span class="dt">variables =</span> <span class="kw">c</span>(<span class="st">&quot;no.rooms&quot;</span>, <span class="st">&quot;surface&quot;</span>))</a>
<a class="sourceLine" id="cb143-8" data-line-number="8"><span class="kw">plot</span>(pd_rf) <span class="op">+</span></a>
<a class="sourceLine" id="cb143-9" data-line-number="9"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Partial dependence for surface and number of rooms&quot;</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:aleExample1"></span>
<img src="ema_files/figure-html/aleExample1-1.png" alt="Partial Dependence profile for surface and number of rooms." width="80%" />
<p class="caption">
Figure 19.3: Partial Dependence profile for surface and number of rooms.
</p>
</div>
<p>LD profiles are calculated by applying function <code>DALEX::variable_profile</code> with additional argument <code>type = &quot;conditional&quot;</code>.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb144-1" data-line-number="1">cd_rf &lt;-<span class="st"> </span><span class="kw">variable_profile</span>(explain_apartments_rf,</a>
<a class="sourceLine" id="cb144-2" data-line-number="2">                          <span class="dt">type =</span> <span class="st">&quot;conditional&quot;</span>,</a>
<a class="sourceLine" id="cb144-3" data-line-number="3">                          <span class="dt">variables =</span> <span class="kw">c</span>(<span class="st">&quot;no.rooms&quot;</span>, <span class="st">&quot;surface&quot;</span>))</a>
<a class="sourceLine" id="cb144-4" data-line-number="4"><span class="kw">plot</span>(cd_rf) <span class="op">+</span></a>
<a class="sourceLine" id="cb144-5" data-line-number="5"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Local dependence for surface and number of rooms&quot;</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:aleExample3"></span>
<img src="ema_files/figure-html/aleExample3-1.png" alt="Local dependence profiles for the number of rooms and surface." width="80%" />
<p class="caption">
Figure 19.4: Local dependence profiles for the number of rooms and surface.
</p>
</div>
<p>LD profiles are calculated by applying function <code>DALEX::variable_profile</code> with additional argument <code>type = &quot;accumulated&quot;</code>.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb145-1" data-line-number="1">ac_rf &lt;-<span class="st"> </span><span class="kw">variable_profile</span>(explain_apartments_rf,</a>
<a class="sourceLine" id="cb145-2" data-line-number="2">                          <span class="dt">type =</span> <span class="st">&quot;accumulated&quot;</span>,</a>
<a class="sourceLine" id="cb145-3" data-line-number="3">                          <span class="dt">variables =</span> <span class="kw">c</span>(<span class="st">&quot;no.rooms&quot;</span>, <span class="st">&quot;surface&quot;</span>))</a>
<a class="sourceLine" id="cb145-4" data-line-number="4"><span class="kw">plot</span>(ac_rf) <span class="op">+</span></a>
<a class="sourceLine" id="cb145-5" data-line-number="5"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Accumulated local profiles for surface and number of rooms&quot;</span>) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:aleExample2"></span>
<img src="ema_files/figure-html/aleExample2-1.png" alt="Accumulated local profiles for the number of rooms and surface." width="80%" />
<p class="caption">
Figure 19.5: Accumulated local profiles for the number of rooms and surface.
</p>
</div>
<p>One can also use the <code>plot()</code> function to juxtapose different types of profiles in a single plot.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" data-line-number="1">pd_rf<span class="op">$</span>agr_profiles<span class="op">$</span><span class="st">`</span><span class="dt">_label_</span><span class="st">`</span> =<span class="st"> &quot;Partial Dependence&quot;</span></a>
<a class="sourceLine" id="cb146-2" data-line-number="2">cd_rf<span class="op">$</span>agr_profiles<span class="op">$</span><span class="st">`</span><span class="dt">_label_</span><span class="st">`</span> =<span class="st"> &quot;Local Dependence&quot;</span></a>
<a class="sourceLine" id="cb146-3" data-line-number="3">ac_rf<span class="op">$</span>agr_profiles<span class="op">$</span><span class="st">`</span><span class="dt">_label_</span><span class="st">`</span> =<span class="st"> &quot;Accumulated Local&quot;</span></a>
<a class="sourceLine" id="cb146-4" data-line-number="4"><span class="kw">plot</span>(pd_rf<span class="op">$</span>agr_profiles, cd_rf<span class="op">$</span>agr_profiles, ac_rf<span class="op">$</span>agr_profiles) </a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:aleExample5"></span>
<img src="ema_files/figure-html/aleExample5-1.png" alt="Different types of profiles for the number of rooms and surface." width="80%" />
<p class="caption">
Figure 19.6: Different types of profiles for the number of rooms and surface.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-ALEPlotRPackage">
<p>Apley, Dan. 2018. <em>ALEPlot: Accumulated Local Effects (Ale) Plots and Partial Dependence (Pd) Plots</em>. <a href="https://CRAN.R-project.org/package=ALEPlot">https://CRAN.R-project.org/package=ALEPlot</a>.</p>
</div>
<div id="ref-ALEPlot2">
<p>Apley, Daniel W., and Jingyu Zhu. 2019. “Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models.” <em>CoRR</em> abs/1612.08468. <a href="http://arxiv.org/abs/1612.08468">http://arxiv.org/abs/1612.08468</a>.</p>
</div>
<div id="ref-ingredientsRPackage">
<p>Biecek, Przemyslaw, Hubert Baniecki, Adam Izdebski, and Katarzyna Pekala. 2019. <em>ingredients: Effects and Importances of Model Ingredients</em>.</p>
</div>
<div id="ref-imlRPackage">
<p>Molnar, Christoph, Bernd Bischl, and Giuseppe Casalicchio. 2018. “iml: An R package for Interpretable Machine Learning.” <em>Joss</em> 3 (26). Journal of Open Source Software: 786. <a href="https://doi.org/10.21105/joss.00786">https://doi.org/10.21105/joss.00786</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="partialDependenceProfiles.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="residualDiagnostic.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ema.pdf", "ema.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
